---
title: "Unemployment Models"
author: "Brian Howard"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 4
    smart: false
---

```{r setup, echo=FALSE}

knitr::opts_chunk$set(echo = TRUE)
options("getSymbols.warning4.0"=FALSE)

```

```{r libraries, echo=FALSE, message=FALSE}

library(tidyverse)
library(tidyquant)
library(Hmisc)
library(gridExtra)
library(signal)
library(caret)
library(data.table)

```

```{r helper functions, echo=FALSE}

# Call helper functions
source("plotHelper.r")

```


```{r load.data, echo=FALSE}

str.data.dir <- "C:/Users/Rainy/OneDrive/Documents/IssaquahDynamical/Datasets/2529RS0082_HistEconData"
out.file <- file.path(str.data.dir, "RecessionIndicator_Buffer.RData")

# Load data
load(out.file)

rm(str.data.dir)
rm(out.file)

```


```{r plot.limits, echo=FALSE}

# Define the plotting ranges
dt.recent = as.Date("2017-01-01")

# Define the start of the prediction
dt.start.prediction <- as.Date("01/02/1962", "%d/%m/%Y")

# Back test range
dt_start_back_test = as.Date('1960-01-01')

# Define the S&P 500 limits
source("SetGSPCMax.r")

```

```{r clean_data, echo=FALSE}

# Keep only the symbols needed by this code
df.symbols <- dplyr::filter(df.symbols,
                            string.symbol %in% c("USREC",
                                                 "GDP",
                                                 "GDPC1",
                                                 "^TNX",
                                                 "NPPTTL",
                                                 "CCSA",
                                                 "PCE",
                                                 "U6RATE",
                                                 "UNRATE",
                                                 "ICSA",
                                                 "POPTHM",
                                                 "CLF16OV"))

if( exists("b.refresh.models")){
  rm(b.refresh.models)
}

if( exists("bRefresh")){
  rm(bRefresh)
}

if( exists("d.income")){
  rm(d.income)
}

if( exists("d.Russell.max")){
  rm(d.Russell.max)
}

if( exists("dt.date")){
  rm(dt.date)
}

if( exists("dt.date.c")){
  rm(dt.date.c)
}

if( exists("i.cols")){
  rm(i.cols)
}

if( exists("idx")){
  rm(idx)
}

if( exists("iDays")){
  rm(iDays)
}

if( exists("list.margin.names")){
  rm(list.margin.names)
}

if( exists("list.options.names")){
  rm(list.options.names)
}

if( exists("str.name")){
  rm(str.name)
}

if( exists("str.safe.name")){
  rm(str.safe.name)
}

if( exists("str_symbol")){
  rm(str_symbol)
}

if( exists("str.symbol")){
  rm(str.symbol)
}

if( exists("str_out")){
  rm(str_out)
}

if( exists("str.symbol.raw")){
  rm(str.symbol.raw)
}

if( exists("str_symbol.raw")){
  rm(str_symbol.raw)
}

if( exists("ylimBackTest")){
  rm(ylimBackTest)
}

if( exists("df.farm.income")){
  rm(df.farm.income)
}

```

## Feature Extraction

With the raw data downloaded, some of the interesting features can be extracted.
The first step is reconcile the time intervals. Some of the data is released
monthly and some daily. I chose to interpolate all data to a daily interval. The
first section of code adds the daily rows to the data frame.

The code performs interpolation for continuous data or carries it forward for
binary data like the recession indicators.

```{r aggsyms}

source("calcInterpolate.r")
df.data <- calcInterpolate(df.symbols)

```

## Truncate data

```{r data.trunc, echo=FALSE, fig.width = 10, fig.asp = .62}

# A very few data series do go back to 1854, but most
# don't even go past WWII so truncate the data frame.
df.data <- df.data[as.Date(rownames(df.data)) > as.Date("1940-01-01"),]

```

## Create aggregate series

Some analysis requires that two or more series be combined. For example, normallizing debt by GDP to get a sense of the proportion of debt to the total economy helps understand the debt cycle.

```{r create aggregate, echo=FALSE}

source("calcAggregateSeries.r")

```

Year over year, smoothed derivative, and log trends tend to smooth out seasonal variation. It gets used so often that I do this for every series downloaded.

```{r calcsYoYSmoothLog}

source("calcFeatures.r")
lst.df <- calcFeatures(df.data, df.symbols)
df.data <- lst.df[[1]]
df.symbols <- lst.df[[2]]

```


```{r calc.features.for.aggregate, echo=FALSE}

# Calculate the features for the aggregated series
source("calcFeaturesAggregate.r")

```


# Recession initiation and termination dates/times

Build the recession and recession initiation dates

```{r recframe}

source("calcRecession.r")

```

## Unemployment models

### Labor force normalization

The BLS statistics (U3, U6, etc.) calculates labor force by summing the number of employed and unemployed people (https://www.bls.gov/cps/lfcharacteristics.htm#laborforce). The problem is that when the survey is troubled, as it was during Covid19, the labor force shows a sudden drop. For example, during the Covid19 outbreak in the spring of 2020 the labor force dropped from 164MM to 155MM. In reality, the labor force did not really drop by this much. In other words there were approximately the same number of people who wanted to work on March 1st of 2020 as there were on June 1st of 2020.

This makes the BLS measures of labor force less useful when I want to normalized by working force population. To get around this I do a linear fit of BLS labor force to general U.S. population (POPTHM) and take the slope of that fit as the average labor force participation rate. I then multiply POPTHM this value to get a constant labor force rate. This has some drawbacks, especially in that it cannot account for demographic shifts. But it should be an okay first order approximation.

```{r lf.lm.setup, echo=FALSE}

dt.start.prediction <- as.Date(max(c(index(CLF16OV[1]), index(POPTHM[1]))))
dt.end.prediction <- as.Date("2020-01-01")

lst_syms <- c("CLF16OV.Value", "POPTHM.Value")
if ( require_columns(df.data, lst_syms ) ){
  
  df.lf.model <-
    df.data[df.data$date >= dt.start.prediction &
              df.data$date <= dt.end.prediction,]
  
  # Perform the fit
  str_form <- as.formula(paste(lst_syms[[1]], "~", lst_syms[[2]]))
  list.fit.clf16ovpopthm <- train(
    str_form,
    data = df.lf.model,
    method = "lm",
    preProcess = c('center', 'scale')
  )
  
  if( exists("str_form")){
    rm(str_form)
  }

}

# Clean and tidy memory
if( exists ("lst_syms")){
  rm(lst_syms)
}

```

```{r lf.lm.update, echo=FALSE, fig.width = 10, fig.asp = .62}

# Add linear prediction to the data frame
str_symbol <- "CLF16OV__lm__POPTHM"
df.data[str_symbol] <-
  predict(list.fit.clf16ovpopthm, newdata = df.data)


# Add the linear model prediction to the symbols table
df.symbols <- symbols_append_row(
  df.symbols,
  list(
    string.symbol = str_symbol,
    string.source = "Predict",
    string.description = "Linear Model Prediction\nCLF16OV given POPTHM",
    string.label.y = getPlotYLabel(df.symbols, "POPTHM")[1],
    float.expense.ratio = -1.00,
    Max030 = FALSE,
    Max180 = FALSE,
    date.series.start = dt.start.prediction,
    date.series.end = as.Date(Sys.Date()),
    string.symbol_safe = safe_symbol_name(str_symbol),
    string.object_name = safe_symbol_name(str_symbol)
  )
)

# Clean and tidy memory
if( exists("str_symbol")){
  rm(str_symbol)
}

```

```{r lf.lm.setup.plot, echo=FALSE, fig.width = 10, fig.asp = .62}

# Define the symbols in the plot
lst_syms <- c("CLF16OV__lm__POPTHM", "CLF16OV.Value")

# Do they exist in the data frame?
if ( require_columns(df.data, lst_syms ) ){

  my_plot <-
    plotSingle(
      dfRecession,
      df.data,
      "date",
      datay = lst_syms[[1]],
      "CLF16OV Compared to CLF16OV predicted using overall population, POPTHM",
      "Date",
      getPlotYLabel(df.symbols, lst_syms[[1]]),
      c(dt.start.prediction, Sys.Date()),
      ylim = c(50000, round_up_to(max(df.data[[lst_syms[[1]]]]),5000)),
      b.legend = TRUE,
      b.percentile = FALSE,
      b.long.legend = TRUE
    )
  my_plot <- my_plot + geom_line(
    data = df.data,
    aes(
      x = .data[["date"]],
      y = .data[[lst_syms[[2]]]],
      colour = getPlotTitle(df.symbols, lst_syms[[2]])
    ),
    na.rm = TRUE
  )
  
  print(my_plot)
  
  # Free up memory
  if( exists("my_plot")){
    rm(my_plot)
  }
}


# Free up memory
if( exists("lst_syms")){
  rm(lst_syms)
}


```

This section normalizes initial claims, ICSA, by the labor force estimated from the U.S. population, POPTHM.

```{r lf.lm.ICSA.norm, echo=FALSE, fig.width = 8, fig.asp = .52}

lst_syms <- c("ICSA.Value", "CLF16OV__lm__POPTHM")
if ( require_columns(df.data, lst_syms ) ){

  # Define the new symbol, make the calculation    
  str_symbol <- "ICSA__by__CLF16OV__lm__POPTHM"
  df.data[str_symbol] <- 
    df.data[[lst_syms[[1]]]] / df.data[[lst_syms[[2]]]]

  # Add the ICSA normalization to the symbols table
  df.symbols <- symbols_append_row(
    df.symbols,
    list(
      string.symbol = str_symbol,
      string.source = "Predict",
      string.description = "ICSA normalized by\nlabor force from POPTHM",
      string.label.y = "Percent",
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date()),
      string.symbol_safe = safe_symbol_name(str_symbol),
      string.object_name = safe_symbol_name(str_symbol)
    )
  )
  
  # Clean and tidy memory
  if( exists("str_symbol")){
    rm(str_symbol)
  }
}

# Free up memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```


```{r lf.lm.ICSA.norm.plot, echo=FALSE, fig.width = 8, fig.asp = .52}

# Define the symbols in the plot
lst_syms <- c("ICSA__by__CLF16OV__lm__POPTHM", "UNRATE.Value")

# Do they exist in the data frame?
if ( require_columns(df.data, lst_syms ) ){
  
  my_plot <-
    plotSingle(
      dfRecession,
      df.data,
      "date",
      datay = lst_syms[[1]],
      "UNRATE Compared to ICSA divided by labor force from POPTHM",
      "Date",
      getPlotYLabel(df.symbols, lst_syms[[1]]),
      c(index(ICSA[1]), Sys.Date()),
      ylim =  c(0, round_up_to(max(df.data[[lst_syms[[1]]]]),5)),
      b.legend = TRUE,
      b.percentile = FALSE,
      b.long.legend = TRUE
    )
  my_plot <- my_plot + geom_line(
    data = df.data,
    aes(
      x = .data[["date"]],
      y = .data[[lst_syms[[2]]]],
      colour = getPlotTitle(df.symbols, lst_syms[[2]])
    ),
    na.rm = TRUE
  )
  
  print(my_plot)
  
  # Free up memory
  if( exists("my_plot")){
    rm(my_plot)
  }
  
}

# Free up memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```


This section normalizes continued claims, CCSA, by the labor force estimated from the U.S. population, POPTHM.

```{r lf.lm.CCSA.norm, echo=FALSE, fig.width = 8, fig.asp = .52}

lst_syms <- c("CCSA.Value", "CLF16OV__lm__POPTHM")
if ( require_columns(df.data, lst_syms ) ){
  
  # Add linear prediction to the data frame
  str_symbol <- "CCSA__by__CLF16OV__lm__POPTHM"
  df.data[str_symbol] <- 
    df.data[[lst_syms[[1]]]] / df.data[[lst_syms[[2]]]]

  # Add the CCSA normalization to the symbols table
  df.symbols <- symbols_append_row(
    df.symbols,
    list(
      string.symbol = str_symbol,
      string.source = "Predict",
      string.description = "CCSA normalized by\nlabor force from POPTHM",
      string.label.y = "Percent",
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date()),
      string.symbol_safe = safe_symbol_name(str_symbol),
      string.object_name = safe_symbol_name(str_symbol)
    )
  )
  
  # Clean and tidy memory
  if( exists("str_symbol")){
    rm(str_symbol)
  }

}

# Free up memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```


```{r lf.lm.CCSA.norm.plot, echo=FALSE, fig.width = 8, fig.asp = .52}

# Define the symbols in the plot
lst_syms <- c("CCSA__by__CLF16OV__lm__POPTHM", "UNRATE.Value")

# Do they exist in the data frame?
if ( require_columns(df.data, lst_syms ) ){
  
  my_plot <-
    plotSingle(
      dfRecession,
      df.data,
      "date",
      datay = lst_syms[[1]],
      "UNRATE Compared to ICSA divided by labor force from POPTHM",
      "Date",
      getPlotYLabel(df.symbols, lst_syms[[1]]),
      c(index(CCSA[1]), Sys.Date()),
      ylim = c(0, round_up_to(max(df.data[[lst_syms[[1]]]]),5)),
      b.legend = TRUE,
      b.percentile = FALSE,
      b.long.legend = TRUE
    )
  my_plot <- my_plot + geom_line(
    data = df.data,
    aes(
      x = .data[["date"]],
      y = .data[[lst_syms[[2]]]],
      colour = shQuote(getPlotTitle(df.symbols, lst_syms[[2]]))
    ),
    na.rm = TRUE
  )
  
  print(my_plot)
  
  # Free up memory
  if( exists("my_plot")){
    rm(my_plot)
  }
  
}

# Free up memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```

This section normalizes total non-farm payroll data provided by ADP and in the NPPTTL series on FRED. Unlike ICSA or CCSA the values here are thousands rather than numbers.

```{r lf.lm.NPPTTL.norm, echo=FALSE, fig.width = 8, fig.asp = .52}

lst_syms <- c("NPPTTL.Value", "CLF16OV__lm__POPTHM")
if ( require_columns(df.data, lst_syms ) ){
  
  # Add normalization to the data frame
  str_symbol <- "NPPTTL__by__CLF16OV__lm__POPTHM"
  df.data[str_symbol] <- 
    ( 100.0 * ( 1.0 - (df.data[[lst_syms[[1]]]] / df.data[[lst_syms[[2]]]]) ) )

  # Add the NPPTTL normalization to the symbols table
  df.symbols <- symbols_append_row(
    df.symbols,
    list(
      string.symbol = str_symbol,
      string.source = "Predict",
      string.description = "NPPTTL (ADP) normalized by\nlabor force from POPTHM",
      string.label.y = "Percent",
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date()),
      string.symbol_safe = safe_symbol_name(str_symbol),
      string.object_name = safe_symbol_name(str_symbol)
    )
  )
  
  # Clean and tidy memory
  if( exists("str_symbol")){
    rm(str_symbol)
  }

}

# Free up memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```


```{r lf.lm.NPPTTL.norm.plot, echo=FALSE, fig.width = 8, fig.asp = .52}

lst_syms <- c("NPPTTL__by__CLF16OV__lm__POPTHM", "UNRATE.Value")
if ( require_columns(df.data, lst_syms ) ){
  
  ylim <- c(0, 40)
  dt.end <- Sys.Date()
  dt.start <- index(NPPTTL[1])
  my_plot <-
    plotSingle(
      dfRecession,
      df.data,
      "date",
      datay = lst_syms[[1]],
      "NPPTTL Compared to NPPTTL divided by labor force from POPTHM",
      "Date",
      getPlotYLabel(df.symbols, lst_syms[[1]]),
      c(dt.start, dt.end),
      ylim,
      b.legend = TRUE,
      b.percentile = FALSE,
      b.long.legend = TRUE
    )
  my_plot <- my_plot + geom_line(
    data = df.data,
    aes(
      x = .data[["date"]],
      y = .data[[lst_syms[[2]]]],
      colour = getPlotTitle(df.symbols, lst_syms[[2]])
    ),
    na.rm = TRUE
  )
  
  print(my_plot)
  
  # Free up memory
  if( exists("my_plot")){
    rm(my_plot)
  }

}

# Free up memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```

### Employment Correlation, U6 and U3

Correlation across some of the series. This section checks that survey data is coherent within itself. Do the U3 and U6 series generally agree?

```{r EMP.cor.setup, echo=FALSE}

# The U6 numbers do not have as much historical data as the U3 so valid data for fit
# begins early. I also excluded the COVID 19 mess of data.
dt.start.prediction <- as.Date("1994-01-01")
dt.end.prediction <- as.Date("2020-01-01")
df.emp.model <-
  df.data[df.data$date >= dt.start.prediction &
            df.data$date <= dt.end.prediction,]


# I break the data into three sets: 50% for training, 25% for testing, and 25% for validation.
lst_syms <- c("UNRATE.Value")
if ( require_columns(df.data, lst_syms ) ){
  
  set.seed(123456)
  in.train <- createDataPartition(y=df.emp.model[[lst_syms[[1]]]], 
                                  p = 0.50, 
                                  list=FALSE)
  df.train <- df.emp.model[in.train,]
  df.data.rest <- df.emp.model[-in.train,]
  in.val <- createDataPartition(y = df.data.rest[[lst_syms[[1]]]], 
                                p = 0.50, 
                                list = FALSE)
  df.val <- df.data.rest[in.val,]
  df.test <- df.data.rest[-in.val,]
  rm(df.data.rest)
}

# Free up memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```

```{r EMP.cor.fit, echo=FALSE}
lst_syms <- c("U6RATE.Value", "UNRATE.Value")
if ( require_columns(df.data, lst_syms ) ){
  
  # Define the equation
  str_form <- as.formula(paste(lst_syms[[1]], "~", lst_syms[[2]]))
  
  # Perform the linear fit
  list.fit.u3u6 <- train(
    str_form,
    data = df.train,
    method = "lm",
    preProcess = c('center', 'scale')
  )
  
  # Perform the knn fit
  list.fit.knn.u3u6 <- train(
    str_form,
    data = df.train,
    method = "knn",
    preProcess = c('center', 'scale')
  )
  
  # Clean and tidy memory
  if( exists("str_form")){
    rm(str_form)
  }
  if( exists("df.emp.model")){
    rm(df.emp.model)
  }
  if( exists("df.train")){
    rm(df.train)
  }
  if( exists("df.val")){
   rm(df.val)
  }
}

# Free up memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```

```{r EMP.cor, echo=FALSE}

# Add prediction to the data frame
str_symbol <- "U6__lm__U3"
df.data[str_symbol] <-
  predict(list.fit.u3u6, newdata = df.data)

# Add the linear model prediction to the symbols table
df.symbols <- symbols_append_row(
  df.symbols,
  list(
    string.symbol = str_symbol,
    string.source = "Predict",
    string.description = "Linear Model Prediction\nU6 given U3",
    string.label.y = df.symbols[df.symbols$string.symbol=="UNRATE","string.label.y"],
    float.expense.ratio = -1.00,
    Max030 = FALSE,
    Max180 = FALSE,
    date.series.start = dt.start.prediction,
    date.series.end = as.Date(Sys.Date()),
    string.symbol_safe = safe_symbol_name(str_symbol),
    string.object_name = safe_symbol_name(str_symbol)
  )
)

# Document the residual to the linear model as well
lst_syms <- c("U6RATE.Value")
if ( require_columns(df.data, lst_syms ) ){
    
  str_symbol.res <- "U6__lm__U3__res"
  df.data[str_symbol.res] <- df.data[[lst_syms[[1]]]] - df.data[str_symbol]
  
  # Add the u6 linear model residual to the symbols table
  df.symbols <- symbols_append_row(
    df.symbols,
    list(
      string.symbol = str_symbol.res,
      string.source = "Predict Resid.",
      string.description = "Linear Model Residual\nU6 given U3",
      string.label.y = df.symbols[df.symbols$string.symbol==str_symbol,"string.label.y"],
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date()),
      string.symbol_safe = safe_symbol_name(str_symbol.res),
      string.object_name = safe_symbol_name(str_symbol.res)
    )
  )

}

# Clean and tidy memory
if( exists("lst_syms")){
  rm(lst_syms)
}
if( exists("str_symbol")){
  rm(str_symbol)
}
if( exists("str_symbol.res")){
  rm(str_symbol.res)
}

# Add KNN prediction to the data frame
str_symbol.knn <- "U6__knn__U3"
df.data[str_symbol.knn] <-
  predict(list.fit.knn.u3u6, newdata = df.data)

# Add the KNN prediction to the symbols table
df.symbols <- symbols_append_row(
  df.symbols,
  list(
    string.symbol = str_symbol.knn,
    string.source = "Predict",
    string.description = "KNN Model Prediction\nU6 given U3",
    string.label.y = df.symbols[df.symbols$string.symbol=="UNRATE","string.label.y"],
    float.expense.ratio = -1.00,
    Max030 = FALSE,
    Max180 = FALSE,
    date.series.start = dt.start.prediction,
    date.series.end = as.Date(Sys.Date()),
    string.symbol_safe = safe_symbol_name(str_symbol.knn),
    string.object_name = safe_symbol_name(str_symbol.knn)
  )
)

# Document the residual to the KNN model as well
lst_syms <- c("U6RATE.Value")
if ( require_columns(df.data, lst_syms ) ){
  
  str_symbol.res.knn <- "U6__knn__U3__res"
  df.data[str_symbol.res.knn] <- df.data[[lst_syms[[1]]]] - df.data[str_symbol.knn]
  
  # Add the u6 residual with respect to the KNN model to the symbols table
  df.symbols <- symbols_append_row(
    df.symbols,
    list(
      string.symbol = str_symbol.res.knn,
      string.source = "Predict Resid.",
      string.description = "KNN Model Residual\nU6 given U3",
      string.label.y = df.symbols[df.symbols$string.symbol==str_symbol.knn,"string.label.y"],
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date()),
      string.symbol_safe = safe_symbol_name(str_symbol.res.knn),
      string.object_name = safe_symbol_name(str_symbol.res.knn)
    )
  )

}

# Clean and tidy memory
if( exists("lst_syms")){
  rm(lst_syms)
}
if( exists("str_symbol.knn")){
  rm(str_symbol.knn)
}
if( exists("str_symbol.res.knn")){
  rm(str_symbol.res.knn)
}


```



Look at how the fits performed on the test data partition

```{r U3.EMP.cor.perf, echo=FALSE}

lst_syms <- c("U6RATE.Value")
if ( require_columns(df.data, lst_syms ) ){
  d.test.resid = (df.test[[lst_syms]] - predict(list.fit.u3u6, newdata = df.test))
  hist(d.test.resid, main=paste("Residual for ", 
                                "U6__lm__U3__res", 
                                " on the Test Partition", sep=" "))
  sd.fit.u3u6 = sd(d.test.resid)
  
  # Clean up memory
  if( exists("d.test.resid")){
    rm(d.test.resid)
  }
  
}

# Clean and tidy memory
if( exists("lst_syms")){
  rm(lst_syms)
}

lst_syms <- c("U6RATE.Value")
if ( require_columns(df.data, lst_syms ) ){
  d.test.resid.knn = (df.test[[lst_syms[[1]]]] - predict(list.fit.knn.u3u6, newdata = df.test))
  hist(d.test.resid.knn, main=paste("Residual for ", 
                                    "U6__knn__U3__res",
                                    " on the Test Partition", sep=" "))
  sd.fit.knn.u3u6 = sd(d.test.resid.knn)
  
  # Clean up memory
  if( exists("d.test.resid.knn")){
    rm(d.test.resid.knn)
  }  
  
}

# Clean and tidy memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```

Plot the measured U6 (U6RATE) to U6 predicted by a linear fit to U3.

```{r EMP.cor.plot, echo=FALSE, fig.width = 10, fig.asp = .62}

lst_syms <- c("U6RATE.Value", "U6__lm__U3")
if ( require_columns(df.data, lst_syms ) ){
    
  my_plot <-
    plotSingle(
      dfRecession,
      df.data,
      "date",
      datay = lst_syms[[1]],
      "U6 Compared to U6 predicted using U3 (UNRATE)",
      "Date",
      getPlotYLabel(df.symbols, lst_syms[[1]]),
      c(as.Date("1jan1994", "%d%b%Y"), Sys.Date()),
      ylim = c(0, 25),
      b.legend = TRUE,
      b.percentile = FALSE,
      b.long.legend = TRUE
    )
  my_plot <- my_plot + geom_line(
    data = df.data,
    aes(
      x = .data[["date"]],
      y = .data[[lst_syms[[2]]]],
      colour = getPlotTitle(df.symbols, lst_syms[[2]])
    ),
    na.rm = TRUE
  )

  print(my_plot)
  
  # Clean memory
  if( exists("my_plot")){
    rm(my_plot)
  }

}

# Clean and tidy memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```

```{r EMP.cor.plot.close, echo=FALSE, fig.width = 10, fig.asp = .62}

lst_syms <- c("U6RATE.Value", "U6__lm__U3")
if ( require_columns(df.data, lst_syms ) ){

  my_plot <-
    plotSingle(
      dfRecession,
      df.data,
      "date",
      datay = lst_syms[[1]],
      "U6 Compared to U6 predicted using U3 (UNRATE)",
      "Date",
      getPlotYLabel(df.symbols, lst_syms[[1]]),
      c(as.Date('2020-01-02'), Sys.Date()),
      ylim = c(0, 25),
      b.legend = TRUE,
      b.percentile = FALSE,
      b.long.legend = TRUE
    )
  my_plot <- my_plot + geom_line(
    data = df.data,
    aes(
      x = .data[["date"]],
      y = .data[[lst_syms[[2]]]],
      colour = getPlotTitle(df.symbols, lst_syms[[2]])
    ),
    na.rm = TRUE
  )

  print(my_plot)

  # Clean memory
  if( exists("my_plot")){
    rm(my_plot)
  }

}

# Clean and tidy memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```


Plot the residual for the U6 linear fit. The residuals decrease quite a bit
during the COVID-19 numbers, at least as of Jun 2020. Probably indicates
uncertainty in the numbers.

```{r EMP.cor.resid, echo=FALSE,, fig.width = 6, fig.asp = .82}

lst_syms <- c("U6__lm__U3__res", "U6__knn__U3__res")
if ( require_columns(df.data, lst_syms ) ){
  
  ylim <- c(-4, 4)
  my_plot <- plotSingle(
    dfRecession,
    df.data,
    "date",
    datay = lst_syms[[1]],
    getPlotTitle(df.symbols, lst_syms[[1]]),
    "Date",
    getPlotYLabel(df.symbols, lst_syms[[1]]),
    c(as.Date("1jan1994", "%d%b%Y"), Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = TRUE,
    b.long.legend = FALSE
  )

  my_plot <- my_plot + geom_line(
    data = df.data,
    aes(
      x = .data[["date"]],
      y = .data[[lst_syms[[2]]]],
      colour = getPlotTitle(df.symbols, lst_syms[[2]])
    ),
    na.rm = TRUE
  )

  
  my_plot <- my_plot + geom_hline(yintercept=(6*sd.fit.u3u6), color = "red", linetype="dashed")
  my_plot <- my_plot + geom_hline(yintercept=(-6*sd.fit.u3u6), color = "red", linetype="dashed")

  print(my_plot)

  # Clean memory
  if( exists("my_plot")){
    rm(my_plot)
  }
}

# Clean and tidy memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```

### Employment Correlation, U3 (UNRATE) and ICSA by labor force 

Calculate linear model fit across the series. ISCA only records those claiming
benefits. Presumably, only a subset of those claiming benefits will prove out to
be eligible to receive benefits. It should always be greater than the continuing
claim numbers.

https://fredblog.stlouisfed.org/2020/04/things-to-know-about-initial-claims-data/

ICSA is normalized by the labor force value estimated from the U.S. population,
POPTHM.

The linear fit for this series will not likely be as accurate as the CCSA prediction

```{r U3_pred_ICSA_setup, echo=FALSE}

# The U6 numbers do not have as much historical data as the U3 so valid data for
# fit begins early. I also excluded the COVID-19 mess of data.
dt.start.prediction <- as.Date("1967-01-07")
dt.end.prediction <- as.Date("2020-01-01")
df.emp.model <-
  df.data[df.data$date >= dt.start.prediction &
            df.data$date <= dt.end.prediction,]

# I break the data into three sets: 50% for training, 25% for testing, and 25%
# for validation using the parent data series (ICSA) as the baseline.
set.seed(123456)
lst_syms <- c("ICSA.Value")
if ( require_columns(df.data, lst_syms ) ){
  
  in.train <- createDataPartition(y=df.emp.model[[lst_syms[[1]]]], p = 0.50, list=FALSE)
  df.train <- df.emp.model[in.train,]
  df.data.rest <- df.emp.model[-in.train,]
  in.val <- createDataPartition(y = df.data.rest[[lst_syms[[1]]]], p = 0.50, list = FALSE)
  df.val <- df.data.rest[in.val,]
  df.test <- df.data.rest[-in.val,]
  rm(df.data.rest)
}

# Clean and tidy memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```

```{r U3_pred_ICSA_fit, echo=FALSE}

lst_syms <- c("UNRATE.Value",
              "ICSA__by__CLF16OV__lm__POPTHM",
              "CCSA__by__CLF16OV__lm__POPTHM")

if ( require_columns(df.data, lst_syms ) ){
  
  # Define the equation
  str_form <- as.formula(paste(lst_syms[[1]], "~", 
                               lst_syms[[2]], " + ",
                               lst_syms[[3]]))
  
  # Perform the linear fit
  list.fit.u3icsapaynsa <- train(
    str_form,
    data = df.train,
    method = "lm",
    preProcess = c('center', 'scale')
  )

  # Perform the KNN fit    
  list.fit.knn.u3icsapaynsa <- train(
    str_form,
    data = df.train,
    method = "knn",
    preProcess = c('center', 'scale')
  )
  
  # ---- Extract LM weights (coefficients) -----------------------------------
  lm_mod <- list.fit.u3icsapaynsa$finalModel       # plain 'lm' object
  coefs_scaled <- stats::coef(lm_mod)              # intercept + betas on standardized X

  # Preprocess info for unscaling to original units
  pp <- list.fit.u3icsapaynsa$preProcess
  mu <- pp$mean[names(coefs_scaled)[-1]]           # means of predictors
  sd <- pp$std [names(coefs_scaled)[-1]]           # std devs of predictors

  # Convert: y = a + sum b_k * (x_k - mu_k) / sd_k
  # => intercept_orig = a - sum(b_k * mu_k / sd_k)
  #    beta_orig      = b_k / sd_k
  intercept_scaled <- coefs_scaled[[1]]
  betas_scaled     <- coefs_scaled[-1]

  betas_orig       <- betas_scaled / sd
  intercept_orig   <- intercept_scaled - sum(betas_scaled * (mu / sd))
  coefs_orig       <- c("(Intercept)" = intercept_orig, betas_orig)

  # ---- Report --------------------------------------------------------------
  cat("\n== Linear Model (caret::train(method = 'lm')) ==\n")
  print(summary(lm_mod))     # full lm summary on standardized predictors

  cat("\n-- Weights on standardized predictors (as trained) --\n")
  print(round(coefs_scaled, 6))

  cat("\n-- Weights transformed to ORIGINAL data scale --\n")
  print(round(coefs_orig, 6))

  if( exists("pp")){
    rm(pp)
  } 
  if( exists("mu")){
    rm(mu)
  }  
  if( exists("sd")){
    rm(sd)
  }
  if( exists("lm_mod")){
    rm(lm_mod)
  }
  if( exists("coefs_scaled")){
    rm(coefs_scaled)
  }
  if( exists("intercept_scaled")){
    rm(intercept_scaled)
  }
  if( exists("betas_scaled")){
    rm(betas_scaled)
  }
  if( exists("betas_orig")){
    rm(betas_orig)
  }  
  if( exists("intercept_orig")){
    rm(intercept_orig)
  }    
  if( exists("coefs_orig")){
    rm(coefs_orig)
  }    
  if( exists("df.emp.model")){
    rm(df.emp.model)
  }
  if( exists("str_form")){
    rm(str_form)
  }
  if( exists("df.train")){
    rm(df.train)
  }
  if( exists("df.val")){
    rm(df.val)
  }
}

# Clean and tidy memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```



```{r U3_pred_ICSA, echo=FALSE}

# Add linear prediction to the data frame
str_symbol <- "U3__lm__ICSA__by__CLF16OV__lm__POPTHM"
df.data[str_symbol] <-
  predict(list.fit.u3icsapaynsa, newdata = df.data)

# Add the linear model prediction to the symbols table
df.symbols <- symbols_append_row(
  df.symbols,
  list(
    string.symbol = str_symbol,
    string.source = "Predict",
    string.description = "Linear Model Prediction\nU3 given ICSA",
    string.label.y = df.symbols[df.symbols$string.symbol=="UNRATE","string.label.y"],
    float.expense.ratio = -1.00,
    Max030 = FALSE,
    Max180 = FALSE,
    date.series.start = dt.start.prediction,
    date.series.end = as.Date(Sys.Date()),
    string.symbol_safe = safe_symbol_name(str_symbol),
    string.object_name = safe_symbol_name(str_symbol)
  )
)

# Clean and tidy memory
if( exists ("str_symbol")){
  rm(str_symbol)
}

# Document the linear model residual as well
lst_syms <- c("UNRate.Value", "U3__lm__ICSA__by__CLF16OV__lm__POPTHM")
if ( require_columns(df.data, lst_syms ) ){
  
  str_symbol.res <- "U3__lm__ICSA__by__CLF16OV__lm__POPTHM__res"
  df.data[str_symbol.res] <- 
    df.data[[lst_syms[[1]]]] - df.data[[lst_syms[[2]]]]
  
  # Add the U3 linear model prediction residual to the symbols table
  df.symbols <- symbols_append_row(
    df.symbols,
    list(
      string.symbol = str_symbol.res,
      string.source = "Predict Resid.",
      string.description = "Linear Model Residual\nU3 given ICSA",
      string.label.y = df.symbols[df.symbols$string.symbol==str_symbol,"string.label.y"],
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date()),
      string.symbol_safe = safe_symbol_name(str_symbol.res),
      string.object_name = safe_symbol_name(str_symbol.res)
    )
  )
}

# Add the KNN prediction to the data frame
str_symbol.knn <- "U3__knn__ICSA__by__CLF16OV__lm__POPTHM"
df.data[str_symbol.knn] <-
  predict(list.fit.knn.u3icsapaynsa, newdata = df.data)

# Add the nearest neighbors prediction to the symbols table
df.symbols <- symbols_append_row(
  df.symbols,
  list(
    string.symbol = str_symbol.knn,
    string.source = "Predict",
    string.description = "KNN Model Prediction\nU3 given ICSA",
    string.label.y = df.symbols[df.symbols$string.symbol=="UNRATE","string.label.y"],
    float.expense.ratio = -1.00,
    Max030 = FALSE,
    Max180 = FALSE,
    date.series.start = dt.start.prediction,
    date.series.end = as.Date(Sys.Date()),
    string.symbol_safe = safe_symbol_name(str_symbol.knn),
    string.object_name = safe_symbol_name(str_symbol.knn)
  )
)

# Clean and tidy memory
if( exists("str_symbol.knn")){
  rm(str_symbol.knn)
}

# Document the KNN residual as well
lst_syms <- c("UNRate.Value", "U3__knn__ICSA__by__CLF16OV__lm__POPTHM")
if ( require_columns(df.data, lst_syms ) ){
  
  str_symbol.res.knn <- "U3__knn__ICSA__by__CLF16OV__lm__POPTHM__res"
  df.data[str_symbol.res.knn] <- 
    df.data[[lst_syms[[1]]]] - df.data[[lst_syms[[2]]]]
  
  # Add the U3 nearest neighbor prediction residual to the symbols table
  df.symbols <- symbols_append_row(
    df.symbols,
    list(
      string.symbol = str_symbol.res.knn,
      string.source = "Predict Resid.",
      string.description = "KNN Model Residual\nU3 given ICSA",
      string.label.y = df.symbols[df.symbols$string.symbol==str_symbol.knn,"string.label.y"],
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date()),
      string.symbol_safe = safe_symbol_name(str_symbol.res.knn),
      string.object_name = safe_symbol_name(str_symbol.res.knn)
    )
  )
  
  # Clean and tidy memory
  if( exists("str_symbol.res.knn")){
    rm(str_symbol.res.knn)
  }  

}

# Clean and tidy memory
if( exists("lst_syms")){
  rm(lst_syms)
}

```

Look at how the fits for U3 performed on the test data partition

```{r U3_pred_ICSA_CCSA_perf, echo=FALSE}

lst_syms <- c("UNRATE.Value")
if ( require_columns(df.data, lst_syms ) ){
  
  d.test.resid = (df.test[[lst_syms[[1]]]] -
                    predict(list.fit.u3icsapaynsa, newdata = df.test))
  hist(d.test.resid, main=paste("Residual for ", 
                                "U3__lm__ICSA__by__CLF16OV__lm__POPTHM",
                                " on the Test Partition",
                                sep=" "))
  sd.fit.u3icsapaynsa = sd(d.test.resid)
  
  # Last use of the fit model so remove it from memory
  if( exists("list.fit.u3icsapaynsa")){
    rm(list.fit.u3icsapaynsa)
  }
  
}

# Clean and tidy memory
if( exists("lst_syms")){
  rm(lst_syms)
}

lst_syms <- c("UNRATE.Value")
if ( require_columns(df.data, lst_syms ) ){
  
  d.test.resid.knn = (df.test[[lst_syms[[1]]]] - 
                        predict(list.fit.knn.u3icsapaynsa, newdata = df.test))
  hist(d.test.resid.knn, main=paste("Residual for ", 
                                    "U3__knn__ICSA__by__CLF16OV__lm__POPTHM", 
                                    " on the Test Partition",
                                    sep=" "))
  sd.fit.knn.u3icsapaynsa = sd(d.test.resid.knn)
  
  if( exists("list.fit.knn.u3icsapaynsa")){
    rm(list.fit.knn.u3icsapaynsa)
  }

}
```

Plot the measured U3 (UNRATE) to U3 predicted by a linear fit to ICSA.

```{r U3_pred_ICSA_CCSA_plot, echo=FALSE, fig.width = 8, fig.asp = .62}


datay <- "U3__lm__ICSA__by__CLF16OV__lm__POPTHM"
datay.aux <- "UNRATE.Value"
# datay.aux.1 <- "UNRATE"
ylim <- c(0, 15)
dt.end <- Sys.Date()
my_plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    "U3 Compared to U3 predicted using initial claims, ICSA",
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(index(ICSA[1]), dt.end),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my_plot <- my_plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux))
  ),
  na.rm = TRUE
)

# my_plot + geom_line(
#   data = df.data,
#   aes_string(
#     x = "date",
#     y = datay.aux.1,
#     colour = shQuote(getPlotTitle(df.symbols, datay.aux.1))
#   ),
#   na.rm = TRUE
# )

print(my_plot)
```

Take a closer look, given the interest around latest U3 numbers

```{r U3.pred.ICSA.plot.recent, echo=FALSE, fig.width = 8, fig.asp = .62}


datay <- "U3.lm.ICSA.by.CLF16OV__lm__POPTHM"
datay.aux <- "UNRATE"
datay.aux.1 <- "UNRATE"
ylim <- c(-10, 75)
dt.end <- Sys.Date()
dt.start <- as.Date("2020-01-01")
my_plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    "U3 Compared to U3 predicted using ICSA",
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, dt.end),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my_plot <- my_plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux))
  ),
  na.rm = TRUE
)

# my_plot <- my_plot + geom_line(
#   data = df.data,
#   aes_string(
#     x = "date",
#     y = datay.aux.1,
#     colour = shQuote(getPlotTitle(df.symbols, datay.aux.1))
#   ),
#   na.rm = TRUE
# )

print(my_plot)

```


Plot the residual for the U3 to predict U3 from ICSA.

```{r U3.pred.ICSA.resid.lm, echo=FALSE, fig.width = 6, fig.asp = .82}

datay <- str_symbol.res
ylim <- c(-50, 10)
my_plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  getPlotTitle(df.symbols, datay),
  "Date",
  getPlotYLabel(df.symbols, datay),
  c(dt.start.prediction, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = TRUE,
  b.long.legend = FALSE
)


my_plot <- my_plot + geom_hline(yintercept=(6*sd.fit.u3icsapaynsa), color = "red", linetype="dashed")
my_plot <- my_plot + geom_hline(yintercept=(-6*sd.fit.u3icsapaynsa), color = "red", linetype="dashed")

print(my_plot)

```

```{r U3.pred.ICSA.resid.knn, echo=FALSE, fig.width = 6, fig.asp = .82}

datay <- "U3.knn.ICSA.by.CLF16OV__lm__POPTHM.res"
ylim <- c(-100, 10)
my_plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  getPlotTitle(df.symbols, datay),
  "Date",
  getPlotYLabel(df.symbols, datay),
  c(dt.start.prediction, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = TRUE,
  b.long.legend = FALSE
)


my_plot <- my_plot + geom_hline(yintercept=(6*sd.fit.knn.u3icsapaynsa), color = "red", linetype="dashed")
my_plot <- my_plot + geom_hline(yintercept=(-6*sd.fit.knn.u3icsapaynsa), color = "red", linetype="dashed")

print(my_plot)

```

### Employment Correlation, U3 (UNRATE) and CCSA 

Calculate linear model fit across the series. CCSA only records those who have experienced a week of unemployment and the filed a continuing claim.


```{r U3.pred.CCSA.setup, echo=FALSE}

# The U6 numbers do not have as much historical data as the U3 so valid data for fit
# begins early. I also exluded the Covid 16 mess of data.
dt.start.prediction <- as.Date("1967-01-07")
dt.end.prediction <- as.Date("2020-01-01")
df.emp.model <-
  df.data[df.data$date >= dt.start.prediction &
            df.data$date <= dt.end.prediction,]

# I break the data into three sets: 50% for training, 25% for testing, and 25% for validation.
set.seed(123456)
in.train <- createDataPartition(y=df.emp.model$ICSA, p = 0.50, list=FALSE)
df.train <- df.emp.model[in.train,]
df.data.rest <- df.emp.model[-in.train,]
in.val <- createDataPartition(y = df.data.rest$ICSA, p = 0.50, list = FALSE)
df.val <- df.data.rest[in.val,]
df.test <- df.data.rest[-in.val,]
rm(df.data.rest)

```

```{r U3.pred.CCSA.fit, echo=FALSE}

rm(df.emp.model)
gc()

# Perform the fit
list.fit.u3ccsa <- train(
  UNRATE ~ CCSA.by.CLF16OV__lm__POPTHM,
  data = df.train,
  method = "lm",
  preProcess = c('center', 'scale')
)

list.fit.knn.u3ccsa <- train(
  UNRATE ~ CCSA.by.CLF16OV__lm__POPTHM,
  data = df.train,
  method = "knn",
  preProcess = c('center', 'scale')
)

rm(df.train)
rm(df.val)


```

```{r U3.pred.CCSA, echo=FALSE}

# Add linear model prediction to the dataframe
str_symbol <- "U3.lm.CCSA.by.CLF16OV__lm__POPTHM"
df.data[str_symbol] <-
  predict(list.fit.u3ccsa, newdata = df.data)

# Add the linear model prediction to the symbols table
df.symbols <-
  rbind(
    df.symbols,
    data.frame(
      string.symbol = str_symbol,
      string.source = "Predict",
      string.description = "\nLinear Model Prediction\nU3 given CCSA",
      string.label.y = df.symbols[df.symbols$string.symbol=="UNRATE","string.label.y"],
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date())
    )
  )

# Document the residual as well
str_symbol.res <- "U3.lm.CCSA.by.CLF16OV__lm__POPTHM.res"
df.data[str_symbol.res] <- df.data$UNRATE - df.data[str_symbol]

# Add the U3 linear model model prediction residual to the symbols table
df.symbols <-
  rbind(
    df.symbols,
    data.frame(
      string.symbol = str_symbol.res,
      string.source = "Predict Resid.",
      string.description = "\nLinear Model Residual\nU3 given CCSA",
      string.label.y = df.symbols[df.symbols$string.symbol==str_symbol,"string.label.y"],
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date())
    )
  )

# Add KNN model prediction to the dataframe
str_symbol <- "U3.knn.CCSA.by.CLF16OV__lm__POPTHM"
df.data[str_symbol] <-
  predict(list.fit.knn.u3ccsa, newdata = df.data)

# Add the knn model prediction to the symbols table
df.symbols <-
  rbind(
    df.symbols,
    data.frame(
      string.symbol = str_symbol,
      string.source = "Predict",
      string.description = "KNN Prediction\nU3 given CCSA",
      string.label.y = df.symbols[df.symbols$string.symbol=="UNRATE","string.label.y"],
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date())
    )
  )

# Document the residual as well
str_symbol.res.knn <- "U3.knn.CCSA.by.CLF16OV__lm__POPTHM.res"
df.data[str_symbol.res.knn] <- df.data$UNRATE - df.data[str_symbol]

# Add the U3 knn model prediction residual to the symbols table
df.symbols <-
  rbind(
    df.symbols,
    data.frame(
      string.symbol = str_symbol.res.knn,
      string.source = "Predict Resid.",
      string.description = "KNN Residual\nU3 given CCSA",
      string.label.y = df.symbols[df.symbols$string.symbol==str_symbol,"string.label.y"],
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date())
    )
  )

```

Look at how the fits performed on the test data partition

```{r U3.pred.CCSA.perf, echo=FALSE}

d.test.resid = (df.test$UNRATE - predict(list.fit.u3ccsa, newdata = df.test))
hist(d.test.resid, main=paste("Residual For", str_symbol.res, sep=" "))
sd.fit.u3ccsa = sd(d.test.resid)


d.test.resid.knn = (df.test$UNRATE - predict(list.fit.knn.u3ccsa, newdata = df.test))
hist(d.test.resid.knn, main=paste("Residual For", str_symbol.res.knn, sep=" "))
sd.fit.knn.u3ccsa = sd(d.test.resid.knn)
rm(list.fit.knn.u3ccsa)

```


Plot the measured U3 (UNRATE) to U3 predicted by a linear fit to CCSA.

```{r U3.pred.CCSA.plot, echo=FALSE,, fig.width = 8, fig.asp = .62}


datay <- "UNRATE"
datay_aux <- "U3.lm.CCSA.by.CLF16OV__lm__POPTHM"
ylim <- c(0, 15)
dt.end <- Sys.Date()
my_plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    "U3 Compared to U3 predicted using CCSA",
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(index(CCSA[1]), dt.end),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my_plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay_aux,
    colour = shQuote(getPlotTitle(df.symbols, datay_aux))
  ),
  na.rm = TRUE
)

```

Zoom in a little. There is a lot of discussion about how valid the latest U3 numbers are.

```{r U3.pred.CCSA.plot.recent, echo=FALSE,, fig.width = 8, fig.asp = .62}


datay <- "UNRATE"
datay_aux <- "U3.lm.CCSA.by.CLF16OV__lm__POPTHM"
ylim <- c(0, 50)
dt.end <- Sys.Date()
dt.start <- as.Date("2019-01-01")
my_plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    "U3 Compared to U3 predicted using CCSA by labor force from POPTHM",
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, dt.end),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my_plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay_aux,
    colour = shQuote(getPlotTitle(df.symbols, datay_aux))
  ),
  na.rm = TRUE
)

```


Plot the residual for the U3 linear fit. The residuals decrease quite a bit during the Covid numbers, at least as of Jun 2020. Probably indicates uncertainty in the numbers.

```{r U3.pred.CCSA.resid, echo=FALSE,, fig.width = 6, fig.asp = .82}

datay <- "U3.lm.CCSA.by.CLF16OV__lm__POPTHM.res"
ylim <- c(-20, 10)
my_plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  getPlotTitle(df.symbols, datay),
  "Date",
  getPlotYLabel(df.symbols, datay),
  c(index(CCSA[1]), Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = TRUE,
  b.long.legend = FALSE
)

my_plot <- my_plot + geom_hline(yintercept=(6*sd.fit.u3ccsa), color = "red", linetype="dashed")
my_plot <- my_plot + geom_hline(yintercept=(-6*sd.fit.u3ccsa), color = "red", linetype="dashed")

print(my_plot)


```


### Employment Correlation, U3 (UNRATE) and NPPTTL (ADP) normalized  

Calculate linear model fit across the series. NPPTTL should be an accurate esimate of the actual number of people on payrolls.


```{r U3.pred.NPPTTL.setup, echo=FALSE}

# The U6 numbers do not have as much historical data as the U3 so valid data for fit
# begins early. I also exluded the Covid 16 mess of data.
dt.start.prediction <- as.Date("2002-04-01")
dt.end.prediction <- as.Date("2020-01-01")
df.emp.model <-
  df.data[df.data$date >= dt.start.prediction &
            df.data$date <= dt.end.prediction,]

# I break the data into three sets: 50% for training, 25% for testing, and 25% for validation.
set.seed(123456)
in.train <- createDataPartition(y=df.emp.model$ICSA, p = 0.50, list=FALSE)
df.train <- df.emp.model[in.train,]
df.data.rest <- df.emp.model[-in.train,]
in.val <- createDataPartition(y = df.data.rest$ICSA, p = 0.50, list = FALSE)
df.val <- df.data.rest[in.val,]
df.test <- df.data.rest[-in.val,]
rm(df.data.rest)


```

```{r U3.pred.NPPTTL.fit, echo=FALSE}

# Perform the fit
list.fit.u3nppttl <- train(
  UNRATE ~ NPPTTL.by.CLF16OV__lm__POPTHM,
  data = df.emp.model,
  method = "lm",
  preProcess = c('center', 'scale')
)

list.fit.knn.u3nppttl <- train(
  UNRATE ~ NPPTTL.by.CLF16OV__lm__POPTHM,
  data = df.train,
  method = "knn",
  preProcess = c('center', 'scale')
)

rm(df.train)
rm(df.val)

```

```{r U3.pred.NPPTTL, echo=FALSE}

# Add linear model prediction to the dataframe
str_symbol <- "U3.lm.NPPTTL.by.CLF16OV__lm__POPTHM"
df.data[str_symbol] <-
  predict(list.fit.u3nppttl, newdata = df.data)

# Add the linear model prediction to the symbols table
df.symbols <-
  rbind(
    df.symbols,
    data.frame(
      string.symbol = str_symbol,
      string.source = "Predict",
      string.description = "Linear Model Prediction\nU3 given NPPTTL by POPTH",
      string.label.y = df.symbols[df.symbols$string.symbol=="UNRATE","string.label.y"],
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date())
    )
  )

# Document the residual as well
str_symbol.res <- "U3.lm.NPPTTL.by.CLF16OV__lm__POPTHM.res"
df.data[str_symbol.res] <- df.data$UNRATE - df.data[str_symbol]

# Add the U3 linear model model prediction residual to the symbols table
df.symbols <-
  rbind(
    df.symbols,
    data.frame(
      string.symbol = str_symbol.res,
      string.source = "Predict Resid.",
      string.description = "Linear Model Residual\nU3 given NPPTTL by POPTHM",
      string.label.y = df.symbols[df.symbols$string.symbol==str_symbol,"string.label.y"],
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date())
    )
  )

# Add KNN model prediction to the dataframe
str_symbol <- "U3.knn.NPPTTL.by.CLF16OV__lm__POPTHM"
df.data[str_symbol] <-
  predict(list.fit.knn.u3nppttl, newdata = df.data)

# Add the knn model prediction to the symbols table
df.symbols <-
  rbind(
    df.symbols,
    data.frame(
      string.symbol = str_symbol,
      string.source = "Predict",
      string.description = "KNN Prediction\nU3 given NPPTTL by POPTHM",
      string.label.y = df.symbols[df.symbols$string.symbol=="UNRATE","string.label.y"],
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date())
    )
  )

# Document the residual as well
str_symbol.res.knn <- "U3.knn.NPPTTL.by.CLF16OV__lm__POPTHM.res"
df.data[str_symbol.res.knn] <- df.data$UNRATE - df.data[str_symbol]

# Add the U3 knn model prediction residual to the symbols table
df.symbols <-
  rbind(
    df.symbols,
    data.frame(
      string.symbol = str_symbol.res.knn,
      string.source = "Predict Resid.",
      string.description = "KNN Residual\nU3 given NPPTTL by POPTHM",
      string.label.y = df.symbols[df.symbols$string.symbol==str_symbol,"string.label.y"],
      float.expense.ratio = -1.00,
      Max030 = FALSE,
      Max180 = FALSE,
      date.series.start = dt.start.prediction,
      date.series.end = as.Date(Sys.Date())
    )
  )
```

Look at how the fits performed on the test data partition

```{r U3.pred.NPPTTL.perf, echo=FALSE}

d.test.resid = (df.test$UNRATE - predict(list.fit.u3nppttl, newdata = df.test))
hist(d.test.resid, main=paste("Residual For", str_symbol.res, sep=" "))
sd.fit.u3nppttl = sd(d.test.resid)


d.test.resid.knn = (df.test$UNRATE - predict(list.fit.knn.u3nppttl, newdata = df.test))
hist(d.test.resid.knn, main=paste("Residual For", str_symbol.res.knn, sep=" "))
sd.fit.knn.u3nppttl = sd(d.test.resid.knn)
rm(list.fit.knn.u3nppttl)


```

The problem with ADP data is that it only goes back a few years so there really is not enough data. What there is does not have a linear relationship with the ADP numbers.

```{r U3.pred.NPPTTL.outlier, fig.width = 6, fig.asp = 1.0}

plot(df.emp.model$NPPTTL,
     df.emp.model$UNRATE,
     main = "ADP v. U3",
     xlab = "NPPTTL (ADP), Thousands",
     ylab = "UNRATE (U3), Percent")


plot( 100*( df.emp.model$CLF16OV__lm__POPTHM -  df.emp.model$NPPTTL ) / df.emp.model$CLF16OV__lm__POPTHM,
     df.emp.model$UNRATE,
     main = "ADP v. U3",
     xlab = "NPPTTL (ADP) normalized by labor force, Percent",
     ylab = "UNRATE (U3), Percent")

rm(df.emp.model)

```


Plot the measured U3 (UNRATE) to U3 predicted by a linear fit to NPPTTL normalized by labor force from POPTHM.

```{r U3.pred.NPPTTL.plot, echo=FALSE, fig.width = 10, fig.asp = .62}


datay <- "UNRATE"
datay_aux <- "U3.lm.NPPTTL.by.CLF16OV__lm__POPTHM"
ylim <- c(0, 15)
dt.end <- Sys.Date()
my_plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    "U3 Compared to U3 predicted using NPPTTL by POPTHM",
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start.prediction, dt.end),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my_plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay_aux,
    colour = shQuote(getPlotTitle(df.symbols, datay_aux))
  ),
  na.rm = TRUE
)

```

Zoom in a little. There is a lot of discussion about how valid the latest U3 numbers are.

```{r U3.pred.NPPTTL.plot.recent, echo=FALSE,, fig.width = 10, fig.asp = .62}


datay <- "UNRATE"
datay_aux <- "U3.lm.NPPTTL.by.CLF16OV__lm__POPTHM"
ylim <- c(0, 20)
dt.end <- Sys.Date()
dt.start <- as.Date("2020-01-01")
my_plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    "U3 Compared to U3 predicted using NPPTTL by POPTHM",
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, dt.end),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my_plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay_aux,
    colour = shQuote(getPlotTitle(df.symbols, datay_aux))
  ),
  na.rm = TRUE
)

```


Plot the residual for the U3 linear fit. The residuals decrease quite a bit during the Covid numbers, at least as of Jun 2020. Probably indicates uncertainty in the numbers.

```{r U3.pred.NPPTTL.resid, echo=FALSE,, fig.width = 6, fig.asp = .82}

datay <- "U3.lm.NPPTTL.by.CLF16OV__lm__POPTHM.res"
ylim <- c(-10, 10)
my_plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  getPlotTitle(df.symbols, datay),
  "Date",
  getPlotYLabel(df.symbols, datay),
  c(dt.start.prediction, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = TRUE,
  b.long.legend = FALSE
)

my_plot <- my_plot + geom_hline(yintercept=(6*sd.fit.u3nppttl), color = "red", linetype="dashed")
my_plot <- my_plot + geom_hline(yintercept=(-6*sd.fit.u3nppttl), color = "red", linetype="dashed")

print(my_plot)


```


### Correlation Summary

```{r cor.summ, echo=FALSE}

str.name <- c('U6 from U3','U3 from ICSA', 'U3 from CCSA', 'U3 from NPPTTL')
dt.list.start <- c(index(U6RATE[1]), index(ICSA[1]), index(CCSA[1]), index(NPPTTL[1]))
df.emp.cor <- data.frame("Relationship"=str.name, "Start Date"=as.Date(dt.list.start))

kable(df.emp.cor) %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  column_spec(column = 1, width = "1.5in; display: inline-block;") %>%
  column_spec(2, width = "10em")

```

