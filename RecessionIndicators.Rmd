---
title: "Recession Indicators"
author: "Brian Howard"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 4
    smart: false
---
```{r}
```


```{r}
```



```{r}

# ------------- Naming conventions ---------------------------------------------
# Minimal change (keep . for field, use __ for operations)
#
# Reserve exactly one . to separate symbol vs. field (e.g., X_GSPC.GSPC.Close,
# GDP.Value).
#
# Use double underscore __ to separate higher-level tokens (operations,
# transforms, right-hand series).
#
# Use single underscore _ inside tokens when you need internal separators.
#
# Examples:
#
# Binary op: GSPC.Close__SUB__SPY.Close
# Unary transform: GDP.Value__YOY
# Multi-step: GSPC.Close__SMA_20__SUB__SPY.Close__SMA_20
#
# Pros: minimal re-factor; your existing SYMBOL.FIELD parsing still works. 
#
# Cons: still uses dots in names (tidyverse style generally prefers
# underscores).
```

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options("getSymbols.warning4.0"=FALSE)
```

```{r libraries, echo=FALSE, message=FALSE}
library(tidyverse)
# What about tidyquant? Looks like it might replace some of the functions below.
# Look into piping: speed and performance improvement
# glimpse str
# quarto

library(UsingR)
library(quantmod)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tools)
library(zoo)
library(signal)
library(corrplot)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(Quandl)
library(nnet)
#library(devtools)
#install_github("andrewuhl/RollingWindow")
library(RollingWindow)

#library(devtools)
#devtools::install_github("jameelalsalam/eia2")
library(eia2)
#key <- "7a2672468131c5a95dffc487d741edf6"

library(gtable)
library(data.table)
library(readxl)
library(plotly)
#install.packages('coronavirus')
library(coronavirus)
library(lubridate)

```

```{r helper functions, echo=FALSE}

# Call helper functions
source("plotHelper.r")
source("utilSyms.r")

```

```{r RefreshFlag, echo=FALSE}

# Define the source of the data (local or web) and whether to update the models.
bRefresh = TRUE
b.refresh.models = FALSE
str.data.dir <- "C:/Users/Rainy/OneDrive/Documents/IssaquahDynamical/Datasets/2529RS0082_HistEconData"

```

```{r plot.limits, echo=FALSE}

# Define the plotting ranges
dt.recent = as.Date("2017-01-01")
dtStartBackTest = as.Date('1960-01-01')
ylimBackTest <- c(0, 120)
dt.start.prediction <- as.Date("01/02/1962", "%d/%m/%Y")

# Define trend limits
d.GSPC.max = 7000
d.Russell.max = 5000

```

# Introduction

For one of my machine learning classes we had a project that consumed financial data. I have extended that project to use machine learning to see if an indicator, or predictor, can be found that identifies market tops that occur prior to recessions. Then I use the model to build a trading strategy and backtest it to see how it performs.

# Get Economic and Financial Data

Acquiring the data consists of two steps. First the code pulls the data into zoo objects which are then collapsed into a single data frame (df.data). Features are extracted from these series and added to the df.data data frame.

## Sample call to pull economic data

Data is pulled from several sources include FRED, yahoo, and Google. The code below shows an example that pulls in the consumer price index (CPI) from the FRED. I pull data using quantmod, Quandl, and some manual extractions stored in spreadsheets. 


```{r defsyms, echo=FALSE}

## --- Save symbols_catalog.csv from the df.symbols dataframe -----------------
# Call code that defines the desired symbols.
# source("SymbolList.r")
# 
# catalog_path <- file.path(str.data.dir, "symbols_catalog.csv")
# tmp <- subset(df.symbols,
#               select = c(string.symbol,string.source,string.description,
#                          string.label.y,float.expense.ratio,
#                          date.series.start,date.series.end))
# # store \n literally so it’s one line per row in the CSV
# tmp$string.description <- gsub("\n", "\\\\n", tmp$string.description)
# write.csv(tmp, catalog_path, row.names = FALSE, na = "")


## --- Load symbols_catalog.csv into df.symbols -------------------------------

# Pick a path that exists in your project
catalog_path <- file.path(str.data.dir, "symbols_catalog.csv")

# Read CSV (prefer readr if available for strict types)
if (requireNamespace("readr", quietly = TRUE)) {
  df.symbols <- readr::read_csv(
    catalog_path,
    col_types = readr::cols(
      string.symbol       = readr::col_character(),
      string.source       = readr::col_character(),
      string.description  = readr::col_character(),
      string.label.y      = readr::col_character(),
      float.expense.ratio = readr::col_double(),
      date.series.start   = readr::col_date(format = ""),
      date.series.end     = readr::col_date(format = "")
    ),
    na = c("", "NA")
  ) |> as.data.frame(stringsAsFactors = FALSE)
} else {
  df.symbols <- read.csv(catalog_path, stringsAsFactors = FALSE, na.strings = c("", "NA"))
  # Coerce types
  if ("float.expense.ratio" %in% names(df.symbols))
    df.symbols$float.expense.ratio <- as.numeric(df.symbols$float.expense.ratio)
  for (nm in c("date.series.start","date.series.end"))
    if (nm %in% names(df.symbols)) df.symbols[[nm]] <- as.Date(df.symbols[[nm]])
}

# # Turn literal "\n" in CSV into real newlines for pretty printing
# if ("string.description" %in% names(df.symbols)) {
#   df.symbols$string.description <- gsub("\\\\n", "\n", df.symbols$string.description)
# }
# 
# # Add safe/object names if your CSV doesn’t already have them
# if (!"string.symbol_safe" %in% names(df.symbols)) {
#   safe_symbol_name <- function(sym) {
#     s <- make.names(sym, unique = TRUE)
#     s <- gsub("\\.", "_", s)
#     gsub("_+", "_", s)
#   }
#   df.symbols$string.symbol_safe <- safe_symbol_name(df.symbols$string.symbol)
#   df.symbols$string.object_name <- df.symbols$string.symbol_safe
# }

# quick sanity check
#str(df.symbols)
#head(df.symbols)



```

```{r getsymexample}
# Consumer Price Index for All Urban Consumers: All Items
if (bRefresh == TRUE) {
  getSymbols("CPIAUCSL", src = "FRED", auto.assign = TRUE)
}
```


```{r getsyms, echo=FALSE}

library(quantmod)

# ---- Utilities -------------------------------------------------------------

safe_symbol_name <- function(sym, prefer_underscore = TRUE, unique = TRUE) {
  
  stopifnot(is.character(sym))
  # 1) make syntactic and (optionally) unique
  s <- make.names(sym, unique = unique)
  
  # 2) prefer underscores over dots
  if (prefer_underscore) s <- gsub("\\.", "_", s)
  
  # 3) collapse multiple underscores (cosmetic)
  s <- gsub("_+", "_", s)
  
  # 4) extra safety: if a name *starts* with a digit, prefix an underscore
  # (make.names() would already prefix with 'X', but keep this in case prefer_underscore=FALSE is used)
  s <- sub("^([0-9])", "_\\1", s)
  
  s
}


escape_regex <- function(x) {
  gsub("([][{}()+*^$|\\\\?.])", "\\\\\\1", x)
}

# Fetch and standardize column names. Returns an xts.
fetch_symbol <- function(symbol,
                         src  = "yahoo",
                         from = as.Date("1900-01-01"),
                         to   = Sys.Date()) {
  x <- getSymbols(Symbols = symbol,
                  src = src,
                  auto.assign = FALSE,
                  from = from,
                  to   = to)

  cols <- colnames(x)
  safe <- safe_symbol_name(symbol)

  # Many sources (esp. Yahoo) return "<rawsym>.<Field>" column names.
  # Strip that raw prefix, safely escaped.
  prefix_pattern <- paste0("^", escape_regex(symbol), "\\.")
  core <- sub(prefix_pattern, "", cols, perl = TRUE)

  # Single-column series (e.g., FRED) -> SAFE.Value
  if (length(cols) == 1L) core <- "Value"

  colnames(x) <- paste0(safe, ".", core)
  x
}

# Ensure df.symbols has useful columns to update
ensure_df_symbols_cols <- function(df) {
  needed <- c("string.symbol_safe", "string.object_name",
              "status", "error", "nrows", "first_date", "last_date")
  for (nm in needed) if (!nm %in% names(df)) df[[nm]] <- NA_character_

  # Set expected types
  suppressWarnings({
    df$nrows <- as.integer(df$nrows)
    df$first_date <- as.Date(df$first_date)
    df$last_date  <- as.Date(df$last_date)
  })
  df
}

# ---- Main driver -----------------------------------------------------------

# Iterates rows of df.symbols, fetches each symbol, assigns to env with a safe name,
# and UPDATES the row with the safe name and fetch status.
update_symbols <- function(df.symbols,
                           target_env = .GlobalEnv,
                           from = as.Date("1900-01-01"),
                           to   = Sys.Date(),
                           replace_symbol_column = FALSE) {
  df <- ensure_df_symbols_cols(df.symbols)

  for (idx in seq_len(nrow(df))) {
    raw_sym <- as.character(df[idx, "string.symbol"])
    src     <- as.character(df[idx, "string.source"])
    safe    <- safe_symbol_name(raw_sym)
    obj     <- safe

    res <- tryCatch({
      x <- fetch_symbol(raw_sym, src = src, from = from, to = to)

      assign(obj, x, envir = target_env)

      nr <- nrow(x)
      # first/last non-all-NA dates
      non_empty_rows <- which(rowSums(!is.na(x)) > 0L)
      fdate <- if (length(non_empty_rows)) index(x)[non_empty_rows[1L]] else as.Date(NA)
      ldate <- if (length(non_empty_rows)) index(x)[non_empty_rows[length(non_empty_rows)]] else as.Date(NA)

      list(ok = TRUE, nr = nr, fdate = as.Date(fdate), ldate = as.Date(ldate), err = NA_character_)
    }, error = function(e) {
      list(ok = FALSE, nr = NA_integer_, fdate = as.Date(NA), ldate = as.Date(NA),
           err = conditionMessage(e))
    })

    # Update THIS ROW in df.symbols
    df[idx, "string.symbol_safe"] <- safe
    df[idx, "string.object_name"] <- obj
    df[idx, "status"]             <- if (res$ok) "ok" else "error"
    df[idx, "error"]              <- res$err
    df[idx, "nrows"]              <- res$nr
    df[idx, "first_date"]         <- res$fdate
    df[idx, "last_date"]          <- res$ldate
  }
  
  # Return the modified table, single exit so end with the value
  df
}

# ---- Main function ----------------------------------------------------------

# df.symbols is expected to have columns: string.symbol, string.source
# This assigns each fetched xts to a *safe* object name in the chosen environment.
ingest_symbols <- function(df.symbols, target_env = .GlobalEnv,
                           from = as.Date("1900-01-01"), to = Sys.Date()) {
  for (idx in seq_len(nrow(df.symbols))) {
    sym <- as.character(df.symbols[idx, "string.symbol"])
    src <- as.character(df.symbols[idx, "string.source"])
    print(sym)
    
    x <- fetch_symbol(sym, src, from = from, to = to)

    safe <- safe_symbol_name(sym)
    assign(safe, x, envir = target_env)
  }
  invisible(NULL)
}


if (bRefresh) {
  
  # Bring the data from the internet into this environment
  ingest_symbols(df.symbols)
  
  # Update the symbols table to include the safe names
  df.symbols <- update_symbols(df.symbols)
  
  # Correct errors in the data series
  for (idx in 1:nrow(df.symbols)) {

    # Revision - 26 Mar 22
    # Remove duplicate date values (believed to be a data source error)
    # Details in "Revision X in date.docx"
    assign(df.symbols[idx, "string.symbol_safe"], 
           get(df.symbols[idx, "string.symbol_safe"])[!duplicated (index(get(df.symbols[idx, "string.symbol_safe"]))), ])
    
    # Grab the series for some additional extractions
    xts.temp <- get(df.symbols[idx, "string.symbol_safe"])
    
    # Update the series start date
    df.symbols[idx, "date.series.start"] <- index(xts.temp[1])
    df.symbols[idx, "date.series.end"] <- index(tail(xts.temp, 1))
    
  }
  
}


```


```{r getQuandl, echo = FALSE}

# # This adds the Quandl symbols and pulls those in.
# 
# if(bRefresh) {
#   # There are a few symbols I wasn't able to include with quantmod so this section uses Quandl to get those data pieces.
#   
#   # Get the PMI composite index
#   str.symbol.raw <- "ISM/MAN_PMI"
#   df.symbols <-
#     rbind(
#       df.symbols,
#       data.frame(
#         string.symbol = str.symbol.raw,
#         string.source = "QUANDL",
#         string.description = "Institute of Supply Managment PMI Composite Index",
#         string.label.y = "Index",
#         float.expense.ratio = -1.00,
#         date.series.start = as.Date("1900-01-01")  ,
#         date.series.end = as.Date("1900-01-01")
#       )
#     )
#   # Set the API key
#   Quandl.api_key('d9LUhcBVPa_8MFdtiFda')
#   dfPMIComp <-
#     Quandl(
#       "ISM/MAN_PMI",
#       type = "raw",
#       collapse = "daily",
#       start_date = "1910-01-01",
#       end_date = Sys.Date()
#     )
#   str.name <-
#     str_replace_all(tail(df.symbols, 1)$string.symbol, "[^[:alnum:]]", "")
#   assign(str.name, xts(dfPMIComp[,-1], order.by = dfPMIComp[, 1]))
#   colnames(ISMMANPMI) <- c(str.name)
#   df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw, ]$date.series.start = tail(dfPMIComp$Date, 1)
#   df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw, ]$date.series.end = dfPMIComp$Date[[1]]
#   
#   # PE Ratio for the S&P 500
#   str.symbol.raw = "MULTPL/SP500_PE_RATIO_MONTH"
#   df.symbols <-
#     rbind(
#       df.symbols,
#       data.frame(
#         string.symbol = str.symbol.raw,
#         string.source = "QUANDL",
#         string.description =  "S&P 500 TTM P/E",
#         string.label.y = "Index",
#         float.expense.ratio = -1.00,
#         date.series.start = as.Date("1900-01-01")  ,
#         date.series.end = as.Date("1900-01-01")
#       )
#     )
#   df.temp <- Quandl(
#     str.symbol.raw,
#     type = "raw",
#     collapse = "daily",
#     start_date = "1910-01-01",
#     end_date = Sys.Date()
#   )
#   
#   str.name <-
#     str_replace_all(tail(df.symbols, 1)$string.symbol, "[^[:alnum:]]", "")
#   assign(str.name, xts(df.temp[, -1], order.by = df.temp[, 1]))
#   colnames(MULTPLSP500PERATIOMONTH) <- c(str.name)
#   df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw, ]$date.series.start = tail(df.temp$Date, 1)
#   df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw, ]$date.series.end = df.temp$Date[[1]]
#   
#   
#   # S&P 500 sales multiple
#   str.symbol.raw = "MULTPL/SP500_SALES_QUARTER"
#   df.symbols <-
#     rbind(
#       df.symbols,
#       data.frame(
#         string.symbol = str.symbol.raw,
#         string.source = "QUANDL",
#         string.description =  "S&P 500 TTM Sales\n(Not Inflation Adjusted)",
#         string.label.y = "Index",
#         float.expense.ratio = -1.00,
#         date.series.start = as.Date("1900-01-01")  ,
#         date.series.end = as.Date("1900-01-01")
#       )
#     )
#   df.temp <-
#     oil_daily <- Quandl(
#       str.symbol.raw,
#       type = "raw",
#       collapse = "daily",
#       start_date = "1910-01-01",
#       end_date = Sys.Date()
#     )
#   
#   str.name <-
#     str_replace_all(tail(df.symbols, 1)$string.symbol, "[^[:alnum:]]", "")
#   assign(str.name, xts(df.temp[, -1], order.by = df.temp[, 1]))
#   colnames(MULTPLSP500SALESQUARTER) <- c(str.name)
#   df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw, ]$date.series.start = tail(df.temp$Date, 1)
#   df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw, ]$date.series.end = df.temp$Date[[1]]
#   
#   
#   # S&P 500 Dividend ratio
#   str.symbol.raw = "MULTPL/SP500_DIV_YIELD_MONTH"
#   df.symbols <-
#     rbind(
#       df.symbols,
#       data.frame(
#         string.symbol = str.symbol.raw,
#         string.source = "QUANDL",
#         string.description =  "S&P 500 Dividend Yield by Month",
#         string.label.y = "Percentage",
#         float.expense.ratio = -1.00,
#         date.series.start = as.Date("1900-01-01") ,
#         date.series.end = as.Date("1900-01-01")
#       )
#     )
#   df.temp <-
#     oil_daily <- Quandl(
#       str.symbol.raw,
#       type = "raw",
#       collapse = "daily",
#       start_date = "1910-01-01",
#       end_date = Sys.Date()
#     )
#   
#   str.name <-
#     str_replace_all(tail(df.symbols, 1)$string.symbol, "[^[:alnum:]]", "")
#   assign(str.name, xts(df.temp[, -1], order.by = df.temp[, 1]))
#   colnames(MULTPLSP500DIVYIELDMONTH) <- c(str.name)
#   df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw, ]$date.series.start = tail(df.temp$Date, 1)
#   df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw, ]$date.series.end = df.temp$Date[[1]]
#   
#   # S&P 500 dividend yield
#   str.symbol.raw = "MULTPL/SP500_DIV_MONTH"
#   df.symbols <-
#     rbind(
#       df.symbols,
#       data.frame(
#         string.symbol = str.symbol.raw,
#         string.source = "QUANDL",
#         string.description =  "S&P 500 Dividend by Month \n (Inflation Adjusted)",
#         string.label.y = "2018 Dollars",
#         float.expense.ratio = -1.00,
#         date.series.start = as.Date("1871-01-01")  ,
#         date.series.end = as.Date("1900-01-01")
#       )
#     )
#   df.temp <-
#     Quandl(
#       str.symbol.raw,
#       type = "raw",
#       collapse = "daily",
#       start_date = "1871-01-01",
#       end_date = Sys.Date()
#     )
#   
#   str.name <-
#     str_replace_all(tail(df.symbols, 1)$string.symbol, "[^[:alnum:]]", "")
#   assign(str.name, xts(df.temp[,-1], order.by = df.temp[, 1]))
#   colnames(MULTPLSP500DIVMONTH) <- c(str.name)
#   df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.start = tail(df.temp$Date, 1)
#   df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.end = df.temp$Date[[1]]
#   
#   # Copper prices
#   str.symbol.raw = "CHRIS/CME_HG1"
#   df.symbols <-
#     rbind(
#       df.symbols,
#       data.frame(
#         string.symbol = str.symbol.raw,
#         string.source = "QUANDL",
#         string.description =  "Copper Futures, Continuous Contract #1 (HG1) \n(Front Month)",
#         string.label.y = "Dollars/pound",
#         float.expense.ratio = -1.00,
#         date.series.start = as.Date("1871-01-01")  ,
#         date.series.end = as.Date("1900-01-01")
#       )
#     )
#   df.temp <- Quandl(
#     str.symbol.raw,
#     type = "raw",
#     collapse = "daily",
#     start_date = "1871-01-01",
#     end_date = Sys.Date()
#   )
#   # Needed because this series include open, close, high, low, etc.
#   df.temp <-
#     df.temp[, (colnames(df.temp) == 'Open') |
#              (colnames(df.temp) == 'Date')]
#   # This series also has zero values. Not sure why, tho.
#   df.temp[df.temp == 0] = NA
#   str.name <-
#     str_replace_all(tail(df.symbols, 1)$string.symbol, "[^[:alnum:]]", "")
#   assign(str.name, xts(df.temp[, -1], order.by = df.temp[, 1]))
#   colnames(CHRISCMEHG1) <- c(str.name)
#   
#   # Air freight data
#   str.symbol.raw = "WWDI/WLD_IS_AIR_GOOD_MT_K1"
#   df.symbols <-
#     rbind(
#       df.symbols,
#       data.frame(
#         string.symbol = str.symbol.raw,
#         string.source = "QUANDL",
#         string.description =  "Air transport, freight",
#         string.label.y = "million ton-km",
#         float.expense.ratio = -1.00,
#         date.series.start = as.Date("1871-01-01") ,
#         date.series.end = as.Date("1900-01-01")
#       )
#     )
#   df.temp <- Quandl(
#     str.symbol.raw,
#     type = "raw",
#     collapse = "daily",
#     start_date = "1973-12-31",
#     end_date = Sys.Date()
#   )
#   
#   str.name <-
#     str_replace_all(tail(df.symbols, 1)$string.symbol, "[^[:alnum:]]", "")
#   assign(str.name, xts(df.temp[, -1], order.by = df.temp[, 1]))
#   colnames(WWDIWLDISAIRGOODMTK1) <- c(str.name)
#   
#   # Gold prices. site: https://data.nasdaq.com/data/LBMA/GOLD
#   str.symbol.raw = "LBMA/GOLD"
#   df.temp <- Quandl(
#     str.symbol.raw,
#     type = "raw",
#     collapse = "daily",
#     start_date = "1871-01-01",
#     end_date = Sys.Date()
#   )
#   
#   # Update the symbol table
#   df.symbols <-
#     rbind(
#       df.symbols,
#       data.frame(
#         string.symbol = str.symbol.raw,
#         string.source = "QUANDL",
#         string.description = "Gold Price: London Fixings,\nLondon Bullion Market Association (LBMA).\n",
#         string.label.y = "USD/ounce (PM)",
#         float.expense.ratio = -1.00,
#         date.series.start = as.Date("1871-01-01")  ,
#         date.series.end = as.Date("1900-01-01")
#       )
#     )
#   
#   # Make the name safe
#   str.name <- str_replace_all(tail(df.symbols, 1)$string.symbol, "[^[:alnum:]]", "")
# 
#   # Update the column names to include the ticker symbol. This triggers 
#   # unique handling later.
#   lst_cols <- colnames(df.temp)
#   lst_cols <- str_replace_all(lst_cols, " ", "")
#   lst_cols <- str_replace_all(lst_cols, "\\(", "_")
#   lst_cols <- str_replace_all(lst_cols, "\\)", "")
#   colnames(df.temp) <-
#     paste(str.name, ".", lst_cols , sep = "")
#   
#   # Create the xts object from the dataframe
#   assign(str.name, xts(df.temp[, -1], order.by = df.temp[, 1]))
# 
# }

```


## Load up the EIA data

```{r EIA data, echo=FALSE}

if (bRefresh){

  # key <- "7a2672468131c5a95dffc487d741edf6"
  Sys.setenv(EIA_KEY = "7a2672468131c5a95dffc487d741edf6")



  # Refiner Motor Gasoline Sales Volumes
    str.symbol.raw = "PET.A103600001.M"
    df.symbols <-
      rbind(
        df.symbols,
        data.frame(
          string.symbol = str.symbol.raw,
          string.source = "EIA",
          string.description =  "U.S. Total Gasoline Retail Sales by Refiners, Monthly",
          string.label.y = "Thousand Gallons per Day",
          float.expense.ratio = -1.00,
          date.series.start = as.Date("1900-01-01"),
          date.series.end = as.Date("1900-01-01"),
          string.symbol_safe = safe_symbol_name(str.symbol.raw),
          string.object_name = safe_symbol_name(str.symbol.raw),
          status = "ok",
          error = NA,
          nrows = 0,
          first_date = as.Date("1900-01-01"),
          last_date = as.Date("1900-01-01")
          
        )
      )

    
    # Define the table name and pull the data series from the EIA website
    str.name <- tail(df.symbols,1)[["string.symbol_safe"]]
    tlb.eia <- eia1_series( str.symbol.raw )
    
    # Convert the table to an xts object an and select the column we are interested in
    PET_A103600001_M <- xts( tlb.eia [,-1], order.by=as.Date(as.yearmon(tlb.eia[['period']])))
    PET_A103600001_M <- PET_A103600001_M[,9]
    colnames(PET_A103600001_M) <- c(str.name)
    # Revision - 26 Mar 2022, reference "Revision EIA Data Unambig.docx"
    df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.start = tail(index(get(str.name)), 1)
    df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.end = index(get(str.name))[[1]]

  # U.S. Regular Gasoline Retail Sales by Refiners, Monthly
    str.symbol.raw = "PET.A123600001.M"
    df.symbols <-
      rbind(
        df.symbols,
        data.frame(
          string.symbol = str.symbol.raw,
          string.source = "EIA",
          string.description =  "U.S. Regular Gasoline Retail Sales\nby Refiners, Monthly",
          string.label.y = "Thousand Gallons per Day",
          float.expense.ratio = -1.00,
          date.series.start = as.Date("1900-01-01") ,
          date.series.end = as.Date("1900-01-01"),
          string.symbol_safe = safe_symbol_name(str.symbol.raw),
          string.object_name = safe_symbol_name(str.symbol.raw),
          status = "ok",
          error = NA,
          nrows = 0,
          first_date = as.Date("1900-01-01"),
          last_date = as.Date("1900-01-01")
        )
      )

    # Define the table name and pull the data series from the EIA website
    str.name <- tail(df.symbols,1)[["string.symbol_safe"]]
    tlb.eia <- eia1_series( str.symbol.raw )
    
    # Convert the table to an xts object an and select the column we are interested in
    PET_A123600001_M <- xts( tlb.eia [,-1], order.by=as.Date(as.yearmon(tlb.eia[['period']])))
    PET_A123600001_M <- PET_A123600001_M[,9]
    colnames(PET_A123600001_M) <- c(str.name)

    # Revision - 26 Mar 2022, reference "Revision EIA Data Unambig.docx"
    df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.start = tail(index(get(str.name)), 1)
    df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.end = index(get(str.name))[[1]]

    # U.S. Gasoline Midgrade Bulk Sales (Volume) by Refiners, Monthly
    str.symbol.raw = "PET.A143B00001.M"
    df.symbols <-
      rbind(
        df.symbols,
        data.frame(
          string.symbol = str.symbol.raw,
          string.source = "EIA",
          string.description =  "U.S. Midgrade Gasoline Retail Sales\nby Refiners, Monthly",
          string.label.y = "Thousand Gallons per Day",
          float.expense.ratio = -1.00,
          date.series.start = as.Date("1900-01-01"),
          date.series.end = as.Date("1900-01-01"),
          string.symbol_safe = safe_symbol_name(str.symbol.raw),
          string.object_name = safe_symbol_name(str.symbol.raw),
          status = "ok",
          error = NA,
          nrows = 0,
          first_date = as.Date("1900-01-01"),
          last_date = as.Date("1900-01-01")
          )
      )

    # Define the table name and pull the data series from the EIA website
    str.name <- tail(df.symbols,1)[["string.symbol_safe"]]
    tlb.eia <- eia1_series( str.symbol.raw )
    
    # Convert the table to an xts object an and select the column we are interested in
    PET_A143B00001_M <- xts( tlb.eia [,-1], order.by=as.Date(as.yearmon(tlb.eia[['period']])))
    PET_A143B00001_M <- PET_A143B00001_M[,9]
    colnames(PET_A143B00001_M) <- c(str.name)

    # Revision - 26 Mar 2022, reference "Revision EIA Data Unambig.docx"
    df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.start = tail(index(get(str.name)), 1)
    df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.end = index(get(str.name))[[1]]

    # U.S. Premium Gasoline Bulk Sales (Volume) by Refiners, Monthly
    str.symbol.raw = "PET.A133B00001.M"
    df.symbols <-
      rbind(
        df.symbols,
        data.frame(
          string.symbol = str.symbol.raw,
          string.source = "EIA",
          string.description =  "U.S. Premium Gasoline Bulk Sales\n(Volume) by Refiners, Monthly",
          string.label.y = "Thousand Gallons per Day",
          float.expense.ratio = -1.00,
          date.series.start = as.Date("1900-01-01"),
          date.series.end = as.Date("1900-01-01"),
          string.symbol_safe = safe_symbol_name(str.symbol.raw),
          string.object_name = safe_symbol_name(str.symbol.raw),
          status = "ok",
          error = NA,
          nrows = 0,
          first_date = as.Date("1900-01-01"),
          last_date = as.Date("1900-01-01")
          )
      )

    # Define the table name and pull the data series from the EIA website
    str.name <- tail(df.symbols,1)[["string.symbol_safe"]]
    tlb.eia <- eia1_series( str.symbol.raw )
    
    # Convert the table to an xts object an and select the column we are interested in
    PET_A133B00001_M <- xts( tlb.eia [,-1], order.by=as.Date(as.yearmon(tlb.eia[['period']])))
    PET_A133B00001_M <- PET_A133B00001_M[,9]
    colnames(PET_A133B00001_M) <- c(str.name)    
    
    # Revision - 26 Mar 2022, reference "Revision EIA Data Unambig.docx"
    df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.start = tail(index(get(str.name)), 1)
    df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.end = index(get(str.name))[[1]]

    # Crude Oil and Natural Gas Rotary Rigs in Operation, Total, Monthly
    str.symbol.raw = "TOTAL.OGNRPUS.M"
    df.symbols <-
      rbind(
        df.symbols,
        data.frame(
          string.symbol = str.symbol.raw,
          string.source = "EIA",
          string.description =  "Crude Oil and Natural Gas Rotary Rigs in Operation, Total, Monthly",
          string.label.y = "Number of rigs",
          float.expense.ratio = -1.00,
          date.series.start = as.Date("1900-01-01") ,
          date.series.end = as.Date("1900-01-01"),
          string.symbol_safe = safe_symbol_name(str.symbol.raw),
          string.object_name = safe_symbol_name(str.symbol.raw),
          status = "ok",
          error = NA,
          nrows = 0,
          first_date = as.Date("1900-01-01"),
          last_date = as.Date("1900-01-01")
          )
      )

    # Define the table name and pull the data series from the EIA website
    str.name <- tail(df.symbols,1)[["string.symbol_safe"]]
    tlb.eia <- eia1_series( str.symbol.raw )
    
    # Convert the table to an xts object an and select the column we are interested in
    TOTAL_OGNRPUS_M <- xts( tlb.eia [,-1], order.by=as.Date(as.yearmon(tlb.eia[['period']])))
    TOTAL_OGNRPUS_M <- TOTAL_OGNRPUS_M[,3]
    colnames(TOTAL_OGNRPUS_M) <- c(str.name)    

    # Revision - 26 Mar 2022, reference "Revision EIA Data Unambig.docx"
    df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.start = tail(index(get(str.name)), 1)
    df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.end = index(get(str.name))[[1]]

    # Crude Oil Rotary Rigs in Operation, Monthly
    str.symbol.raw = "TOTAL.PANRPUS.M"
    df.symbols <-
      rbind(
        df.symbols,
        data.frame(
          string.symbol = str.symbol.raw,
          string.source = "EIA",
          string.description =  "Crude Oil Rotary Rigs in Operation, Monthly",
          string.label.y = "Number of rigs",
          float.expense.ratio = -1.00,
          date.series.start = as.Date("1900-01-01"),
          date.series.end = as.Date("1900-01-01"),
          string.symbol_safe = safe_symbol_name(str.symbol.raw),
          string.object_name = safe_symbol_name(str.symbol.raw),
          status = "ok",
          error = NA,
          nrows = 0,
          first_date = as.Date("1900-01-01"),
          last_date = as.Date("1900-01-01")
          )
      )

    # Define the table name and pull the data series from the EIA website
    str.name <- tail(df.symbols,1)[["string.symbol_safe"]]
    tlb.eia <- eia1_series( str.symbol.raw )
    
    # Convert the table to an xts object an and select the column we are interested in
    TOTAL_PANRPUS_M <- xts( tlb.eia [,-1], order.by=as.Date(as.yearmon(tlb.eia[['period']])))
    TOTAL_PANRPUS_M <- TOTAL_PANRPUS_M[,3]
    colnames(TOTAL_PANRPUS_M) <- c(str.name)    

    # Revision - 26 Mar 2022, reference "Revision EIA Data Unambig.docx"
    df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.start = tail(index(get(str.name)), 1)
    df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.end = index(get(str.name))[[1]]

    # Natural Gas Rotary Rigs in Operation, Monthly
    str.symbol.raw = "TOTAL.NGNRPUS.M"
    df.symbols <-
      rbind(
        df.symbols,
        data.frame(
          string.symbol = str.symbol.raw,
          string.source = "EIA",
          string.description =  "Natural Gas Rotary Rigs in Operation, Monthly",
          string.label.y = "Number of rigs",
          float.expense.ratio = -1.00,
          date.series.start = as.Date("1900-01-01") ,
          date.series.end = as.Date("1900-01-01"),
          string.symbol_safe = safe_symbol_name(str.symbol.raw),
          string.object_name = safe_symbol_name(str.symbol.raw),
          status = "ok",
          error = NA,
          nrows = 0,
          first_date = as.Date("1900-01-01"),
          last_date = as.Date("1900-01-01")
          )
      )

    # Define the table name and pull the data series from the EIA website
    str.name <- tail(df.symbols,1)[["string.symbol_safe"]]
    tlb.eia <- eia1_series( str.symbol.raw )
    
    # Convert the table to an xts object an and select the column we are interested in
    TOTAL_NGNRPUS_M <- xts( tlb.eia [,-1], order.by=as.Date(as.yearmon(tlb.eia[['period']])))
    TOTAL_NGNRPUS_M <- TOTAL_NGNRPUS_M[,3]
    colnames(TOTAL_NGNRPUS_M) <- c(str.name)    

    # Revision - 26 Mar 2022, reference "Revision EIA Data Unambig.docx"
    df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.start = tail(index(get(str.name)), 1)
    df.symbols[df.symbols[, "string.symbol"] == str.symbol.raw,]$date.series.end = index(get(str.name))[[1]]

}

```

## Load rig count data

The Baker Hughes rig count numbers

```{r bkr.rig.count.load, echo=FALSE}

if(bRefresh){
  
  # Manually change dirs for testing
  #setwd('C:/Users/Rainy/OneDrive/Documents/Hobby/GitHub/Economics')
  
  # Read in the data
  df.rig.raw <- data.frame(read_excel('North America Rotary Rig Count (Jan 2000 - Current).xlsx', sheet = "US Oil & Gas Split", skip=5))
  df.rig.raw$Date <- as.Date(df.rig.raw$Date)
  
  # Create the zoo object for total rig count
  str.symbol <- 'BKR/Total'
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "BKR",
        string.description =  "Total Rig Count",
        string.label.y = "Number of rigs",
        float.expense.ratio = -1.00,
        date.series.start = df.rig.raw$Date[[1]] ,
        date.series.end = tail(df.rig.raw$Date, 1),
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
        )
    )
  
  # Process the total rig count
  str.safe.name <- tail(df.symbols,1)[["string.symbol_safe"]]
  assign(str.safe.name, xts(df.rig.raw$Total, order.by = df.rig.raw$Date))
  colnames(BKR_Total)[[1]] <- c(str.safe.name)
  
  # Create the zoo object for gas rig count
  str.symbol <- 'BKR/Gas'
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "BKR",
        string.description =  "Gas Rig Count",
        string.label.y = "Number of rigs",
        float.expense.ratio = -1.00,
        date.series.start = tail(df.rig.raw$Date, 1) ,
        date.series.end = df.rig.raw$Date[[1]],
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
        )
    )
  
  # Process the total gas rig count
  str.safe.name <- tail(df.symbols,1)[["string.symbol_safe"]]
  assign(str.safe.name, xts(df.rig.raw$Gas, order.by = df.rig.raw$Date))
  colnames(BKR_Gas)[[1]] <- c(str.safe.name)
  
  # Create the zoo object for oil rig count
  str.symbol <- 'BKR/Oil'
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "BKR",
        string.description =  "Oil Rig Count",
        string.label.y = "Number of rigs",
        float.expense.ratio = -1.00,
        date.series.start = tail(df.rig.raw$Date, 1) ,
        date.series.end = df.rig.raw$Date[[1]],
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
        )
    )
  
  # Process the total gas rig count
  str.safe.name <-tail(df.symbols,1)[["string.symbol_safe"]]
  assign(str.safe.name, xts(df.rig.raw$Oil, order.by = df.rig.raw$Date))
  colnames(BKR_Oil)[[1]] <- c(str.safe.name)

}

```

## USDA data

Loading in farm data

```{r farm.income, echo=FALSE}

if(bRefresh){
  
  # Get farm income data. From USDA website:
  # https://www.ers.usda.gov/data-products/farm-income-and-wealth-statistics/data-files-us-and-state-level-farm-income-and-wealth-statistics/
  
  # Read in th Excel file
  df.farm.income <- data.frame(read_excel('farmsectorindicators.xlsx', range='Sheet1!A2:I28'))
  
  # Extract the income and dates
  i.cols <- ncol(df.farm.income)
  d.income <- as.numeric(tail(df.farm.income,1)[2:i.cols])
  
  dt.date <- as.numeric(df.farm.income[3,2:i.cols])
  dt.date[(i.cols-1)] <- dt.date[i.cols-2] + 1
  # Have to append the day, otherwise it crashes on leap year.
  dt.date.c <- paste(as.character(dt.date), "-01-01", sep="")
  dt.date <- as.Date(dt.date.c)
  
  # Create the XTS object and update the symbols table
  str.symbol <- 'FARMINCOME'
  assign(str.symbol, xts(x=d.income, order.by=dt.date))
  colnames(FARMINCOME) <- "FARMINCOME"
  
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "USDA",
        string.description =  "Net Farm Income",
        string.label.y = "Billions of Dollars",
        float.expense.ratio = -1.00,
        date.series.start = dt.date[1],
        date.series.end = tail(dt.date,1),
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
      )
    )
}

```

Loading in Silverblatt's S&P 500 spreadsheet starting with the quarterly data.

```{r silverblatt.data, echo=FALSE}

if(bRefresh){
  
  # Get S&P 500 Silverblatt data. From USDA website:
  # https://us.spindices.com/documents/additional-material/sp-500-eps-est.xlsx
  
  # Read in th Excel file, starting with the quarterly data
  df.silverblatt <- data.frame(read_excel('sp-500-eps-est.xlsx', range='QUARTERLY DATA!A7:I147'))
  
  # Human readable column names
  colnames(df.silverblatt) <-
    c(
      "QUARTER.END",
      "OP.EARNINGS.PER.SHARE",
      "AR.EARNINGS.PER.SHARE",
      "CASH.DIVIDENDS.PER.SHR",
      "SALES.PER.SHR",
      "BOOKVAL.PER.SHR",
      "CAPEX.PER.SHR",
      "PRICE",
      "DIVISOR"
    )
  
  # Re-cast the dates characters as datetime values
  df.silverblatt$QUARTER.END <-
    as.Date(df.silverblatt$QUARTER.END, "%m/%d/%Y", tz = 'America/Los_Angeles')
  
  # Create the XTS object and update the symbols table for operating earnings
  str.symbol <- 'OPEARNINGSPERSHARE'
  assign(str.symbol, xts(x=df.silverblatt$OP.EARNINGS.PER.SHARE, order.by=df.silverblatt$QUARTER.END))
  colnames(OPEARNINGSPERSHARE) <- "OPEARNINGSPERSHARE"
  
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "SILVERBLATT",
        string.description =  "Operating Earnings per Share",
        string.label.y = "Dollars",
        float.expense.ratio = -1.00,
        date.series.start = tail(df.silverblatt$QUARTER.END,1),
        date.series.end = df.silverblatt$QUARTER.END[1],
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
      )
    )
  
  # Create the XTS object and update the symbols table for as reported earnings
  str.symbol <- 'AREARNINGSPERSHARE'
  assign(str.symbol, xts(x=df.silverblatt$AR.EARNINGS.PER.SHARE, order.by=df.silverblatt$QUARTER.END))
  colnames(AREARNINGSPERSHARE) <- "AREARNINGSPERSHARE"
  
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "SILVERBLATT",
        string.description =  "As-Reported Earnings per Share",
        string.label.y = "Dollars",
        float.expense.ratio = -1.00,
        date.series.start = tail(df.silverblatt$QUARTER.END,1),
        date.series.end = df.silverblatt$QUARTER.END[1],
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
      )
    )
  
  # Create the XTS object and update the symbols table for cash dividends
  str.symbol <- 'CASHDIVIDENDSPERSHR'
  assign(str.symbol, xts(x=df.silverblatt$CASH.DIVIDENDS.PER.SHR, order.by=df.silverblatt$QUARTER.END))
  colnames(CASHDIVIDENDSPERSHR) <- "CASHDIVIDENDSPERSHR"
  
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "SILVERBLATT",
        string.description =  "Cash Dividends per Share",
        string.label.y = "Dollars",
        float.expense.ratio = -1.00,
        date.series.start = tail(df.silverblatt$QUARTER.END,1),
        date.series.end = df.silverblatt$QUARTER.END[1],
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
      )
    )
  
  # Create the XTS object and update the symbols table for sales per share
  str.symbol <- 'SALESPERSHR'
  assign(str.symbol, xts(x=df.silverblatt$SALES.PER.SHR, order.by=df.silverblatt$QUARTER.END))
  colnames(SALESPERSHR) <- "SALESPERSHR"
  
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "SILVERBLATT",
        string.description =  "Sales per Share",
        string.label.y = "Dollars",
        float.expense.ratio = -1.00,
        date.series.start = tail(df.silverblatt$QUARTER.END,1),
        date.series.end = df.silverblatt$QUARTER.END[1],
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
      )
    )
  
  # Create the XTS object and update the symbols table for book value per share
  str.symbol <- 'BOOKVALPERSHR'
  assign(str.symbol, xts(x=df.silverblatt$BOOKVAL.PER.SHR, order.by=df.silverblatt$QUARTER.END))
  colnames(BOOKVALPERSHR) <- "BOOKVALPERSHR"
  
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "SILVERBLATT",
        string.description =  "Book value per Share",
        string.label.y = "Dollars",
        float.expense.ratio = -1.00,
        date.series.start = tail(df.silverblatt$QUARTER.END,1),
        date.series.end = df.silverblatt$QUARTER.END[1],
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
      )
    )
  
  
  # Create the XTS object and update the symbols table for cap ex per share
  str.symbol <- 'CAPEXPERSHR'
  assign(str.symbol, xts(x=df.silverblatt$CAPEX.PER.SHR, order.by=df.silverblatt$QUARTER.END))
  colnames(CAPEXPERSHR) <- "CAPEXPERSHR"
  
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "SILVERBLATT",
        string.description =  "Cap ex per Share",
        string.label.y = "Dollars",
        float.expense.ratio = -1.00,
        date.series.start = tail(df.silverblatt$QUARTER.END,1),
        date.series.end = df.silverblatt$QUARTER.END[1],
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
      )
    )
  
  # Create the XTS object and update the symbols table for price
  str.symbol <- 'PRICE'
  assign(str.symbol, xts(x=df.silverblatt$PRICE, order.by=df.silverblatt$QUARTER.END))
  colnames(PRICE) <- "PRICE"
  
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "SILVERBLATT",
        string.description =  "Price",
        string.label.y = "Dollars",
        float.expense.ratio = -1.00,
        date.series.start = tail(df.silverblatt$QUARTER.END,1),
        date.series.end = df.silverblatt$QUARTER.END[1],
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
      )
    )

}

```

Now load in the estimates

```{r silverblatt.est, echo=FALSE}
if(bRefresh){
  
  # Read in th Excel file, now for the estimates
  df.silverblatt.act <-
    data.frame(read_excel(
      'sp-500-eps-est.xlsx',
      range = 'ESTIMATES&PEs!A133:J273',
      col_types = c(
        "date",
        "numeric",
        "numeric",
        "numeric",
        "numeric",
        "numeric",
        "numeric",
        "numeric",
        "numeric",
        "numeric"
      )
    ))

  # Human readable column names
  colnames(df.silverblatt.act) <-
    c(
      "QUARTER.END",
      "PRICE",
      "OP.EARNINGS.PER.SHARE",
      "AR.EARNINGS.PER.SHARE",
      "EMPTY",
      "OP.EARNINGS.PE",
      "AR.EARNINGS.PE",
      "EMPTY1",
      "OP.EARNINGS.12.MONTH",
      "AR.EARNINGS.12.MONTH"
    )
  

  # Re-cast the dates characters as datetime values
  df.silverblatt.act$QUARTER.END <-
    as.Date(df.silverblatt.act$QUARTER.END, "%m/%d/%Y", tz = 'America/Los_Angeles')

  # Create the XTS object and update the symbols table for trailing 12-month operating earnings
  str.symbol <- 'OPEARNINGSTTM'
  assign(str.symbol, xts(x=df.silverblatt.act$OP.EARNINGS.12.MONTH, order.by=df.silverblatt.act$QUARTER.END))
  colnames(OPEARNINGSTTM) <- "OPEARNINGSTTM"
  
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "SILVERBLATT",
        string.description =  "TTM Operating Earnings",
        string.label.y = "Dollars",
        float.expense.ratio = -1.00,
        date.series.start = tail(df.silverblatt.act$QUARTER.END,1),
        date.series.end = df.silverblatt.act$QUARTER.END[1],
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
      )
    )
  
  str.symbol <- 'AREARNINGSTTM'
  assign(str.symbol, xts(x=df.silverblatt.act$AR.EARNINGS.12.MONTH, order.by=df.silverblatt.act$QUARTER.END))
  colnames(AREARNINGSTTM) <- "AREARNINGSTTM"
  
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "SILVERBLATT",
        string.description =  "TTM Reported Earnings",
        string.label.y = "Dollars",
        float.expense.ratio = -1.00,
        date.series.start = tail(df.silverblatt.act$QUARTER.END,1),
        date.series.end = df.silverblatt.act$QUARTER.END[1],
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
      )
    )
}

```


```{r margin.debt.load, echo=FALSE}
if(bRefresh){
  
  # Manually change dirs for testing
  #setwd('C:/Users/Rainy/OneDrive/Documents/Hobby/GitHub/Economics')
  
  # Read in the data
  df.margin <- data.frame(read_excel('MarginData.xlsx'))
  df.margin$Date <- as.Date(df.margin$Date)
  list.margin.names <- names(df.margin)
  
  # Create the zoo object for margin debt
  str.symbol <- 'FINRA/MarginDebt'
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "FINRA",
        string.description =  "Margin Debt",
        string.label.y = "Dollars",
        float.expense.ratio = -1.00,
        date.series.start = tail(df.margin$Date, 1) ,
        date.series.end = df.margin$Date[[1]],
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
      )
    )
  
  # Process the margin debt
  str.safe.name <-tail(df.symbols,1)[["string.symbol_safe"]]
  assign(str.safe.name, xts(df.margin[, 8], order.by = df.margin[, 1]))
  colnames(FINRA_MarginDebt)[[1]] <- c(str.safe.name)
  
  
  # Create the zoo object for free credit in margin
  str.symbol <- 'FINRA/FreeCreditMargin'
  df.symbols <-
    rbind(
      df.symbols,
      data.frame(
        string.symbol = str.symbol,
        string.source = "FINRA",
        string.description =  "Free Credit Balances in Customers' Securities Margin Accounts",
        string.label.y = "Dollars",
        float.expense.ratio = -1.00,
        date.series.start = tail(df.margin$Date, 1)  ,
        date.series.end = as.Date("1900-01-01"),
        string.symbol_safe = safe_symbol_name(str.symbol),
        string.object_name = safe_symbol_name(str.symbol),
        status = "ok",
        error = NA,
        nrows = 0,
        first_date = as.Date("1900-01-01"),
        last_date = as.Date("1900-01-01")
      )
    )
  
  # Process the free credit in margin
  str.safe.name <- tail(df.symbols,1)[["string.symbol_safe"]]
  assign(str.safe.name, xts(df.margin[, 10], order.by = df.margin[, 1]))
  colnames(FINRA_FreeCreditMargin)[[1]] <- c(str.safe.name)

}

```


```{r options.volume, echo=FALSE }

if(bRefresh){
  
# Tracking option volume. Data is freely avaliable from OCC at https://www.theocc.com/webapps/historical-volume-query. 

# Manually change dirs for testing
#setwd('H:/Documents/Hobby/GitHub/Economics')

# Read in the data
df.options <- data.frame(read_excel('volstat-annual.xlsx'))
df.options$Date <- as.Date(df.options$Date)
df.options$Equity.Volume <- df.options$Equity.Volume/1000000
df.options$Non.Equity.Volume <- df.options$Non.Equity.Volume/1000000
list.options.names <- names(df.options)

# Create the symbols table for the equity volumes
str.symbol <- 'OCC/EquityVolume'

# Update the symbols table    
df.symbols <- symbols_append_row(
  df.symbols,
  list(
      string.symbol = str.symbol,
      string.source = "OCC",
      string.description =  "Equity Options Volume",
      string.label.y = "Millions of Options/Day",
      float.expense.ratio = -1.00,
      date.series.start = tail(df.options$Date, 1) ,
      date.series.end = df.options$Date[[1]],
      string.symbol_safe = safe_symbol_name(str.symbol),
      string.object_name = safe_symbol_name(str.symbol),
      status = "ok",
      error = NA,
      nrows = 0,
      first_date = as.Date("1900-01-01"),
      last_date = as.Date("1900-01-01")
  )
)

# Process the options equity volume, create the zoo object
str.safe.name <- tail(df.symbols,1)[["string.symbol_safe"]]
assign(str.safe.name, xts(df.options[, 2], order.by = df.options[, 1]))
colnames(OCC_EquityVolume)[[1]] <- c(str.safe.name)


#-------------- Create symbols table for non-equity margin ---------------------
str.symbol <- 'OCC/NonEquityVolume'

# Update the symbols table    
df.symbols <- symbols_append_row(
  df.symbols,
  list(
    string.symbol = str.symbol,
    string.source = "OCC",
    string.description =  "Non-Equity Options Volume",
    string.label.y = "Millions of Options/Day",
    date.series.start = tail(df.options$Date, 1) ,
    float.expense.ratio = -1.00,
    date.series.end = df.options$Date[[1]],
    string.symbol_safe = safe_symbol_name(str.symbol),
    string.object_name = safe_symbol_name(str.symbol)
  )
)

# Process the options equity volume, create the zoo object
str.safe.name <- tail(df.symbols,1)[["string.symbol_safe"]] 
assign(str.safe.name, xts(df.options[, 3], order.by = df.options[, 1]))
colnames(OCC_NonEquityVolume)[[1]] <- c(str.safe.name)

}

```


```{r SaveData, echo=FALSE}

# Either save or load data depending on the flag
out.file <- file.path(str.data.dir, "RecessionIndicator_Buffer.RData")

if( bRefresh ){
  
  save.image(out.file)
  
}else{

  load(out.file)
  
}

```

## Feature Extraction

With the raw data downloaded, some of the interesting features can be extracted. The first step is reconcile the time intervals. Some of the data is released monthly and some daily. I chose to interpolate all data to a daily interval. The first section of code adds the daily rows to the dataframe. 

The code performs interpolation for continuous data or carries it forward for binary data like the recession indicators.

```{r aggsyms}

source("calcInterpolate.r")
df.data <- calcInterpolate(df.symbols)

```

## Truncate data

```{r data.trunc, echo=FALSE}

# A very few data series do go back to 1854, but most
# don't even go past WWII so truncate the dataframe
df.data <- df.data[as.Date(rownames(df.data)) > as.Date("1950-01-01"),]

```


## Create aggregate series

Some analysis requires that two or more series be combined. For example, normalizing debt by GDP to get a sense of the proportion of debt to the total economy helps understand the debt cycle.

```{r create aggregate, echo=FALSE}

source("calcAggregateSeries.r")

```

Year over year, smoothed derivative, and log trends tend to smooth out seasonal variation. It gets used so often that I do this for every series downloaded.

```{r calcsYoYSmoothLog}

source("calcFeatures.r")
lst.df <- calcFeatures(df.data, df.symbols)
df.data <- lst.df[[1]]
df.symbols <- lst.df[[2]]
```


```{r calc.features.for.aggregate, echo=FALSE}

# Calculate the features for the aggregated series
source("calcFeaturesAggregate.r")

```

# Recession calculations

```{r calc.recession, echo=FALSE}

source("calcRecession.r")

```

# Document the final data frame

```{r create.data.dictionary, echo=FALSE}

## ---- Build data dictionary with descriptions from the symbols table ----

# 1) Base dictionary
df.dict <- data.frame(
  column     = names(df.data),
  type       = sapply(df.data, function(x) paste(class(x), collapse = ",")),
  n_missing  = sapply(df.data, function(x) sum(is.na(x))),
  example    = sapply(df.data, function(x) paste(head(na.omit(unique(x)), 3), collapse = ", ")),
  stringsAsFactors = FALSE
)

# 2) Derive the *root* symbol from each df.data column:
#    drop only the final ".<Field>" so "BRK.B.Adjusted" -> "BRK.B"
root_symbol <- sub("\\.[^.]*$", "", df.dict$column)

# Does the raw ticker symbol exist in df.symbols? Only in the case where it does
# not exist try the root symbol.
for ( idx in seq_along(root_symbol)){ 
  if( df.dict$column[[idx]] %in% df.symbols$string.symbol){
    root_symbol[[idx]] <- safe_symbol_name(df.dict$column[[idx]])  
  }
}
df.dict$string.symbol_root <- root_symbol

# 3) Pick the symbols table and validate required columns
sym_tbl <- if (exists("dt.symbols")) dt.symbols else if (exists("df.symbols")) df.symbols else NULL

if (!is.null(sym_tbl)) {
  needed <- c("string.symbol_safe", "string.description")
  missing <- setdiff(needed, names(sym_tbl))
  if (length(missing)) {
    stop("Symbols table is missing columns: ", paste(missing, collapse = ", "))
  }

  # 4) Build a name -> description map and attach descriptions
  desc_map <- setNames(
    as.character(sym_tbl$string.description),
    as.character(sym_tbl$string.symbol_safe)
  )
  df.dict$string.description <- unname(desc_map[df.dict$string.symbol_root])
} else {
  # No symbols table available; leave descriptions as NA
  df.dict$string.description <- NA_character_
}

# ---- Write dictionary ----
out.file <- file.path(str.data.dir, "data_dictionary.csv")

write.csv(df.dict, out.file, row.names = TRUE)

# Cleanup
rm(df.dict)
rm(out.file)


```


# Summary calculations

These values are used below

# Conclusion

In this worksheet a model predicting the onset of recession was built. From the model a trading rule was derived to allow back testing. The model performed well and the trading rule backtesting showed that applying this in the post-WWII period would have resulted in an increase in returns. That is not too bad, but there are a few changes that would likely improve the model:

- Go long on short term bonds, rather than just roll out of the market. That way at least some returns would be generated during recessions.
- Refine the recession indicator. 

## Market Conditions

```{r old.code}

#The model is predicting a `r paste(sprintf("%3.0f", tail(df.data$recession.initiation.smooth.avg,1)[[1]]*100), "%", sep="")` chance of recession in the next 12 months. :

#- P/E ratio of `r sprintf("%3.2f", tail(df.data$MULTPLSP500PERATIOMONTH,1))` compares to a historical mean value over the last decade of `r sprintf("%3.2f", df.data$MULTPLSP500PERATIOMONTH_Mean[1])`. Since 2008 recession P/E has only fallen below historical norm a few times. The current value is high, but well off the peaks. If earnings are +2-4% year-over-year then it is not unrealistic.

```

<!-- As of Feb 2020 we have entered a recession as defined by the NBER yet the market continues to rise. -->

<!-- P/E ratio of `r sprintf("%3.2f", tail(df.data$MULTPLSP500PERATIOMONTH,1))` compares to a historical mean value over the last decade of `r sprintf("%3.2f", df.data$MULTPLSP500PERATIOMONTH_Mean[1])`. Since 2008 recession P/E has only fallen below historical norm a few times. The current value is high, but well off the peaks. If earnings are +2-4% year-over-year then it is not unrealistic. -->


```{r bullet1, echo = FALSE}
# datay <- "MULTPLSP500PERATIOMONTH"
# datay.aux <- "MULTPLSP500PERATIOMONTH_Mean"
# ylim <- c(10, 50)
# dt.start <- as.Date('2010-01-01')
# b.legend <- TRUE
# my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
#             getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, b.legend)
# my.plot + geom_line(data=df.data, aes_string(x="date", y=datay.aux, colour=shQuote(datay.aux)), na.rm = TRUE)
```

- S&P 500 Volume, last updated on `r index(tail(X_GSPC,1))`, is `r getTrendString(df.data, 'X_GSPC.GSPC.Volume', 365)` over the last year and `r getTrendString(df.data, 'X_GSPC.GSPC.Volume', 30)` over the last month. 


```{r bullet2, echo=FALSE}
datay.input = "X_GSPC.GSPC.Volume"
datay_aux <- "GSG__Close__by__GSPC__Close__mva050"
datay_aux2 <- "GSG__Close__by__GSPC__Close__mva200"
my.plot <- plotSingle(dfRecession, df.data, "date", 
                      datay = datay.input, 
                      getPlotTitle(df.symbols, datay.input), "Date", 
                      getPlotYLabel(df.symbols, datay.input), 
                      c(as.Date('2017-01-01'), Sys.Date()), 
                      ylim = c(1000000000, 8000000000), 
                      b.legend = TRUE)
my.plot <- my.plot + geom_line(data=df.data, 
                               aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)
my.plot <- my.plot + geom_line(data=df.data, 
                               aes_string(x="date", y=datay_aux2, colour=shQuote(datay_aux2)), na.rm = TRUE)
my.plot

# Tidy memory
rm(datay.input)
rm(datay_aux)
rm(datay_aux2)
rm(my.plot)

```

## Unemployment 

- Headline unemployment (U-3) stands at `r paste(sprintf("%3.2f", tail(df.data$UNRATE.Value,1)),"%", sep="")` (last updated on `r index(tail(UNRATE,1))`) which is near the 1-year average of `r paste(sprintf("%3.2f",mean(tail(df.data$UNRATE.Value, 365))),"%",sep="")` and rising with respect to the low in the last twelve months of `r paste(sprintf("%3.2f", min(tail(UNRATE,12))),"%",sep="")`. Unlikely the rate will drop again. 

```{r bullet3, echo=FALSE}

datay.input = "UNRATE.Value" 
plotSingle(dfRecession, df.data, "date", datay = datay.input, 
           getPlotTitle(df.symbols, datay.input), "Date", 
           getPlotYLabel(df.symbols, datay.input), 
           c(as.Date('2010-01-01'), Sys.Date()), 
           ylim =  c(2.5, 15),
           b.legend = TRUE)

# Tidy up memory
rm(datay.input)

```



- Payrolls (BLS data, NSA) year-over-year stands at `r paste(sprintf("%3.2f", tail(df.data$PAYNSA.Value__YoY,1)),"%", sep="")` which is above the 1-year average of `r paste(sprintf("%3.2f",mean(tail(df.data$PAYNSA.Value__YoY, 365))),"%",sep="")` and falling with respect to the peak, in the last twelve months, of `r paste(sprintf("%3.2f", max(tail(df.data$PAYNSA.Value__YoY,365))),"%",sep="")`.  

```{r bullet4, echo=FALSE}

datay.input = "PAYNSA.Value__YoY" 
plotSingle(dfRecession, df.data, "date", datay = datay.input, 
           getPlotTitle(df.symbols, datay.input), "Date", 
           getPlotYLabel(df.symbols, datay.input), 
           c(as.Date('2010-01-01'), Sys.Date()), 
           ylim = c(-12.5, 12.5), b.legend = TRUE,
           b.percentile = FALSE)

# Tidy up memory
rm(datay.input)

```

- Jobless claims (ICSA data) year-over-year stands at `r paste(sprintf("%3.2f", tail(df.data$ICSA.Value__YoY,1)),"%", sep="")` (last updated on `r index(tail(ICSA,1))`) which is in-line with the 1-year average of `r paste(sprintf("%3.2f", mean(tail(df.data$ICSA.Value__YoY, 365))),"%",sep="")` and below the peak, in the last twelve months, of `r paste(sprintf("%3.2f", max(tail(df.data$ICSA.Value__YoY,365))),"%",sep="")`. 

```{r bullet5, echo=FALSE}

datay.input <- "ICSA.Value__YoY"
ylim <- c(-150, 120)
dt.start <- as.Date('2010-01-01')
b.percentile <- TRUE
b.legend <- FALSE
plotSingleQuick(dfRecession, df.data, datay = datay.input, ylim, dt.start, b.legend, b.percentile)

# Tidy memory
rm(datay.input)
rm(ylim)
rm(b.legend)
rm(b.percentile)
rm(dt.start)
   
```

## Personal Income

- Real personal income year over year growth stands at `r paste(sprintf("%3.2f", tail(df.data$W875RX1.Value__YoY,1)),"%", sep="")` (last updated on `r df.symbols[df.symbols$string.symbol == 'W875RX1.Value__YoY',]$date.series.end`). This is below the recent peak of `r paste(sprintf("%3.2f", max(tail(df.data$W875RX1.Value__YoY,365))),"%",sep="")`.

```{r bullet6, echo=FALSE}

datay.input <- "W875RX1.Value__YoY"
ylim <- c(-7.5, 9.5)
dt.start <- as.Date('2010-01-01')
b.legend <- FALSE
b.percentile <- TRUE
plotSingleQuick(dfRecession, df.data, datay = datay.input, ylim, dt.start, b.legend, b.percentile)

# Tidy memory
rm(datay.input)
rm(ylim)
rm(b.legend)
rm(b.percentile)
rm(dt.start)

```


## Yield Curve and Bond Market

- The 10-year to 3-month yield stands at `r paste(sprintf("%3.2f", tail(df.data$DGS10TODTB3,1)),"%", sep="")` (last updated on `r df.symbols[df.symbols$string.symbol == 'DGS10TODTB3',]$date.series.end`). This is above the recent low of `r paste(sprintf("%3.2f", min(tail(df.data$DGS10TODTB3,365))),"%",sep="")`. The trend is `r getTrendString(df.data, 'DGS10TODTB3', 365)` over the last year and `r getTrendString(df.data, 'DGS10TODTB3', 30)` over the last month.

```{r bullet7, echo=FALSE}

datay.input <- "DGS10TODTB3"
ylim <- c(-2.0, 2)
dt.start <- as.Date('2017-01-01')
b.legend <- FALSE
b.percentile <- TRUE
plotSingleQuick(dfRecession, df.data, datay.input, ylim, dt.start, b.legend, b.percentile)

# Tidy memory
rm(datay.input)
rm(ylim)
rm(b.legend)
rm(b.percentile)
rm(dt.start)

```


- Auto sales flat?


# Auxillary Series

I explored additional data series. The sections below have those data series along with comments.


## Recent Highs

Print out the new 180 day high values

```{r New180}
df.symbolsTrue <-
  df.symbols[df.symbols$'Max180' == TRUE, c("string.symbol", "string.description")]
df.symbolsTrue <-
  df.symbolsTrue[!(is.na(df.symbolsTrue$string.symbol)), ]
df.symbolsTrue <-
  df.symbolsTrue[!(df.symbolsTrue$string.symbol == 'USREC'), ]
#print(head(df.symbolsTrue,20))

kable(df.symbolsTrue, caption = "6-Month High") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))  

```


## Equities

### S&P 500 SMA Trends

Take a look at recent activity in the equities market. This section looks at the S&P 500 close value to the 50 day and 200 day simple moving average (SMA).

```{r SP500pltNear, echo=FALSE }
datay.input <- "X_GSPC.GSPC.Close"
datay_aux <- "X_GSPC.GSPC.Close__mva200"
datay_aux2 <- "X_GSPC.GSPC.Close__mva050"
ylim <- c(2000, d.GSPC.max)
my.plot <- plotSingle(dfRecession, df.data, "date", datay = datay.input, 
                      getPlotTitle(df.symbols, datay.input), "Date", 
                      getPlotYLabel(df.symbols, datay.input), 
                      c(dt.recent, Sys.Date()), ylim, TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)
my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux2, colour=shQuote(datay_aux2)), na.rm = TRUE)

# Tidy memory
rm(datay.input)
rm(datay_aux)
rm(datay_aux2)
rm(ylim)
rm(my.plot)

```

This is a longer view for the S&P 500 trend.

```{r SP500MA200, echo=FALSE}

datay.input <- "X_GSPC.GSPC.Open"
datay_aux <- "X_GSPC.GSPC.Open__mva200"
datay_aux2 <- "X_GSPC.GSPC.Open__mva050"
ylim <- c(0, d.GSPC.max)
dt.start = as.Date('1980-01-01')
my.plot <- plotSingle(dfRecession, df.data, "date", datay = datay.input, 
                      getPlotTitle(df.symbols, datay.input), "Date", 
                      getPlotYLabel(df.symbols, datay.input), 
                      c(dt.start, Sys.Date()), ylim, TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)
my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux2, colour=shQuote(datay_aux2)), na.rm = TRUE)

# Tidy memory
rm(datay.input)
rm(datay_aux)
rm(datay_aux2)
rm(ylim)
rm(dt.start)
rm(my.plot)

```

### Equity indexes normalized by GDP

```{r GDPSP500.etal, echo=FALSE}

datay.input <- "GDPSP500"
datay.aux <- "RLGSP500"
datay.aux.1 <- "DJISP500"
datay.aux.scale <- 0.1
ylim <- c(0.00, 0.25)
dt.start = as.Date('1980-01-01')
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay = datay.input,
    getPlotTitle(df.symbols, datay.input),
    "Date",
    getPlotYLabel(df.symbols, datay.input),
    c(dt.start, Sys.Date()),
    ylim,
    TRUE
  )
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(datay.aux)
  ),
  na.rm = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = df.data[[datay.aux.1]] * datay.aux.scale,
    colour = shQuote(datay.aux.1)
  ),
  na.rm = TRUE
)
my.plot <-
  my.plot + scale_y_continuous(
    sec.axis = sec_axis( ~ . * (1 / datay.aux.scale), 
    name = paste(datay.aux.1, " ($/$)", sep ="")), 
    limits = ylim
  )

my.plot 

# Tidy up
rm(datay.input)
rm(my.plot)

```

```{r GDPSP500.close, echo=FALSE}

datay.input <- "GDPSP500"
ylim <- c(0.00, 0.22)
dt.start = as.Date('1995-01-01')
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay = datay.input,
    getPlotTitle(df.symbols, datay.input),
    "Date",
    getPlotYLabel(df.symbols, datay.input),
    c(dt.start, Sys.Date()),
    ylim,
    TRUE
  )

my.plot 

# Tidy up
rm(datay.input)
rm(my.plot)

```

The last two years compare favorably with the period around the late 1950's. Need to dig into this one.

```{r SP500SPpltNear.similar, echo=FALSE}
datay.input <- "GDPSP500"
ylim <- c(0.10, 0.30)
my.data <- plotSimilarPeriods(df.data, dfRecession, df.symbols, 
                              datay = datay.input, ylim, i.window = 50)
my.data[[1]]

rm(datay.input)
rm(ylim)

```

```{r SP500pltNear.similar}
datay <- "X_GSPC.GSPC.Close"
ylim <- c(2000, d.GSPC.max)
my.data <- plotSimilarPeriods(df.data, dfRecession, df.symbols, datay, ylim, i.window = 60)
my.data[[1]]

```

Look at how the different segments of the market move

```{r GSPCByMDY}

datay <- "X_GSPC__Close__by__MDY__Close__YoY"
ylim <- c(-50, 75)
dt.start = as.Date('1980-01-01')
plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, TRUE)

```

```{r GSPCByMDY.yoy}

datay <- "X_GSPC__Close__by__MDY__Close"
ylim <- c(0, 20)
dt.start = as.Date('1980-01-01')
b.legend = TRUE
b.percentile = TRUE
plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay),
           "Date",getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), 
           ylim, b.legend, b.percentile)

# Tidy up memory
rm(datay)
rm(ylim)
rm(dt.start)
rm(b.legend)
rm(b.percentile)

```

### S&P 500 Normalized moving average

Look at moving average relationship by dividing the S&P 500 open price by the 200 day SMA.

```{r SP500MA200Norm}

datay <- "GSPC__Open__mva200__Norm"
ylim <- c(50, 125)
dt.start = as.Date('2008-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

# Tidy up memory
rm(datay)
rm(ylim)
rm(dt.start)

```

### Crossovers

Look at the 50 DMA versus 200 DMA, often used as a technical indicator of market direction.

```{r SP500MA050MinusMA200}

datay <- "GSPC__Open__mva050__minus__mva200"
ylim <- c(-500, 500)
plotSingleQuick(dfRecession, df.data, datay, ylim, dtStartBackTest)

# Tidy up memory
rm(datay)
rm(ylim)

```

```{r SP500MA050MinusMA200Sig}

datay <- "GSPC__Open__mva050__mva200__sig "
ylim <- c(0.0, 1.0)
plotSingleQuick(dfRecession, df.data, datay, ylim, dtStartBackTest)

```

```{r SP500MA050MinusMA200SigTrade, echo=FALSE, fig.width=7,fig.height=10}


lst.syms <- c("GSPC__Open__mva050__mva200__sig", "retBase")
if ( require_columns( df.data, lst.syms ) ){

  str.symbol.new <- "ret050MAMinus200MA"
  df.data[[str.symbol.new]] <- df.data[[lst.syms[[2]]]] * df.data[[lst.syms[[1]]]]
  #df.data$ret050MAMinus200MAShort <- df.data$retBase * abs(df.data$GSPC.Open_mva050_mva200_sig-1.0)
  
  # Update the symbols table    
  df.symbols <- symbols_append_row(
    df.symbols,
    list(
        string.symbol = str.symbol.new,
        string.source = "Calc",
        string.description =  "Rate of Change, 50 DMA - 200 DMA Rule",
        string.label.y = "Percent",
        float.expense.ratio = -1.00,
        Max030 = FALSE,
        Max180 = FALSE,
        date.series.start = dt.start.prediction ,
        date.series.end = as.Date(Sys.Date()),
        string.symbol_safe = safe_symbol_name(str.symbol.new),
        string.object_name = safe_symbol_name(str.symbol.new)
    )
  )   

  # Tidy  up
  rm( str.symbol.new )
}

# Tidy memory
rm(lst.syms)


lst.syms <- c("ret050MAMinus200MA", "retBase")
if ( require_columns( df.data, lst.syms ) ){
  
  str.symbol.new <- "ret050MAMinus200MARet"
  df.data[[str.symbol.new]] <- exp(cumsum(df.data[[lst.syms[[1]]]]))
  df.data[[str.symbol.new]] <-    
      df.data[[str.symbol.new]]/df.data[min(which(df.data$date>dtStartBackTest)),str.symbol.new]

  # Update the symbols table    
  df.symbols <- symbols_append_row(
    df.symbols,
    list(
        string.symbol = str.symbol.new,
        string.source = "Calc",
        string.description =  "Equity Return, 50 DMA - 200 DMA Rule",
        string.label.y = "$1 Invested",
        float.expense.ratio = -1.00,
        Max030 = FALSE,
        Max180 = FALSE,
        date.series.start = dt.start.prediction ,
        date.series.end = as.Date(Sys.Date()),
        string.symbol_safe = safe_symbol_name(str.symbol.new),
        string.object_name = safe_symbol_name(str.symbol.new)
    )
  )   

  # Tidy  up
  rm( str.symbol.new )
}

# Tidy memory
rm(lst.syms)
```

```{r SP500MA050MinusMA200SigTradePlot, echo=FALSE, fig.width=7,fig.height=10}

dataTrade <- "GSPC__Open__mva050__mva200__sig"
dataRet <- "ret050MAMinus200MA"
dataEq <- "ret050MAMinus200MARet"
p1 <-
  plotBack(
    dfRecession,
    df.data,
    dataTrade,
    dataRet,
    dataEq,
    dfPred,
    bOverlay = FALSE,
    dtStartBackTest,
    ylimBackTest
  )

# Tidy up memory
rm(dataTrade)
rm(dataRet)
rm(dataEq)

```


### S&P 500 TTM P/E

Take a look at some of the earnings trends from SilverBlatt's sheet.

```{r SP500TTTMPE.silver.est, echo=FALSE}

#################################################################
# Import first estimate
#################################################################
str.est1 <- 'sp-500-eps-est_170715.xlsx'
str.range.est1 <- 'ESTIMATES&PEs!A105:J111'

df.silverblatt.est1 <-
  data.frame(read_excel(str.est1, range = str.range.est1))

# Human readable names
colnames(df.silverblatt.est1) <-
  c(
    "QUARTER.END",
    "PRICE",
    "OP.EARNINGS.PER.SHARE",
    "AR.EARNINGS.PER.SHARE",
    "EMPTY",
    "OP.EARNINGS.PE",
    "AR.EARNINGS.PE",
    "EMPTY1",
    "OP.EARNINGS.12.MONTH",
    "AR.EARNINGS.12.MONTH"
  )

# Create the XTS object and update the symbols table for estimated trailing 12-month operating earnings
assign(
  'OPEARNINGSTTM.est1',
  xts(
    x = df.silverblatt.est1$OP.EARNINGS.12.MONTH,
    order.by = as.Date(df.silverblatt.est1$QUARTER.END, "%m/%d/%Y")
  )
)

# Assign column names
colnames(OPEARNINGSTTM.est1) <- c("data.est")

# Create the XTS object and update the symbols table for estimated trailing 12-month as-reported earnings
assign(
  'AREARNINGSTTM.est1',
  xts(
    x = df.silverblatt.est1$AR.EARNINGS.12.MONTH,
    order.by = as.Date(df.silverblatt.est1$QUARTER.END, "%m/%d/%Y")
  )
)
# Assign column names
colnames(AREARNINGSTTM.est1) <- c("data.est")

#################################################################
# Next estimate
#################################################################
str.est2 <- 'sp-500-eps-est_180713.xlsx'
str.range.est2 <- 'ESTIMATES&PEs!A107:J114'

df.silverblatt.est2 <-
  data.frame(read_excel(str.est2, range = str.range.est2))

# Human readable names
colnames(df.silverblatt.est2) <-
  c(
    "QUARTER.END",
    "PRICE",
    "OP.EARNINGS.PER.SHARE",
    "AR.EARNINGS.PER.SHARE",
    "EMPTY",
    "OP.EARNINGS.PE",
    "AR.EARNINGS.PE",
    "EMPTY1",
    "OP.EARNINGS.12.MONTH",
    "AR.EARNINGS.12.MONTH"
  )

# Create the XTS object and update the symbols table for estimated trailing 12-month operating earnings
assign(
  'OPEARNINGSTTM.est2',
  xts(
    x = df.silverblatt.est2$OP.EARNINGS.12.MONTH,
    order.by = as.Date(df.silverblatt.est2$QUARTER.END, "%m/%d/%Y")
  )
)
# Assign column names
colnames(OPEARNINGSTTM.est2) <- c("data.est")

# Create the XTS object and update the symbols table for estimated trailing 12-month as-reported earnings
assign(
  'AREARNINGSTTM.est2',
  xts(
    x = df.silverblatt.est2$AR.EARNINGS.12.MONTH,
    order.by = as.Date(df.silverblatt.est2$QUARTER.END, "%m/%d/%Y")
  )
)
# Assign column names
colnames(AREARNINGSTTM.est2) <- c("data.est")


#################################################################
# Next estimate
#################################################################
str.est3 <- 'sp-500-eps-est_190421.xlsx'
str.range.est3 <- 'ESTIMATES&PEs!A125:J132'

df.silverblatt.est3 <-
  data.frame(read_excel(str.est3, range = str.range.est3))

# Human readable names
colnames(df.silverblatt.est3) <-
  c(
    "QUARTER.END",
    "PRICE",
    "OP.EARNINGS.PER.SHARE",
    "AR.EARNINGS.PER.SHARE",
    "EMPTY",
    "OP.EARNINGS.PE",
    "AR.EARNINGS.PE",
    "EMPTY1",
    "OP.EARNINGS.12.MONTH",
    "AR.EARNINGS.12.MONTH"
  )

# Create the XTS object and update the symbols table for estimated trailing 12-month operating earnings
assign(
  'OPEARNINGSTTM.est3',
  xts(
    x = df.silverblatt.est3$OP.EARNINGS.12.MONTH,
    order.by = as.Date(df.silverblatt.est3$QUARTER.END, "%m/%d/%Y")
  )
)
# Assign column names
colnames(OPEARNINGSTTM.est3) <- c("data.est")

# Create the XTS object and update the symbols table for estimated trailing 12-month as-reported earnings
assign(
  'AREARNINGSTTM.est3',
  xts(
    x = df.silverblatt.est3$AR.EARNINGS.12.MONTH,
    order.by = as.Date(df.silverblatt.est3$QUARTER.END, "%m/%d/%Y")
  )
)
# Assign column names
colnames(AREARNINGSTTM.est3) <- c("data.est")


#################################################################
# Next estimate
#################################################################
str.est4 <- 'sp-500-eps-est_210718.xlsx'
str.range.est4 <- 'ESTIMATES&PEs!A127:J134'

df.silverblatt.est4 <-
  data.frame(read_excel(str.est4, range = str.range.est4))

# Human readable names
colnames(df.silverblatt.est4) <-
  c(
    "QUARTER.END",
    "PRICE",
    "OP.EARNINGS.PER.SHARE",
    "AR.EARNINGS.PER.SHARE",
    "EMPTY",
    "OP.EARNINGS.PE",
    "AR.EARNINGS.PE",
    "EMPTY1",
    "OP.EARNINGS.12.MONTH",
    "AR.EARNINGS.12.MONTH"
  )

# Create the XTS object and update the symbols table for estimated trailing 12-month operating earnings
assign(
  'OPEARNINGSTTM.est4',
  xts(
    x = df.silverblatt.est4$OP.EARNINGS.12.MONTH,
    order.by = as.Date(df.silverblatt.est4$QUARTER.END, "%m/%d/%Y")
  )
)
# Assign column names
colnames(OPEARNINGSTTM.est4) <- c("data.est")

# Create the XTS object and update the symbols table for estimated trailing 12-month as-reported earnings
assign(
  'AREARNINGSTTM.est4',
  xts(
    x = df.silverblatt.est4$AR.EARNINGS.12.MONTH,
    order.by = as.Date(df.silverblatt.est4$QUARTER.END, "%m/%d/%Y")
  )
)
# Assign column names
colnames(AREARNINGSTTM.est4) <- c("data.est")

```

```{r SP500TTMPE.Silver.or,  echo=FALSE, fig.width = 9, fig.asp = 0.4 }

datay <- "OPEARNINGSTTM"
ylim <- c(0, 250)
dt.start <- as.Date('2010-01-01')
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()%m+% months(24)),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )

my.plot <-
  my.plot + geom_point(
    data = OPEARNINGSTTM.est1,
    aes_string(
      x = index(OPEARNINGSTTM.est1),
      y = "data.est",
      colour = shQuote('OE Est. 7/15/17')
    ),
    na.rm = TRUE
  )

my.plot <-
  my.plot + geom_point(
    data = OPEARNINGSTTM.est2,
    aes_string(
      x = index(OPEARNINGSTTM.est2),
      y = "data.est",
      colour = shQuote('OE Est. 7/13/18')
    ),
    na.rm = TRUE
  )


my.plot <-
  my.plot + geom_point(
    data = OPEARNINGSTTM.est3,
    aes_string(
      x = index(OPEARNINGSTTM.est3),
      y = "data.est",
      colour = shQuote('OE Est. 4/21/19')
    ),
    na.rm = TRUE
  )


my.plot <-
  my.plot + geom_point(
    data = OPEARNINGSTTM.est4,
    aes_string(
      x = index(OPEARNINGSTTM.est4),
      y = "data.est",
      colour = shQuote('OE Est. 7/18/21')
    ),
    na.rm = TRUE
  )

my.plot

```
```{r SP500TTMPE.Silver.ar,  echo=FALSE, fig.width = 9, fig.asp = 0.4 }

datay <- "AREARNINGSTTM"
ylim <- c(0, 250)
dt.start <- as.Date('2010-01-01')
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    paste("As-Reported Earnings\n",getPlotTitle(df.symbols, datay), sep=""),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()%m+% months(24)),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )

my.plot <-
  my.plot + geom_point(
    data = AREARNINGSTTM.est1,
    aes_string(
      x = index(OPEARNINGSTTM.est1),
      y = "data.est",
      colour = shQuote('AR Est. 7/15/17')
    ),
    na.rm = TRUE
  )

my.plot <-
  my.plot + geom_point(
    data = AREARNINGSTTM.est2,
    aes_string(
      x = index(OPEARNINGSTTM.est2),
      y = "data.est",
      colour = shQuote('AR Est. 7/13/18')
    ),
    na.rm = TRUE
  )


my.plot <-
  my.plot + geom_point(
    data = AREARNINGSTTM.est3,
    aes_string(
      x = index(AREARNINGSTTM.est3),
      y = "data.est",
      colour = shQuote('AR Est. 4/21/19')
    ),
    na.rm = TRUE
  )


my.plot <-
  my.plot + geom_point(
    data = AREARNINGSTTM.est4,
    aes_string(
      x = index(AREARNINGSTTM.est4),
      y = "data.est",
      colour = shQuote('AR Est. 7/18/21')
    ),
    na.rm = TRUE
  )

my.plot

```

Take a longer look back at as-reported and operating earnings

```{r SP500TTMPE.Silver.long,  echo=FALSE, fig.width = 9, fig.asp = 0.4 }

datay <- "AREARNINGSTTM"
datay.aux.1 <- "OPEARNINGSTTM"
ylim <- c(0, 300)
dt.start <- as.Date('1990-01-01')
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my.plot <-
  my.plot + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux.1,
      colour = shQuote(datay.aux.1)
    ),
    na.rm = TRUE
  )

my.plot

# Tidy up memory
rm(datay)
rm(datay.aux.1)
rm(ylim)
rm(dt.start )

```


Market prices can out-run earnings so take a look at price to earnings.

```{r SP500TTMPE,  echo=FALSE, fig.width = 9, fig.asp = 0.4 }

# datay <- "MULTPLSP500PERATIOMONTH"
# datay.aux <- "MULTPLSP500PERATIOMONTH_Mean"
# datay.aux.1 <- "AREARNINGSTTM"
# ylim <- c(0, 150)
# dt.start <- as.Date('1950-01-01')
# my.plot <-
#   plotSingle(
#     dfRecession,
#     df.data,
#     "date",
#     datay,
#     getPlotTitle(df.symbols, datay),
#     "Date",
#     getPlotYLabel(df.symbols, datay),
#     c(dt.start, Sys.Date()),
#     ylim,
#     b.legend = TRUE,
#     b.percentile = FALSE,
#     b.long.legend = TRUE
#   )
# my.plot <- my.plot + geom_line(
#   data = df.data,
#   aes_string(
#     x = "date",
#     y = datay.aux,
#     colour = shQuote(datay.aux)
#   ),
#   na.rm = TRUE
# )
# # my.plot <-
# #   my.plot + geom_line(
# #     data = df.data,
# #     aes_string(
# #       x = "date",
# #       y = datay.aux.1,
# #       colour = shQuote(datay.aux.1)
# #     ),
# #     na.rm = TRUE
# #   )
# 
# my.plot

```


Focus on some of the more recent activity

```{r SP500TTMPE.recent, echo=FALSE }

# datay <- "MULTPLSP500PERATIOMONTH"
# datay.aux <- "MULTPLSP500PERATIOMONTH_Mean"
# ylim <- c(10, 45)
# dt.start <- as.Date('2010-01-01')
# b.legend <- TRUE
# my.plot <-
#   plotSingle(
#     dfRecession,
#     df.data,
#     "date",
#     datay,
#     getPlotTitle(df.symbols, datay),
#     "Date",
#     getPlotYLabel(df.symbols, datay),
#     c(dt.start, Sys.Date()),
#     ylim,
#     b.legend
#   )
# my.plot + geom_line(
#   data = df.data,
#   aes_string(
#     x = "date",
#     y = datay.aux,
#     colour = shQuote(datay.aux)
#   ),
#   na.rm = TRUE
# )

```

### S&P 500 Sales

# ```{r SP500Sales }
# 
# datay <- "MULTPLSP500SALESQUARTER"
# ylim <- c(500, 2000)
# dt.start <- as.Date('1999-01-01')
# plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)
# 
# ```

# ```{r SP500SalesShort }
# 
# datay <- "MULTPLSP500SALESQUARTER"
# ylim <- c(500, 2000)
# dt.start = as.Date('2001-01-01')
# plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)
# 
# ```


### Unit Profits

The series peaks in the middle of a bull market.

```{r PRS88003193, echo=FALSE }

datay <- "PRS88003193.Value"
ylim <- c(10, 200)
dt.start = as.Date('1948-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = FALSE)

# Free up memory
rm(datay)
rm(ylim)
rm(dt.start)

```



### S&P 500 dividends

12-month real dividend per share inflation adjusted November, 2018 dollars. Data courtesy Standard & Poor's and Robert Shiller.

https://www.quandl.com/data/MULTPL/SP500_DIV_MONTH-S-P-500-Dividend-by-Month

```{r SP500Dividend.dollar, echo=FALSE, fig.width = 7, fig.asp = 1.1 }

# datay <- "MULTPLSP500DIVMONTH"
# ylim <- c(0, 70)
# dt.start = as.Date('1990-01-01')
# p1 <-
#   plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = FALSE)
# 
# 
# datay.1 <- "CASHDIVIDENDSPERSHR"
# ylim.1 <- c(0, 20)
# p2 <-
#   plotSingleQuick(dfRecession, df.data, datay.1, ylim.1, dt.start, b.percentile = FALSE)
# 
# grid.arrange(p1,
#              p2,
#              ncol = 1,
#              top = "S&P 500 Dividends by source")

```

Evaluate year over year dividend growth.

```{r SP500Dividend.dollar.yoy, echo=FALSE}
 
# datay <- "MULTPLSP500DIVMONTH_YoY"
# ylim <- c(-50, 50)
# dt.start = as.Date('1960-01-01')
# plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = FALSE)
 
```

Real value dividend growth.

```{r SP500Dividend.dollar.near, echo=FALSE}
 
# datay <- "MULTPLSP500DIVMONTH"
# ylim <- c(20, 70)
# dt.start = as.Date('2001-01-01')
# plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = FALSE)
 
```


<!-- ```{r SP500Dividend.dollar.yoy.recent} -->

<!-- datay <- "MULTPLSP500DIVMONTH_YoY" -->
<!-- ylim <- c(-40, 20) -->
<!-- dt.start = as.Date('2001-01-01') -->
<!-- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = FALSE) -->

<!-- ``` -->

S&P 500 dividend yield (12 month dividend per share)/price. Yields following September 2018 (including the current yield) are estimated based on 12 month dividends through September 2018, as reported by S&P. Sources: Standard & Poor's for current S&P 500 Dividend Yield. Robert Shiller and his book Irrational Exuberance for historic S&P 500 Dividend Yields.

https://www.quandl.com/data/MULTPL/SP500_DIV_YIELD_MONTH-S-P-500-Dividend-Yield-by-Month

```{r SP500Dividend.yied}

# datay <- "MULTPLSP500DIVYIELDMONTH"
# ylim <- c(0, 12)
# dt.start = as.Date('1950-01-01')
# plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = FALSE)


```

```{r SP500Dividend.recent}

# datay <- "MULTPLSP500DIVYIELDMONTH"
# ylim <- c(1, 4)
# dt.start = as.Date('2001-01-01')
# plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = FALSE)

```

### S&P 500 Volume

The log of the S&P volume has some interesting patterns, but nothing that seems to help with a recession indicator.

```{r SP500Vol, echo=FALSE}

datay <- "X_GSPC.GSPC.Volume__Log"
ylim <- c(12, 23)
plotSingleQuick(dfRecession, df.data, datay, ylim)
#my.plot + geom_rect(data=dfRecession,  aes(xmin=initStart, xmax=initEnd, ymin=-Inf, ymax=Inf),
#              fill="blue", alpha=0.2, na.rm = TRUE)

```

That is one spiky data series. Not sure there is a lot to help us here.


```{r SP500Vol_Smoott, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "X_GSPC.GSPC.Volume"
datay.aux <- "GSG__Close__by__GSPC__Close__mva050"
datay.title <- getPlotTitle(df.symbols, datay.aux, str.sep = "\n")
datay.aux.1 <- "GSG__Close__by__GSPC__Close__mva200"
datay.title.1 <- getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n")
ylim <- c(100000, 8000000000)
dt.start = as.Date('2010-01-01')
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my.plot <-
  my.plot + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux,
      colour = shQuote(datay.title)
    ),
    na.rm = TRUE
  )
my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.1,
    colour = shQuote(datay.title.1)
  ),
  na.rm = TRUE
)

# Free up memory
rm(datay)
rm(datay.aux)
rm(datay.title)
rm(datay.aux.1)
rm(datay.title.1)
rm(ylim)
rm(dt.start)

```

### Russell 2000

Take a look at recent activity in the small cap market.

```{r Russel, echo=FALSE, fig.width = 9, fig.asp = 0.4 }
datay <- "X_RLG.RLG.Open"
datay.aux <- "X_RLG.RLG.Open__mva200"
datay.title <- getPlotTitle(df.symbols, datay.aux, str.sep = "\n")
datay.aux.1 <- "X_RLG.RLG.Open__mva050"
datay.title.1 <- getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n")
ylim <- c(1000, d.Russell.max)
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.recent, Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my.plot <-
  my.plot + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux,
      colour = shQuote(datay.title)
    ),
    na.rm = TRUE
  )
my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.1,
    colour = shQuote(datay.title.1)
  ),
  na.rm = TRUE
)

# Free up memory
rm(datay)
rm(datay.aux)
rm(datay.title)
rm(datay.aux.1)
rm(ylim)

```

### S&P 500 to Rusell 2000

#### Thirty day movement

#### Correlation


```{r rollingcorS&PtoRussell, echo=FALSE, fig.width = 10, fig.asp = .62}

datay1 <- "X_RLG.RLG.Open"
ylim1 <- c(0, d.Russell.max )

datay2 <- "X_GSPC.GSPC.Open"
ylim2 <- c(0, d.GSPC.max)

dt.start <- as.Date("1jan2003","%d%b%Y")

w <- 30
corrName <- calcRollingCorr(dfRecession, df.data, df.symbols, datay1, ylim1, datay2, ylim2, w, dt.start)

# Tidy up memory
rm(w)
rm(datay1)
rm(ylim1)
rm(datay2)
rm(ylim2)

```

### S&P 500 to MDY (Mid-cap) 2000 Correlation

```{r rollingcorS&PtoMDY, fig.width = 10, fig.asp = .62}

datay1 <- "X_RLG.RLG.Open"
ylim1 <- c(0, d.Russell.max)

datay2 <- "MDY.Open"
ylim2 <- c(0, 1000)

dt.start <- as.Date("1jan2003","%d%b%Y")

w <- 30
corrName <-
  calcRollingCorr(dfRecession,
                  df.data,
                  df.symbols,
                  datay1,
                  ylim1,
                  datay2,
                  ylim2,
                  w,
                  dt.start)

# Tidy up memory
rm(w)
rm(datay1)
rm(ylim1)
rm(datay2)
rm(ylim2)

```


### Dividend Stocks

This is an interesting series, they should perform better through the recessions. Unfortunately they are short lived so there is not much data so this is more of a place holder for now.

```{r DivStocks }
datay <- "NOBL.Open"
ylim <- c(40, 110)
dt.start <- as.Date('2014-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```


## Margin and option data

### NYSE Margin Debt

Taking a look at margin debt. NYXDATA stopped providing NYSE margin debt data on Dec 2017. Data is available from FINRA, but it includes more accounts than the data did for NYXdata. I stitched togeter the data sets: data after Jan 2010 include NYSE+Others, data prior is just NYSE account data scaled up to match the FINRA data.


It tends to creep up when there is a frenzy in the stock market.

```{r NYSEMargin }

datay <- "FINRA_MarginDebt__Log"
ylim <- c(5, 15)
plotSingleQuick(dfRecession, df.data, datay, ylim)

# Clean up memory
rm(datay)
rm(ylim)

```

Take a close look at recent activity

```{r FINRA.margin.debt.nearterm, echo=FALSE}

datay <- "FINRA_MarginDebt"
ylim <- c(100000, 1000000)
dt.start <- as.Date('2000-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

# Tidy up memory
rm(datay)
rm(ylim)
rm(dt.start)

```

Sometimes it is more helpful to view year over year growth.

```{r NYSEMargin_Yoy, echo=FALSE }

datay <- "FINRA_MarginDebt__YoY"
ylim <- c(-50, 100)
dt.start <- as.Date('1960-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = TRUE)

# Tidy up memory
rm(datay)
rm(ylim)
rm(dt.start)

```

More near-term trend.

```{r NYSEMargin_Yoy.nearterm, echo=FALSE }

datay <- "FINRA_MarginDebt__YoY"
ylim <- c(-100, 75)
dt.start <- as.Date('2000-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile=TRUE)

# Tidy up memory
rm(datay)
rm(ylim)
rm(dt.start)

```

Take a look at some of the correlations


```{r rollingcor.FINRAMarginDebt_YoY.by.GSPC.Close_YoY, fig.width = 10, fig.asp = .62}

datay1 <- "FINRA_MarginDebt__YoY"
ylim1 <- c(-100, 100)

datay2 <- "X_GSPC.GSPC.Close__YoY"
ylim2 <- c(-100, 100)

dt.start <- as.Date("1jan1995","%d%b%Y")

w <- 200
corrName <-
  calcRollingCorr(dfRecession,
                  df.data,
                  df.symbols,
                  datay1,
                  ylim1,
                  datay2,
                  ylim2,
                  w,
                  dt.start)

# Tidy up memory
rm(datay1)
rm(ylim1)
rm(datay2)
rm(ylim2)
rm(dt.start)
rm(w)

```

Comparison to the Russell 2000

```{r rollingcor.FINRAMarginDebt_YoY.by.RLG.Close_YoY, fig.width = 10, fig.asp = .62}

datay1 <- "FINRA_MarginDebt__YoY"
ylim1 <- c(-100, 100)

datay2 <- "X_RLG.RLG.Close__YoY"
ylim2 <- c(-100, 100)

dt.start <- as.Date("1jan1995","%d%b%Y")

w <- 200
corrName <-
  calcRollingCorr(dfRecession,
                  df.data,
                  df.symbols,
                  datay1,
                  ylim1,
                  datay2,
                  ylim2,
                  w,
                  dt.start)

# Tidy up memory
rm(datay1)
rm(ylim1)
rm(datay2)
rm(ylim2)
rm(dt.start)
rm(w)

```

### OCC Options Volumes

See what is happening with the options volumes for equities. (From: https://www.theocc.com/webapps/historical-volume-query)

```{r OCC.equity.volume, echo=FALSE, fig.width = 7, fig.asp = 1.1 }

datay <- "OCC_EquityVolume"
ylim <- c(0, 35)
dt.start <- as.Date('2016-01-01')
b.percentile <- TRUE
p1 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile)

datay <- "OCC_NonEquityVolume"
ylim <- c(0, 7.5)
p2 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile)

grid.arrange(p1, p2, ncol = 1, top = "Options Volumes")


# Tidy up memory
rm(datay)
rm(ylim)
rm(dt.start)
rm(b.percentile)
rm(p1)
rm(p2)


```

Looks like options on non-equity co-occurs with peaks/troughs?.

```{r OCC.equity.volume.to.market, echo=FALSE, fig.width = 7, fig.asp = 1.1 }


datay <- "OCC_NonEquityVolume"
ylim <- c(0, 7.5)
dt.start = as.Date('2015-01-01')
p1 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2015-08-24"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2016-01-08"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2018-02-05"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2018-10-11"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )

datay <- "X_GSPC.GSPC.Open"
datay_aux <- "X_GSPC.GSPC.Close"
ylim <- c(1500, d.GSPC.max)
p2 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    TRUE
  )

p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2015-08-24"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2016-01-08"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2018-02-05"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2018-10-11"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )


grid.arrange(p1,
             p2,
             ncol = 1,
             top = "Non-equity Options and S&P Price")

```

## Market Volatility

Take a look at some of the indications of market volatility

### CBOE VIX

```{r VIX, echo=FALSE }

datay <- "VIXCLS.Value"
ylim <- c(10, 80)
dt.start <- as.Date('1990-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

As markets become complacent (low VIX) and high values, peaks often occur.

```{r VIX_near, echo=FALSE, fig.width = 7, fig.asp = 1.1 }


datay <- "VIXCLS.Value"
ylim <- c(0, 80)
dt.start = as.Date('2015-01-01')
p1 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = TRUE)
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2015-08-24"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2016-01-08"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2018-02-05"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2018-10-11"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )

datay <- "X_GSPC.GSPC.Close"
ylim <- c(1500, d.GSPC.max)
p2 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    TRUE
  )

p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2015-08-24"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2016-01-08"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2018-02-05"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2018-10-11"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )


grid.arrange(p1,
             p2,
             ncol = 1,
             top = "CBOE VIX and S&P Price")

```

Compare the VIX to some of the ETF's out there.

```{r VIX.VXX, echo=FALSE, fig.width = 7, fig.asp = 1.1 }


datay <- "VIXCLS.Value"
ylim <- c(0, 80)
dt.start = as.Date('2015-01-01')
p1 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = TRUE)
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2015-08-24"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2016-01-08"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2018-02-05"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2018-10-11"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )

datay <- "VXX.Open"
ylim <- c(0, 400)
p2 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    TRUE
  )

p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2015-08-24"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2016-01-08"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2018-02-05"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2018-10-11"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )


grid.arrange(p1,
             p2,
             ncol = 1,
             top = "CBOE VIX and VXX ETF")

```

There 

```{r VIXtoGSPCCorr, echo = FALSE, fig.width = 7, fig.asp = 1.1}

datay1 <- "VIXCLS.Value"
ylim1 <- c(0, 80)

datay2 <- "X_GSPC.GSPC.Open"
ylim2 <- c(1000, d.GSPC.max)

dt.start <-  as.Date('2005-01-01')

w <- 30
corrName <- calcRollingCorr(dfRecession, df.data, df.symbols, datay1, ylim1, datay2, ylim2, w, dt.start)

```

Not much predictive in VIX, take a quick look at the smoothed derivative.

```{r VIX_SmoothDer, echo=FALSE }

datay <- "VIXCLS.Value__Log"
ylim <- c(2, 5)
dt.start <- as.Date('1990-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

### S&P Daily Swings

Daily changes in the S&P should correlate well with the VIX.

```{r GSPC.DailySwing, echo=FALSE }

plotSingleQuick(dfRecession, df.data, datay="X_GSPC__DailySwing", 
                ylim=c(0, 0.12), dt.start=as.Date('1990-01-01'))

```

More of a correlating series than a predictor.

```{r GSPC.DailySwing.near, echo=FALSE, fig.width = 7, fig.asp = 1.1 }


datay <- "X_GSPC__DailySwing"
ylim <- c(0, 0.10)
dt.start = as.Date('2015-01-01')
p1 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2015-08-24"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2016-01-08"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2018-02-05"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2018-10-11"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )

datay <- "X_GSPC.GSPC.Open"
datay_aux <- "X_GSPC.GSPC.Close"
ylim <- c(1500, d.GSPC.max)
p2 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    TRUE
  )

p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2015-08-24"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2016-01-08"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2018-02-05"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2018-10-11"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )


grid.arrange(p1,
             p2,
             ncol = 1,
             top = "CBOE VIX and S&P Price")

# Tidy up memory
rm(p1)
rm(p2)
```


## Employment and payrolls

### Unemployment rates

Unemployment rates will probably be useful, let's take a look at the U-3. The data is a little noisy so there is also a smoothed version plotted. There seems to be a relationship between the unemployment rate and the recessions, but it could be a lagging indicator.  This will be explored a little bit more later.

```{r unrate, echo=FALSE, fig.width = 9, fig.asp = 0.4}
datay <- "UNRATE.Value"
datay_aux <- "UNRATE.Value__mva365"
ylim <- c(2, 15)
b.legend <- TRUE
b.percentile <- TRUE
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(as.Date("1jan1950", "%d%b%Y"), Sys.Date()),
    ylim,
    b.legend,
    b.percentile,
    b.long.legend = TRUE
  )
my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay_aux,
    colour = shQuote(getPlotTitle(df.symbols, datay_aux))
  ),
  na.rm = TRUE
)

```

Suggested by Charlie and a Wealthian video the 12 month-MA might be helpful to look at.

```{r unrate.ma, echo=FALSE, fig.width = 9, fig.asp = 0.4}
datay <- "UNRATE.Value"
datay_aux <- "UNRATE.Value__mva365"
ylim <- c(2, 15)
b.legend <- TRUE
b.percentile <- TRUE
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(as.Date("1jan2000", "%d%b%Y"), Sys.Date()),
    ylim,
    b.legend,
    b.percentile,
    b.long.legend = TRUE
  )
my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay_aux,
    colour = shQuote(getPlotTitle(df.symbols, datay_aux))
  ),
  na.rm = TRUE
)

```



Looking at the unemployment rate, the eye is drawn to the rise and fall of the data, this suggests that the derivative might be helpful as well. The figure below shows the results, using a Savitzky-Golay FIR filter. It looks like the unemployment rate peaks in the middel of the recession. That peak might be a good buy signal.

```{r UnrateDer, echo=FALSE}

plotSingleQuick(dfRecession, df.data, datay="UNRATE.Value__SmoothDer", 
                ylim= c(-0.02, 0.02), dt.start = as.Date('1950-01-01'),
                b.percentile = TRUE)

```

### Continuing Claims

A good measure of how much unemployment is growing. 

Continued claims, also referred to as insured unemployment, is the number of people who have already filed an initial claim and who have experienced a week of unemployment and then filed a continued claim to claim benefits for that week of unemployment. Continued claims data are based on the week of unemployment, not the week when the initial claim was filed

https://fred.stlouisfed.org/series/CCNSA

```{r CCSA, echo=FALSE}

datay <- "CCSA.Value"
ylim <- c(0, 28000000)
b.percentile <- TRUE
dt.start <- as.Date('1967-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile)

# Tidy up
rm(datay)
rm(ylim)
rm(b.percentile)
rm(dt.start)

```


A good measure of how much unemployment is growing

```{r CCSA.close, echo=FALSE}

datay <- "CCSA.Value"
ylim <- c(0, 28000000)
b.percentile <- TRUE
dt.start <- as.Date('2009-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile)

# Tidy up
rm(datay)
rm(ylim)
rm(b.percentile)
rm(dt.start)

```

### Initial Claims

A good measure of how much unemployment is growing. 

An initial claim is a claim filed by an unemployed individual after a separation from an employer. The claim requests a determination of basic eligibility for the Unemployment Insurance program.

https://fred.stlouisfed.org/series/ICSA

```{r ICSA, echo=FALSE}

datay <- "ICSA.Value"
ylim <- c(0, 2800000)
b.percentile <- TRUE
dt.start <- as.Date('1967-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile)

# Tidy up
rm(datay)
rm(ylim)
rm(b.percentile)
rm(dt.start)

```


### Unemployment rates, year-over-year

Both the headline unemployment and U-6 number changes are similar. During the upswing on the cycle it does look like the headline number falls faster than U-6

```{r UnrateDer.yoy, echo=FALSE}

datay <- "UNRATE.Value__YoY"
ylim <- c(-50, 350)
b.percentile <- TRUE
dt.start <- as.Date('1950-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile)

# Tidy up
rm(datay)
rm(ylim)
rm(b.percentile)
rm(dt.start)

```
### Unemployment rates, similar periods

Historically the last two years of record low unemployment appear most similar to the 1971-1973 time frame. Just before inflation took off.

```{r unrate.similar, echo=FALSE}
datay <- "UNRATE.Value"
ylim <- c(3.3, 4.5)
i.window = 730
my.data <- plotSimilarPeriods(df.data, dfRecession, df.symbols, datay, ylim, i.window)
my.data[[1]]

```

### Unemployment rates, U-6 and headline number. 

Let's also take a look at the total unemployed, U-6. It continues to fall as the headline number stabilizes as people return to the work force. An indicator the cycle is beginning to top out.


```{r unrateU6, echo=FALSE}

datay <- "UNRATE.Value"
datay_aux <- "U6RATE.Value"
ylim <- c(0, 25)
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(as.Date("1jan1995", "%d%b%Y"), Sys.Date()),
    ylim,
    TRUE
  )
my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay_aux,
    colour = shQuote(datay_aux)
  ),
  na.rm = TRUE
)

```

Difference between U6 and U3 to see how close the economy is getting to full employment.

```{r unrateU6toU3, echo=FALSE}

datay <- "U6toU3"
ylim <- c(2.5, 10)
dt.start <- as.Date("1jan1995", "%d%b%Y")
my.plot <-
  plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)
my.plot

```

### Unemployment and market bottoms

```{r U3.GSPC, echo=FALSE, fig.width = 11, fig.asp = 0.2}
datay <- "GDPSP500" 
datay.aux <- "UNRATE.Value" 
datay.aux.scale <- 0.01;
ylim <- c(0, 0.2)
dt.start = as.Date('1998-01-01')
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my.plot <-
  my.plot + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = df.data[[datay.aux]] * datay.aux.scale,
      colour = shQuote(datay.aux)
    ),
    na.rm = TRUE
  )
my.plot + scale_y_continuous(sec.axis = sec_axis( ~ . * (1 / datay.aux.scale), name = "Percent"), limits = ylim)

```


### Initial jobless claims

We will also take a look at initial jobless claims, this should start to rise just before the unemployment rate.

```{r initclaims, echo=FALSE}

datay <- "ICSA.Value"
ylim <- c(100000, 7000000)
dt.start <- as.Date('1968-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

It looks like the jobless claim tend to peak more towards the end of the recession. It does not seem to be as strong of a sell indicator as the U-3 rate.

```{r initclaimsDer, echo=FALSE}
datay <- "ICSA.Value__SmoothDer"
ylim <- c(-3500, 3500)
dt.start <- as.Date('1968-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = TRUE)

```

Jobless claims have a seasonal component to them. One way to reduce this effect is to calculate year over year growth. That helps some, the peaks seem to be more closely aligned with the middle to end of recessions.

```{r initialclaimsYoy, echo=FALSE}
datay <- "ICSA.Value__YoY"
ylim <- c(-75, 4000)
dt.start <- as.Date('1968-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = TRUE)

```

Take a closer look at recent data

```{r initialclaimsYoy.twoyears, echo=FALSE}

datay <- "ICSA.Value__YoY"
ylim <- c(-50, 4000)
dt.start <- as.Date('2005-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = TRUE)

```

Take a look at the percentage of the population looking for work

```{r LNU03000000BYPOPTHM, echo=FALSE }

datay <- "LNU03000000BYPOPTHM"
ylim <- c(0, 10)
datay_aux <- "UNEMPLOYBYPOPTHM"
dt.start <- as.Date('1968-01-01')
my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, TRUE)
my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)

```

A bit more recent trend

```{r LNU03000000BYPOPTHM.recent, echo=FALSE }

datay <- "LNU03000000BYPOPTHM"
ylim <- c(0,10)
datay_aux <- "UNEMPLOYBYPOPTHM"
my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.recent, Sys.Date()), ylim, TRUE)
my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)

```

### Unemployment Level

ADP data here. comes out before the official numbers.

```{r NPPTTL, echo=FALSE}
datay <- "NPPTTL.Value"
ylim <- c(100000, 135000)
dt.start <- as.Date('2000-01-01')
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    TRUE,
    b.long.legend = FALSE
  )

```

Look at the year-over-year change in ADP.

```{r NPPTTL.YoY, echo=FALSE}
datay <- "NPPTTL.Value__YoY"
ylim <- c(-20, 10)
dt.start <- as.Date('2000-01-01')
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    TRUE,
    b.long.legend = FALSE
  )

```

ADP data divided by the population

```{r NPPTTLBYPOP, echo=FALSE}
datay <- "NPPTTLBYPOPTHM"
ylim <- c(30, 40)
dt.start <- as.Date('2000-01-01')
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    TRUE,
    b.long.legend = FALSE
  )

```



```{r UNEMPLOY, echo=FALSE}
datay <- "UNEMPLOY.Value"
datay.aux <- "NPPTTL.Value"
ylim <- c(-75, 25000)
dt.start <- as.Date('1968-01-01')
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    TRUE,
    b.long.legend = FALSE
  )

```

```{r UNEMPLOY.yoy, echo=FALSE}
datay <- "UNEMPLOY.Value__YoY"
ylim <- c(-25, 350)
dt.start <- as.Date('1968-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

### Payrolls

Look at the BLS data on payrolls. Check the NSA series, then we will look at YoY data.

```{r PAYNSA, echo=FALSE}
datay <- "PAYNSA.Value"
datay_aux <- "PAYNSA.Value__Smooth"
ylim <- c(20000, 200000)
b.legend <- TRUE
b.percentile <- FALSE
my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(as.Date("1jan1950","%d%b%Y"), Sys.Date()), ylim, b.legend, b.percentile)
my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)

```

```{r PAYNSA_YoY, echo=FALSE}

datay <- "PAYNSA.Value__YoY"
ylim <- c(-17.5, 7.5)
b.legend <- TRUE
b.percentile <- TRUE
plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(as.Date("1jan1950","%d%b%Y"), Sys.Date()), ylim, b.legend, b.percentile)

```

```{r PAYNSA_YoY.Recent, echo=FALSE}

datay <- "PAYNSA.Value__YoY"
ylim <- c(-17.5, 7.5)
b.legend <- TRUE
b.percentile <- FALSE
dt.start <- as.Date('2000-01-01')
plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, b.legend, b.percentile)

```

### Hours worked

Sparked by an article at Mises (https://mises.org/wire/how-alexandria-ocasio-cortez-misunderstands-american-poverty), take a look at average weekly hours

```{r avghours, echo=FALSE}

datay <- "CEU0600000007.Value"
ylim <- c(36, 43)
plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(as.Date("1jan1945","%d%b%Y"), Sys.Date()), ylim, TRUE)

```

The time series is pretty lumpy, plot the YoY change

```{r avghours_yoy, echo=FALSE}

datay <- "CEU0600000007.Value__YoY"
ylim <- c(-7.5, 7.5)
b.percentile <- TRUE
dt.start <- as.Date('1968-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile)

```

A more recent look at average weekly hours of production

```{r avghours_yoy.recent, echo=FALSE}

datay <- "CEU0600000007.Value__YoY"
ylim <- c(-7.5, 7.5)
b.percentile <- FALSE
dt.start <- as.Date('2010-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile)


```

## Industrial Production

Industrial production is also known to fall during an economic downturn, let's take a look at some of the data from the FRED on industrial production. It does seem to peak prior to a recession so let's smooth and look at the derivative as it might be a good indicator as well.

```{r indpro, echo=FALSE}
datay <- "INDPRO.Value"
ylim <- c(0, 125)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

Industrial production over the last ten years or so

```{r indpro.recent, echo=FALSE}
datay <- "INDPRO.Value"
ylim <- c(80, 120)
dt.start <- as.Date('2000-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = TRUE)

```


The derivative isn't bad, but it sometimes crosses zeros well into a recession. That is less helpful as either a buy or sell indicator. A better measure might year over year (YoY) change.

```{r indproderplot, echo=FALSE}
datay <- "INDPRO.Value__SmoothDer"
ylim <- c(-0.10, 0.10)
dt.start <- as.Date('1968-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = TRUE)

```

The year over year change has a similar appearance. The low values at the beginning make the year over year values larger than the more recent values. Seems like it will rank low a reliable indicator.

```{r indproYoY, echo=FALSE}

datay <- "INDPRO.Value__YoY"
ylim <- c(-20, 12)
dt.start <- as.Date('1968-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = TRUE)

```


```{r rollingcor.indpro, fig.width = 10, fig.asp = .62}

datay1 <- "INDPRO.Value__YoY"
ylim1 <- c(-20, 12)

datay2 <- "X_GSPC.GSPC.Close__YoY"
ylim2 <- c(-100, 50)

dt.start <- as.Date("1jan1981","%d%b%Y")

w <- 360
corrName <- calcRollingCorr(dfRecession, df.data, df.symbols, datay1, ylim1, datay2, ylim2, w, dt.start)

```

## Retail Sales

### Retail sales, aggregate

Retail sales also change during recession. As the plot below shows, it seems to follow the trend of industrial production. It might be too strongly correlated to add much to the model. The will be examined in the correlation section.

```{r rsalesagg, echo=FALSE}
datay <- "RSALESAGG"
ylim <- c(50000, 200000)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

The derivative of retail sales is a little more erratic than is was the industrial products. Looks like it might be helpful to include in the model as well.

```{r rsalesderplot, echo=FALSE}
datay <- "RSALESAGG__SmoothDer" 
ylim <- c(-100, 100)
dt.start <- as.Date('1968-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = TRUE)

```

### Retail sales, aggregate year-over-year

Take a look at year-over-year changes

```{r rsalesderplot.yoy, echo=FALSE, fig.width = 9, fig.asp = .42}
datay <- "RSALESAGG__YoY" 
ylim <- c(-12.5, 12.5)
dt.start <- as.Date('1968-01-01')
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    "Real retail sales YoY",
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = TRUE,
    b.long.legend = TRUE
  )
my.plot

```

### Retail sales and unemployment correlations

Let's see how that looks on year over year basis. Interesting to compare to unemployment rates there appears to a correlation over the long term.

```{r rsalesYoYToUNRATE.yoy, echo=FALSE}
datay <- "RSALESAGG__YoY" 
datay.aux <- "UNRATE.Value__YoY" 
datay.aux.scale <- 0.25;
ylim <- c(-15, 70)
dt.start = as.Date('1998-01-01')
my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=df.data[[datay.aux]]*datay.aux.scale, colour=shQuote(datay.aux)), na.rm = TRUE)
my.plot + scale_y_continuous(sec.axis = sec_axis(~.*(1/datay.aux.scale), name = "Percent"), limits = ylim)

```


There is some similarity. The rolling correlation shows the inverse relationship prior to a recession.

```{r rollingcor.rsalesagg.yoy.by.unrate.yoy, fig.width = 10, fig.asp = .62}

datay1 <- "RSALESAGG__YoY"
ylim1 <- c(-12.5, 12.5)

datay2 <- "UNEMPLOY.Value__YoY"
ylim2 <- c(-30, 150)

dt.start <- as.Date("1jan1970","%d%b%Y")

w <- 200
corrName <- calcRollingCorr(dfRecession,df.data, df.symbols, datay1, ylim1, datay2, ylim2, w, dt.start)

```

### Retail sales correlation and industrial production

Industrial production and retail sales look very similar so the plot below shows the 360 correlation. The corerlation does tend to fall around a recession, although 2008 was so bad that they both fell together. Not sure if it is that useful.

```{r rollingcortest, fig.width = 10, fig.asp = .62}

datay1 <- "INDPRO.Value"
ylim1 <- c(40, 125)

datay2 <- "RSALESAGG"
ylim2 <- c(100000, 200000)

dt.start <- as.Date("1jan1981","%d%b%Y")

w <- 60
corrName <- calcRollingCorr(dfRecession, df.data, df.symbols, datay1, ylim1, datay2, ylim2, w, dt.start)

```

It is interesting to see the strong correlation; however, I suspect this is due to more to the shape of the trends. How do the YoY correlations look? They are a little less correlated, probably better to use in the machine learning later.

```{r rollingcortestYoY, fig.width = 10, fig.asp = .62}

datay1 <- "INDPRO.Value__YoY"
ylim1 <- c(-20, 20)

datay2 <- "RSALESAGG__YoY"
ylim2 <- c(-20, 20)

dt.start <- as.Date("1jan1981","%d%b%Y")

w <- 200
corrName <- calcRollingCorr(dfRecession, df.data, df.symbols, datay1, ylim1, datay2, ylim2, w, dt.start)

```

### Advance Retail Sales

This is an advanced estimate of the retail sales value.

```{r rsafs, echo=FALSE}
datay <- "RSAFS.Value"
ylim <- c(150000, 900000)
dt.start = as.Date('1992-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

Also take a look at year over year

```{r rsafs.yoy, echo=FALSE}
datay <- "RSAFS.Value__YoY"
ylim <- c(-22.5, 42.5)
dt.start = as.Date('1992-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

### Retail sales and the labor market

```{r rsalesYoYToU4, echo=FALSE}
datay <- "RSALESAGG__YoY" 
ylim <- c(-15, 15)
plotSingleQuick(dfRecession, df.data, datay, ylim)


```

## Income

### Real Personal Income

```{r realperinc, echo=FALSE}
datay <- "RPI.Value"
ylim <- c(0, 22000)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

```{r realperincYoY, echo=FALSE, fig.width = 7, fig.asp = .42}
datay <- "RPI.Value__YoY"
ylim <- c(-15, 15)
dt.start <- as.Date('1970-01-02')
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    "Real personal income, year over year",
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = TRUE,
    b.long.legend = TRUE
  )
my.plot

```

### Real Personal Income (Excluding Transfer, Annual)

During a recession real personal income falls. In the plot the peaks can be seen prior to each recession.

```{r realperincex}
datay <- "W875RX1.Value"
ylim <- c(3000, 20000)
plotSingleQuickModern(datay, ylim)

```

The features we are interested in are the peaks and valleys so we'll use the derivative to get to those. Interesting, there is usually a first zero crossing before a recession and a second during or just after the recession.

```{r rperincderplot, echo=FALSE}
datay <- "W875RX1.Value__SmoothDer"
ylim <- c(-5, 3)
plotSingleQuickModern(datay, ylim)

```

Real personal income might have some seasonal variance, but it seems the year over year change tells the same story.

```{r rperincYoYplotex, echo=FALSE}
datay <- "W875RX1.Value__YoY"
ylim <- c(-7.5, 7.5)
b.percentile <- TRUE
plotSingleQuickModern(datay, ylim, b.percentile)

```


## Price and cost measures

This section shows price and cost measures. 

Two commonly used indexes are the CPI (consumer price index) and PPI (producer price index). CPI tries to show final prices paid for goods and services by urban U.S. consumers. This index includes sales tax and imports. The PPI attempts to reflect the prices paid at all stages of production, including goods and services purchases as inputs as well as goods and services purchased by consumers from retail and producer sellers. The PPI does not include imports or sales tax. The CPI reflects all rebates and financing plans wherease the PPI reflects only those rebate and financing plans provided by the producer. For example if an automotive manufacturer offers a rebate of \$500 and the dealer offers an additional rebate of \$500 then the PPI would reflect only the automotive manufacturer rebate, but the CPI would reflect both rebates.

Sources; https://www.bls.gov/opub/hom/pdf/cpihom.pdf and https://www.bls.gov/opub/hom/pdf/ppi-20111028.pdf.

### Consumer price index

What does CPI look like?

```{r CPIPlot}
datay <- "CPIAUCSL.Value"
ylim <- c(0, 400)
plotSingleQuickModern(datay, ylim)

```

Check out the YoY growth

```{r CPIPlot_YoY}
datay <- "CPIAUCSL.Value__YoY"
ylim <- c(-2, 15)
plotSingleQuickModern(datay, ylim)

```

### CPI to PPI

Suggested by Charlie, it can be helpful to look at the relationship between producer prices and consumer prices.

```{r CPItoPPI, echo=FALSE, fig.width = 9, fig.asp = 0.4}
datay <- "CPIAUCSL.Value__YoY"
datay.aux <- "PPIACO.Value__YoY"
datay.aux.scale <- 0.5
datay.aux.1 <- "PCEPI.Value__YoY"

ylim <- c(-10, 20)
dt.start = as.Date('1960-01-01')
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    paste(getPlotYLabel(df.symbols, datay), ", ", datay, sep=""),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.long.legend = TRUE
  )
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = df.data[[datay.aux]] * datay.aux.scale,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
  ),
  na.rm = TRUE
)

my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = df.data[[datay.aux.1]] * datay.aux.scale,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n"))
  ),
  na.rm = TRUE
)


my.plot + scale_y_continuous(sec.axis = sec_axis(
  ~ . * (1 / datay.aux.scale),
  name = paste(getPlotYLabel(df.symbols, datay.aux), ", ", datay.aux, sep = "")
), limits = ylim)

```

### Producer Price Index (Commodities)

```{r plot.ppi, echo=FALSE}
datay <- "PPIACO.Value"
ylim <- c(0, 350)
dt.start = as.Date('1965-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

## Commodities

### Basket

Take a look at some trends of baskets of commodities.

```{r comm.basket, echo=FALSE}

datay <- "GSG.Close"
ylim <- c(-10, 100)
dt.start = as.Date('2005-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```



This plot examines commodity performance relative to the GDP deflator

```{r comm.basket.gdp, echo=FALSE}

datay <- "GSG__Close__by__GDPDEF"
ylim <- c(0, 1.0)
dt.start = as.Date('2005-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```


```{r comm.basket.GSPC, echo=FALSE}

datay <- "GSG__Close__by__GSPC__Close"
ylim <- c(0, 0.1)
dt.start = as.Date('2005-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

### Crude oil

Look at a trend of West Texas Intermediate (WTI)

```{r Crude, echo=FALSE}

datay <- "DCOILWTICO.Value"
ylim <- c(-10, 150)
dt.start = as.Date('1987-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

# Tidy memory
rm(datay)
rm(ylim)
rm(dt.start)

```

This is ticker data from yahoo

```{r Crude.yahoo, echo=FALSE, fig.width = 9, fig.asp = 1.0}

datay <- "CL_F.Close"
ylim <- c(-10, 150)
dt.start = as.Date('2000-01-01')
p1 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

datay <- "CL_F.Volume"
ylim <- c(0, 1500000)
p2 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

datay <- "CL_F.Volume__YoY"
ylim <- c(-150, 150)
p3 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)


grid.arrange(p1,
             p2,
             p3,
             ncol = 1,
             top = "Crude oil prices and volume")

# Tidy up memory
rm(datay)
rm(ylim)
rm(dt.start)
rm(p1)
rm(p2)
rm(p3)

```



Take a look at both WTI and Brent crude. 

```{r crude.recent, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "DCOILWTICO.Value"
datay.aux <- "DCOILBRENTEU.Value"
datay.aux.1 <- "CL_F.Close"
dt.start = as.Date('2019-01-01')
my.plot <-
  plotSingleQuick(
    dfRecession,
    df.data,
    datay,
    ylim = c(-10, 150),
    dt.start,
    b.legend = TRUE,
    b.long.legend = TRUE
  )
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.1,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot

# Tidy up memory
rm(datay )
rm(datay.aux )
rm(datay.aux.1 )
rm(dt.start )


```


Real price of crude using producer price index for commodities

```{r crude.recent.real, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "DCOILWTICO__by__PPIACO"
datay.aux <- "DCOILBRENTEU__by__PPIACO"
dt.start = as.Date('1987-01-01')
my.plot <-
  plotSingleQuick(
    dfRecession,
    df.data,
    datay,
    ylim = c(0, 0.75),
    dt.start,
    b.legend = TRUE,
    b.long.legend = TRUE
  )
my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
  ),
  na.rm = TRUE
)

# Tidy up memory
rm(datay )
rm(datay.aux )
rm(dt.start )

```

```{r Crude_YoY, echo=FALSE}

datay <- "DCOILWTICO.Value__YoY"
ylim <- c(-100, 150)
dt.start = as.Date('1987-01-01')
b.legend <- TRUE
b.percentile <- TRUE
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.legend, b.percentile)

# Tidy up
rm(datay)
rm(ylim)
rm(dt.start)
rm(b.percentile)


```

```{r crude.yoy.recent, echo=FALSE}

datay <- "DCOILWTICO.Value__YoY"
ylim <- c(-100, 500)
dt.start = dt.recent
b.legend <- TRUE
b.percentile <- TRUE
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.legend, b.percentile)

# Tidy up
rm(datay)
rm(ylim)
rm(dt.start)
rm(b.legend)
rm(b.percentile)

```

### Gold

As risks increase investors often flock to safe haven assets like gold. An up-tick in prices can indicate investor uncertainty. This can be seen in the nominal price plot around 1980 and again in 2007.


```{r gold.nominal.price, echo=FALSE}

datay <- "GC_F.Close"
ylim <- c(0, 4000)
dt.start = as.Date('1970-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

# Tidy up memory
rm(datay)
rm(ylim)
rm(dt.start)

```

This plots out the real price of gold by two different deflators. PPI corrected price is a little higher, to be expected since CPI also includes the effects of sales tax and imports. The spike in 1980 is especially pronounced in this series.

```{r gold.by.index, echo=FALSE, fig.width = 9, fig.asp = 0.4}

# datay <- "LBMAGOLD.USD_PM.by.CPIAUCSL"
# ylim <- c(0, 12)
# dt.start = as.Date('1970-01-01')
# datay.aux <- "LBMAGOLD.USD_PM.by.PPIACO"
# my.plot <- plotSingle(
#   dfRecession,
#   df.data,
#   datax = "date",
#   datay,
#   titlelabel = "Real Price of Gold",
#   xlabel = "Date",
#   ylabel = getPlotYLabel(df.symbols, datay),
#   ylim,
#   xlim = c(dt.start, Sys.Date()),
#   b.legend = TRUE,
#   b.long.legend = TRUE
# )
# 
# my.plot + geom_line(
#   data = df.data,
#   aes_string(
#     x = "date",
#     y = datay.aux,
#     colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
#   ),
#   na.rm = TRUE
# )

```

See how nominal and real prices look year over year. From the long-term view seems like there is little difference in the three series. Although not shown, even over the near-term there is little difference in the series.

```{r gold.YoY, echo=FALSE, fig.width = 9, fig.asp = 0.4}

# datay <- "LBMAGOLD.USD_PM_YoY"
# ylim <- c(-75, 75)
# dt.start = as.Date('1970-01-01')
# datay.aux <- "LBMAGOLD.USD_PM.by.CPIAUCSL_YoY"
# datay.aux.1 <- "LBMAGOLD.USD_PM.by.PPIACO_YoY"
# my.plot <- plotSingle(
#   dfRecession,
#   df.data,
#   datax = "date",
#   datay,
#   titlelabel = "Price of Gold Year-Over-Year change",
#   xlabel = "Date",
#   ylabel = getPlotYLabel(df.symbols, datay),
#   ylim,
#   xlim = c(dt.start, Sys.Date()),
#   b.legend = TRUE,
#   b.long.legend = TRUE
# )
# 
# my.plot <- my.plot + geom_line(
#   data = df.data,
#   aes_string(
#     x = "date",
#     y = datay.aux,
#     colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
#   ),
#   na.rm = TRUE
# )
# 
# my.plot + geom_line(
#   data = df.data,
#   aes_string(
#     x = "date",
#     y = datay.aux.1,
#     colour = shQuote(getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n"))
#   ),
#   na.rm = TRUE
# )


```

See how gold correlates with the VIX. Both gold and VIX should respond to investor axiety, but it doesn't look like it correlates very well.

```{r corrGoldYoYVix, echo=FALSE}

# datax = "LBMAGOLD.USD_PM_YoY"
# datay = "VIXCLS"
# titlelabel <- paste(datay, " | ", datax)
# ylim <- c(0, 45)
# ylabel <- paste(datay, ", ", df.symbols[grep(datay, df.symbols$string.symbol),]$yLabel, sep="")
# xlim <- c(-50, 50)
# xlabel <- paste(datax, ", ", df.symbols[grep(datax, df.symbols$string.symbol),]$yLabel, sep="")
# bLegend <- FALSE
# bFitLinear <- TRUE
# dt.start = as.Date('2000-01-01')
# b.reverse.y = FALSE
# plotXvY(df.data, dfRecession, datax, datay, titlelabel, xlabel, ylabel, xlim, ylim, bLegend, bFitLinear, dt.start, b.reverse.y)

```


### Copper

Dr. Copper has a reputation as an indicator of economic malaise, but it does not seem to have much of a correlation with the recessions. The series below is from CME via Quandl. It has a lot of data so I am also looking at the smoothed version.

```{r plot.CHRISCMEHG1, echo=FALSE}
# datay <- "CHRISCMEHG1"
# datay_aux <- "CHRISCMEHG1_Smooth"
# ylim <- c(0, 5)
# dt.start = as.Date('1959-01-01')
# my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
#             getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, TRUE)
# my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)

```

```{r plot.CHRISCMEHG1.close, echo=FALSE}
# datay <- "CHRISCMEHG1"
# datay_aux <- "CHRISCMEHG1_Smooth"
# ylim <- c(0, 5)
# dt.start = as.Date('2008-01-01')
# my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
#             getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, TRUE)
# my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)

```

Copper is one of the commodities in the PPI so it is a bit of a proxy for how copper is doing relative to the basket of commodities.

```{r coppyer.by.index, echo=FALSE, fig.width = 9, fig.asp = 0.4}

# datay <- "CHRISCMEHG1.by.CPIAUCSL"
# ylim <- c(0, 0.03)
# dt.start = as.Date('1970-01-01')
# datay.aux <- "CHRISCMEHG1.by.PPIACO"
# my.plot <- plotSingle(
#   dfRecession,
#   df.data,
#   datax = "date",
#   datay,
#   titlelabel = "Real Price of Copper",
#   xlabel = "Date",
#   ylabel = getPlotYLabel(df.symbols, datay),
#   ylim,
#   xlim = c(dt.start, Sys.Date()),
#   b.legend = TRUE,
#   b.long.legend = TRUE
# )
# 
# my.plot + geom_line(
#   data = df.data,
#   aes_string(
#     x = "date",
#     y = datay.aux,
#     colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
#   ),
#   na.rm = TRUE
# )

```

The change in prices, year over year, do generally peak prior to a recession. The time and shape of this peak varies, but it still might be helpful. A couple of the large troughs do seem to correlate with the end of the recession. Likely this is because industrial production has also fallen.

```{r plot.CHRISCMEHG1.yoy, echo=FALSE}
# datay <- "CHRISCMEHG1_YoY"
# ylim <- c(-100, 100)
# dt.start = as.Date('1960-01-01')
# plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile = TRUE)

```

There is some correlation between copper and the smooth recession initiator, especially at the end of the recession.

```{r rollingcor.indpro.copper.yoy, echo=FALSE, fig.width = 10, fig.asp = .62}
# 
# datay1 <- "INDPRO_YoY"
# ylim1 <- c(-25, 25)
# 
# datay2 <- "CHRISCMEHG1_YoY"
# ylim2 <- c(-100, 100)
# 
# dt.start = as.Date('1960-01-01')
# 
# w <- 360
# corrName <- calcRollingCorr(dfRecession, df.data, df.symbols, datay1, ylim1, datay2, ylim2, w, dt.start)

```

Might be easier to see correlation in a dot plot format.

```{r corrscatter.indpro.copper.yoy, echo=FALSE}

# datay = "INDPRO_YoY"
# ylim <- c(-25, 25)
# ylabel <- paste(datay, ", ", df.symbols[grep(datay, df.symbols$string.symbol),]$yLabel, sep="")
# 
# datax = "CHRISCMEHG1_YoY"
# xlim <- c(-100, 100)
# xlabel <- paste(datax, ", ", df.symbols[grep(datax, df.symbols$string.symbol),]$yLabel, sep="")
# 
# titlelabel <- paste(datay, " | ", datax)
# bLegend <- FALSE
# bFitLinear <- TRUE
# dt.start = as.Date('1950-01-01')
# b.reverse.y = FALSE
# plotXvY(df.data, dfRecession, datax, datay, titlelabel, xlabel, ylabel, xlim, ylim, bLegend, bFitLinear, 
#         dt.start, b.reverse.y)

```


This is a legacy series from FRED. It has not been updated in a couple of years so I am assuming it will go away. 

```{r cuprice, echo=FALSE}

plotSingleQuick(dfRecession, df.data, datay = "PCOPPUSDM.Value",
                ylim = c(0, 12000), 
                dt.start = as.Date('1980-01-01'),
                b.legend = TRUE, b.percentile = TRUE)

```

## Oil Services

Amazing events in the first half of 2020, take a look at those

```{r crude.recent.bkr, echo=FALSE, fig.width = 13, fig.asp = 0.5}
##
# Crude
#datay <- "DCOILWTICO"
datay <- "CL_F.Close"
datay.aux <- "DCOILBRENTEU.Value"
dt.start = as.Date('2019-01-01')
p1 <-
  plotSingleQuick(
    dfRecession,
    df.data,
    datay,
    ylim = c(-10, 150),
    dt.start,
    b.legend = TRUE,
    b.long.legend = FALSE
  )
p1 <- p1 + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
  ),
  na.rm = TRUE
)

# Events on the crude oil price timeline
str.1 <- c("2020-01-20", "2020-03-05", "2020-03-08", "2020-03-30")
txt.1 <-
  c("First US Covid-19",
    "OPEC Fails to Agree",
    "S-R Price War",
    "OPEC Prod. Cuts Expire")
idx.list = 1
y.1 = 0
for (str.data in str.1) {
  y.1[idx.list] <- df.data[rownames(df.data) == as.Date(str.1[idx.list]), datay]
  idx.list <- idx.list + 1
}
d.bkr = data.table(dt = as.Date(str.1), y = y.1, txt = txt.1)
p1 <-
  p1 + geom_point(data = d.bkr, aes(x = dt, y = y))  + geom_text(data = d.bkr, aes(
    x = dt,
    y = y,
    label = txt,
    hjust = "right",
    vjust = "top"
  ))

# Events on the crude oil price timeline
str.1 <- c("2020-04-10")
txt.1 <-
  c("S-R Reach Deal")
idx.list = 1
y.1 = 0
for (str.data in str.1) {
  y.1[idx.list] <- df.data[rownames(df.data) == as.Date(str.1[idx.list]), datay]
  idx.list <- idx.list + 1
}
d.bkr.1 = data.table(dt = as.Date(str.1), y = y.1, txt = txt.1)
p1 <-
  p1 + geom_point(data = d.bkr, aes(x = dt, y = y)) + geom_text(data = d.bkr, aes(
    x = dt,
    y = y,
    label = txt,
    hjust = "right",
    vjust = "top"
  ))  + geom_point(data = d.bkr.1, aes(x = dt, y = y)) + geom_text(data = d.bkr.1, aes(
    x = dt,
    y = y+5,
    label = txt,
    hjust = "center",
    vjust = "bottom"
  ))

##-----------------------------------------------------------------------------------------------------------------##
# Baker
datay <- "BKR.Close"
p2 <-
  plotSingleQuick(
    dfRecession,
    df.data,
    datay,
    ylim = c(5, 60),
    dt.start,
    b.legend = TRUE,
    b.long.legend = FALSE
  )

# Events on the baker price timeline
str.1 <- c("2020-04-13")
txt.1 <-
  c("Restructure\n $15B GoodWill Impairment")
idx.list = 1
y.1 = 0
for (str.data in str.1) {
  y.1[idx.list] <- df.data[rownames(df.data) == as.Date(str.1[idx.list]), datay]
  idx.list <- idx.list + 1
}
d.bkr = data.table(dt = as.Date(str.1), y = y.1, txt = txt.1)
p2 <-
  p2 + geom_point(data = d.bkr, aes(x = dt, y = y))  + geom_text(data = d.bkr, aes(
    x = dt,
    y = y,
    label = txt,
    hjust = "center",
    vjust = "bottom"
  ))

# Events on the baker oil price timeline
str.1 <- c("2020-02-26")
txt.1 <-
  c("Worrell, 3,000\nSimonelli, 11,254\nBeattie, 5000")
idx.list = 1
y.1 = 0
for (str.data in str.1) {
  y.1[idx.list] <- df.data[rownames(df.data) == as.Date(str.1[idx.list]), datay]
  idx.list <- idx.list + 1
}
d.bkr = data.table(dt = as.Date(str.1), y = y.1, txt = txt.1)
p2 <-
  p2 + geom_point(data = d.bkr, aes(x = dt, y = y))  + geom_text(data = d.bkr, aes(
    x = dt,
    y = y,
    label = txt,
    hjust = "right",
    vjust = "top"
  ))

##-----------------------------------------------------------------------------------------------------------------##
# Haliburton
datay <- "HAL.Close"
p3 <-
  plotSingleQuick(
    dfRecession,
    df.data,
    datay,
    ylim = c(0, 60),
    dt.start,
    b.legend = TRUE,
    b.long.legend = FALSE
  )

# Events on the haliburton price timeline
str.1 <- c("2020-03-19")
txt.1 <-
  c("Furlough 3,500")
idx.list = 1
y.1 = 0
for (str.data in str.1) {
  y.1[idx.list] <- df.data[rownames(df.data) == as.Date(str.1[idx.list]), datay]
  idx.list <- idx.list + 1
}
d.hal = data.table(dt = as.Date(str.1), y = y.1, txt = txt.1)
p3 <-
  p3 + geom_point(data = d.hal, aes(x = dt, y = y))  + geom_text(data = d.hal, aes(
    x = dt,
    y = y,
    label = txt,
    hjust = "center",
    vjust = "top"
  ))



##-----------------------------------------------------------------------------------------------------------------##
# Schlumberger
datay <- "SLB.Close"
p4 <-
  plotSingleQuick(
    dfRecession,
    df.data,
    datay,
    ylim = c(0, 60),
    dt.start,
    b.legend = TRUE,
    b.long.legend = FALSE
  )

# Events on the schlumberger price timeline
str.1 <- c("2019-08-13","2020-03-25")
txt.1 <-
  c("%8.8B Goodwill Impairment", "CpeEx Cut 30%")
idx.list = 1
y.1 = 0
for (str.data in str.1) {
  y.1[idx.list] <- df.data[rownames(df.data) == as.Date(str.1[idx.list]), datay]
  idx.list <- idx.list + 1
}
d.slb = data.table(dt = as.Date(str.1), y = y.1, txt = txt.1)
p4 <-
  p4 + geom_point(data = d.slb, aes(x = dt, y = y))  + geom_text(data = d.slb, aes(
    x = dt,
    y = y,
    label = txt,
    hjust = "center",
    vjust = "top"
  ))


grid.arrange(p1,
             p2,
             ncol = 1,
             top = "Baker and Crude Oil Price Year-over-Year Changes")

grid.arrange(p1,
             p3,
             ncol = 1,
             top = "Haliburton and Crude Oil Price Year-over-Year Changes")

grid.arrange(p1,
             p4,
             ncol = 1,
             top = "Schlumberger and Crude Oil Price Year-over-Year Changes")


```

See how the players are doing

```{r crude.recent.bkr.players, echo=FALSE, fig.width = 13, fig.asp = 0.4}

##-----------------------------------------------------------------------------------------------------------------##
## Rig counts
datay <- "BKR_Total__YoY"
ylim <- c(-100, 150)
dt.start = as.Date('2019-01-01')
p1 <-
  plotSingleQuick(
    dfRecession,
    df.data,
    datay,
    ylim,
    dt.start,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = FALSE
  )

# Events on the rig count timeline
str.1 <- c("2020-01-20")
txt.1 <-
  c("First US Covid-19")
idx.list = 1
y.1 = 0
for (str.data in str.1) {
  y.1[idx.list] <- df.data[rownames(df.data) == as.Date(str.1[idx.list]), datay]
  idx.list <- idx.list + 1
}
d.rigtags = data.table(dt = as.Date(str.1), y = y.1, txt = txt.1)
p1 <-
  p1 + geom_point(data = d.rigtags, aes(x = dt, y = y))  + geom_text(data = d.rigtags, aes(
    x = dt,
    y = y+5,
    label = txt,
    hjust = "right",
    vjust = "bottom"
  ))

# Events on the crude oil price timeline
str.1 <- c("2020-03-08")
txt.1 <-
  c("S-R Price War")
idx.list = 1
y.1 = 0
for (str.data in str.1) {
  y.1[idx.list] <- df.data[rownames(df.data) == as.Date(str.1[idx.list]), datay]
  idx.list <- idx.list + 1
}
d.rigtags.1 = data.table(dt = as.Date(str.1), y = y.1, txt = txt.1)
p1 <-
  p1 + geom_point(data = d.rigtags.1, aes(x = dt, y = y))  + geom_text(data = d.rigtags.1, aes(
    x = dt,
    y = y,
    label = txt,
    hjust = "right",
    vjust = "bottom"
  ))


# Events on the crude oil price timeline
str.1 <- c("2020-03-30", "2020-04-10")
txt.1 <-
  c("OPEC Prod. Cuts Expire",
    "S-R Reach Deal")
idx.list = 1
y.1 = 0
for (str.data in str.1) {
  y.1[idx.list] <- df.data[rownames(df.data) == as.Date(str.1[idx.list]), datay]
  idx.list <- idx.list + 1
}
d.rigtags.2 = data.table(dt = as.Date(str.1), y = y.1, txt = txt.1)
p1 <-
  p1 + geom_point(data = d.rigtags.2, aes(x = dt, y = y)) + geom_text(data = d.rigtags.2, aes(
    x = dt,
    y = y,
    label = txt,
    hjust = "right",
    vjust = "top"
  ))  

##-----------------------------------------------------------------------------------------------------------------##
## Ticker price change
datay <- "BKR.Close__YoY"
datay.aux.1 <- "SLB.Close__YoY"
datay.aux.2 <- "HAL.Close__YoY"
p2 <-
  plotSingleQuick(
    dfRecession,
    df.data,
    datay,
    ylim = c(-100, 150),
    dt.start,
    b.legend = TRUE,
    b.long.legend = FALSE
  )
p2 <- p2 + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.1,
    colour = shQuote(datay.aux.1)
  ),
  na.rm = TRUE
)
p2 <- p2 + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.2,
    colour = shQuote(datay.aux.2)
  ),
  na.rm = TRUE
)



grid.arrange(p1,
             p2,
             ncol = 1,
             top = "Rig Count and Oil Field Services Companies")

```


## Federal Reserve

The federal reserve has an impact on the economy, here are some data series relating to that.

```{r WALCL, echo=FALSE}

plotSingleQuick(dfRecession, df.data, datay = "WALCL.Value", 
                ylim = c(0, 10000))

```

Little bit closer

```{r WALCL_Near}

plotSingleQuick(dfRecession, df.data, datay = "WALCL.Value", 
                ylim = c(0, 10000), 
                dt.start = as.Date('2003-01-01'))

```

### Federal Reserve Reverse Repo Agreements

Compare liabilities to reverse repo trends

```{r WLRRAL, echo=FALSE}

plotSingleQuick(dfRecession, df.data, datay = "WLRRAL.Value",
                ylim = c(0, 3000), 
                dt.start = as.Date('2003-01-01'),
                b.percentile = TRUE)

```

Take a look at more recent trends


```{r WLRRAL.close, echo=FALSE}

plotSingleQuick(dfRecession, df.data, datay = "WLRRAL.Value",
                ylim = c(0, 3000), 
                dt.start = as.Date('2020-01-01'),
                b.percentile = TRUE)

```

Spiky, might be easier to look at year-over-year

```{r WLRRAL.YoY, echo=FALSE}

plotSingleQuick(dfRecession, df.data, datay = "WLRRAL.Value__YoY",
                ylim = c(-100, 500), 
                dt.start = as.Date('2003-01-01'))

```

Normalized by GDP

```{r WLRRAL.by.GDP}

plotSingleQuick(dfRecession, df.data, datay = "WLRRAL__by__GDP", 
                ylim = c(0, 4), 
                dt.start =  as.Date('2003-01-01'))

```

### Overnight Bank Funding Rate

"The overnight bank funding rate is calculated using federal funds transactions and certain Eurodollar transactions. The federal funds market consists of domestic unsecured borrowings in U.S. dollars by depository institutions from other depository institutions and certain other entities, primarily government-sponsored enterprises, while the Eurodollar market consists of unsecured U.S. dollar deposits held at banks or bank branches outside of the United States. U.S.-based banks can also take Eurodollar deposits domestically through international banking facilities (IBFs). The overnight bank funding rate (OBFR) is calculated as a volume-weighted median of overnight federal funds transactions and Eurodollar transactions reported in the FR 2420 Report of Selected Money Market Rates.
Volume-weighted median is the rate associated with transactions at the 50th percentile of transaction volume. Specifically, the volume-weighted median rate is calculated by ordering the transactions from lowest to highest rate, taking the cumulative sum of volumes of these transactions, and identifying the rate associated with the trades at the 50th percentile of dollar volume. The published rates are the volume-weighted median transacted rate, rounded to the nearest basis point."
https://www.newyorkfed.org/markets/obfrinfo.


```{r OBFR_Near, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "OBFR.Value"
ylim <- c(0, 7)
datay.aux <- "OBFR99.Value"
datay.aux.1 <- "OBFR1.Value"
my.plot <- plotSingle(
  dfRecession,
  df.data,
  datax = "date",
  datay,
  titlelabel = getPlotTitle(df.symbols, datay),
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  ylim,
  xlim = c(as.Date('2018-01-01'), Sys.Date()),
  b.legend = TRUE,
  b.long.legend = TRUE
)

my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
  ),
  na.rm = TRUE
)

my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.1,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n"))
  ),
  na.rm = TRUE
)

x <- as.yearqtr(2016 + seq(0, 40)/4)
x.date <- as.Date(x)-1
my.plot + geom_vline(xintercept=as.numeric(x.date), linetype=4)


```

### Secured Overnight Financing Rate

"The Secured Overnight Financing Rate (SOFR) is a broad measure of the cost of borrowing cash overnight collateralized by Treasury securities. The SOFR includes all trades in the Broad General Collateral Rate plus bilateral Treasury repurchase agreement (repo) transactions cleared through the Delivery-versus-Payment (DVP) service offered by the Fixed Income Clearing Corporation (FICC), which is filtered to remove a portion of transactions considered “specials” "
https://apps.newyorkfed.org/markets/autorates/sofr

```{r SOFR_Near, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "SOFR.Value"
ylim <- c(0, 10)
datay.aux <- "SOFR99.Value"
datay.aux.1 <- "SOFR1.Value"
my.plot <- plotSingle(
  dfRecession,
  df.data,
  datax = "date",
  datay,
  titlelabel = getPlotTitle(df.symbols, datay),
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  ylim,
  xlim = c(as.Date('2018-01-01'), Sys.Date()),
  b.legend = TRUE,
  b.long.legend = TRUE
)

my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
  ),
  na.rm = TRUE
)

my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.1,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n"))
  ),
  na.rm = TRUE
)

add.quarter.lines(my.plot, dt.start.year = 2016)


```

Take a look at the variation (99th - 1st percentile)

```{r SOFR.dist, echo=FALSE}

datay <- "SOFR99__minus__SOFR1"
ylim <- c(0, 4)
dt.start = as.Date('2018-01-01')
my.plot <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

add.quarter.lines(my.plot, dt.start.year = 2016)

```

### Reserve Balances with Federal Reserve Banks

```{r WRESBALspread, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "WRESBAL.Value"
datay.aux <- "EXCSRESNW.Value"
datay.title <- getPlotTitle(df.symbols, datay.aux, str.sep = "\n")
datay.aux.1 <- "WALCL.Value"
datay.title.1 <- getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n")
ylim <- c(0, 10000)
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    "Federal Reserve Balances",
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(as.Date("1jan2003", "%d%b%Y"), Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my.plot <-
  my.plot + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux,
      colour = shQuote(datay.title)
    ),
    na.rm = TRUE
  )
my.plot <-
  my.plot + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux.1,
      colour = shQuote(datay.title.1)
    ),
    na.rm = TRUE
  )
my.plot

```


Hard to get a sense of these series in the absolute. Take a look relative to GDP.

```{r WRESBALspread.GPD, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "WRESBAL__by__GDP"
datay.aux <- "EXCSRESNW__by__GDP"
datay.title <- getPlotTitle(df.symbols, datay.aux, str.sep = "\n")
datay.aux.1 <- "WALCL__by__GDP"
datay.title.1 <-
  getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n")
ylim <- c(0, 40)
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    "Federal Reserve Balances as Percent of GDP",
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(as.Date("1jan2003", "%d%b%Y"), Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my.plot <-
  my.plot + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux,
      colour = shQuote(datay.title)
    ),
    na.rm = TRUE
  )
my.plot <-
  my.plot + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux.1,
      colour = shQuote(datay.title.1)
    ),
    na.rm = TRUE
  )
my.plot

```

By double entry book-keeping reserves+loans (assets) = deposit (liabilities). Does that really work?

```{r double.entrey.check, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "TOTLLNSA.Value"
datay.aux <- "DPSACBW027SBOG.Value"
datay.title <- getPlotTitle(df.symbols, datay.aux, str.sep = "\n")
datay.aux.1 <- "WRESBAL.Value"
datay.title.1 <-
  getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n")
datay.aux.2 <- "TOTLLNSA__plus__WRESBAL"
datay.title.2 <-
  getPlotTitle(df.symbols, datay.aux.2, str.sep = "\n")
ylim <- c(0, 18000)
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    "Loans, Reserves and Deposits",
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(as.Date("1jan1950", "%d%b%Y"), Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my.plot <-
  my.plot + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux,
      colour = shQuote(datay.title)
    ),
    na.rm = TRUE
  )
my.plot <-
  my.plot + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux.1,
      colour = shQuote(datay.title.1)
    ),
    na.rm = TRUE
  )
my.plot <-
  my.plot + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux.2,
      colour = shQuote(datay.title.2)
    ),
    na.rm = TRUE
  )
my.plot

```


### Correlation Between Reserves and Total Loans

As reserves increase there should be less lending. That correlation generally holds.

```{r WRESBAL_YoY, echo=FALSE, fig.width = 11, fig.asp = 0.4}

datay <- "WRESBAL.Value__YoY"
datay.aux <- "TOTLLNSA.Value__YoY"
datay.aux.scale <- 4
datay.title <- getPlotTitle(df.symbols, datay.aux, str.sep = "\n")
ylim <- c(-50, 100)
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    "Reserve Balances with Federal Reserve Banks and Total Loans",
    "Date",
    paste(datay, ", ", getPlotYLabel(df.symbols, datay), sep=""),
    c(as.Date("1jan2003", "%d%b%Y"), Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my.plot <-
  my.plot + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = df.data[[datay.aux]] * datay.aux.scale,
      colour = shQuote(datay.title)
    ),
    na.rm = TRUE
  )
my.plot <-
  my.plot + scale_y_continuous(
    sec.axis = sec_axis( ~ . * (1 / datay.aux.scale), 
    name = paste(datay.aux, ", Percent", sep ="")), 
    limits = ylim
  )
my.plot

```

Did the reserve balances increase after the 2016 and 2018 drops? Not in the same way. There are some relationships between the equities market and the reserves though.

```{r WRESBAL_YoY.to.market, echo=FALSE, fig.width = 7, fig.asp = 1.1 }


datay <- "WRESBAL.Value__YoY"
ylim <- c(-40, 150)
dt.start = as.Date('2015-01-01')
p1 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2015-08-24"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2016-01-08"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2018-02-05"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2018-10-11"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )

datay <- "X_GSPC.GSPC.Open"
datay_aux <- "X_GSPC.GSPC.Close"
ylim <- c(1500, d.GSPC.max)
p2 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend = FALSE,
    b.percentile = FALSE,
    b.long.legend = FALSE
  )

p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2015-08-24"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2016-01-08"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2018-02-05"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2018-10-11"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )


grid.arrange(p1,
             p2,
             ncol = 1,
             top = "Reserve balance YoY change and S&P Price")

```

Explicitly correlate reserve balances and total loans. It is a weak and noisy correlation.

```{r corrWRESBAL_YoY, echo=FALSE}

datax = "TOTLLNSA.Value__YoY"
datay = "WRESBAL.Value__YoY"
titlelabel <- paste(datay, " | ", datax)
ylim <- c(-40, 60)
ylabel <- paste(datay, ", ", df.symbols[grep(datay, df.symbols$string.symbol),]$yLabel, sep="")
xlim <- c(-30, 30)
xlabel <- paste(datax, ", ", df.symbols[grep(datax, df.symbols$string.symbol),]$yLabel, sep="")
bLegend <- FALSE
bFitLinear <- TRUE
dt.start = as.Date('2008-01-01')
b.reverse.y <- FALSE
plotXvY(df.data, dfRecession, datax, datay, titlelabel, xlabel, ylabel, xlim, ylim, bLegend, bFitLinear, dt.start, b.reverse.y)

```

### Interest on excess reserves

```{r IOERspread, echo=FALSE}

datay <- "CPIAUCSL.Value__YoY"
datay_aux <- "IOER.Value"
ylim <- c(-2.5, 7.5)
my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(as.Date("1jan2003","%d%b%Y"), Sys.Date()), ylim, TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)
my.plot

```

### Monetary Base

Currency trend, base

```{r BOGMBASE.trend, echo=FALSE}
# The billions and trillions conversion is not working here
datay <- "BOGMBASE.Value"
dt.start = as.Date('1959-01-01')
ylim <- c(0, 7000)
my.plot <-
  plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)
my.plot

```


```{r MB.to.Gold, echo=FALSE, fig.width = 7, fig.asp = 1.1 }


# datay <- "BOGMBASE"
# dt.start = as.Date('1959-01-01')
# ylim <- c(0, 7000)
# p1 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)
# p1 <-
#   p1 + geom_vline(
#     xintercept = as.Date("2015-08-24"),
#     linetype = "dashed",
#     color = "grey",
#     size = 1.0
#   )
# p1 <-
#   p1 + geom_vline(
#     xintercept = as.Date("2016-01-08"),
#     linetype = "dashed",
#     color = "grey",
#     size = 1.0
#   )
# p1 <-
#   p1 + geom_vline(
#     xintercept = as.Date("2018-02-05"),
#     linetype = "dashed",
#     color = "grey",
#     size = 1.0
#   )
# p1 <-
#   p1 + geom_vline(
#     xintercept = as.Date("2018-10-11"),
#     linetype = "dashed",
#     color = "grey",
#     size = 1.0
#   )
# 
# datay <- "LBMAGOLD.USD_PM"
# ylim <- c(0, 2500)
# p2 <-
#   plotSingle(
#     dfRecession,
#     df.data,
#     "date",
#     datay,
#     getPlotTitle(df.symbols, datay),
#     "Date",
#     getPlotYLabel(df.symbols, datay),
#     c(dt.start, Sys.Date()),
#     ylim,
#     b.legend = FALSE,
#     b.percentile = FALSE,
#     b.long.legend = FALSE
#   )
# 
# p2 <-
#   p2 + geom_vline(
#     xintercept = as.Date("2015-08-24"),
#     linetype = "dashed",
#     color = "grey",
#     size = 1.0
#   )
# p2 <-
#   p2 + geom_vline(
#     xintercept = as.Date("2016-01-08"),
#     linetype = "dashed",
#     color = "grey",
#     size = 1.0
#   )
# p2 <-
#   p2 + geom_vline(
#     xintercept = as.Date("2018-02-05"),
#     linetype = "dashed",
#     color = "grey",
#     size = 1.0
#   )
# p2 <-
#   p2 + geom_vline(
#     xintercept = as.Date("2018-10-11"),
#     linetype = "dashed",
#     color = "grey",
#     size = 1.0
#   )
# 
# 
# grid.arrange(p1,
#              p2,
#              ncol = 1,
#              top = "Monetary base and gold")

```


This used to trend along with GDP. It doesn't anymore.

```{r BOGMBASE.trend.by.GDP, echo=FALSE}

datay <- "BOGMBASE__by__GDP"
dt.start = as.Date('1959-01-01')
ylim <- c(0, 30)
my.plot <-
  plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)
my.plot

```

### Money supplies

Basic currency trend (currency component of M1)

```{r currrency.trend, echo=FALSE}

datay <- "WCURRNS.Value"
dt.start = as.Date('1970-01-01')
ylim <- c(0, 2500)
myplot <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)
myplot

```

```{r currrency.trend.yoy}

datay <- "WCURRNS.Value__YoY"
ylim <- c(0, 17)
myplot <- plotSingleQuick(dfRecession, df.data, datay, ylim, 
                          dt.start = as.Date('1980-01-01'),
                          b.percentile = TRUE)

myplot

# Tidy memory
rm(myplot)

```


```{r currrency.trend.yoy.close}

datay <- "WCURRNS.Value__YoY"
dt.start = as.Date('2000-01-01')
ylim <- c(0, 20)
myplot <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)
myplot

```


The rate of change of money supply could be an indicator of a recession. Let's see how that compares.

```{r M1_YoY, echo=FALSE}

datay <- "M1.Value__YoY"
ylim <- c(-15, 35)
datay_aux <- "M2.Value__YoY"
dt.start = as.Date('1980-01-01')
#myplot <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, TRUE)
my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)

```

### Intervention in the repo market

The federal reserve provides liquidity to the repo market, summary of that action


```{r RPONTSYD, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay.input <- "RPONTSYD.Value"
datay.title <- getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n")
ylim <- c(0, 80)
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay = datay.input,
    "Federal Overnight Reserve Repo Market",
    "Date",
    "Billions of Dollars/Euros",
    c(as.Date("1jan2003", "%d%b%Y"), Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )


```

```{r RPONTSYD.near, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay.input <- "RPONTSYD.Value"
datay.title <- getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n")
ylim <- c(0, 80)
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay = datay.input,
    "Federal Overnight Reserve Repo Market",
    "Date",
    "Billions of Dollars/Euros",
    c(as.Date("1jan2023", "%d%b%Y"), Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )


```

## European central bank

The European central band (ECB) has taken a different path compared to the US Federal Reserve bank.

```{r ECBASSETS, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "ECBASSETS.Value"
datay.aux <- "WALCL.Value"
datay.title <- getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n")
ylim <- c(0, 9000)
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    "Central Bank Assets",
    "Date",
    "Billions of Dollars/Euros",
    c(as.Date("1jan2003", "%d%b%Y"), Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my.plot <-
  my.plot + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux,
      colour = shQuote(datay.title)
    ),
    na.rm = TRUE
  )
my.plot

```


```{r ECBASSETS.by.GDP, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "WALCL__by__GDP"
datay.aux <- "ECBASSETS__by__EUNNGDP"
datay.aux.scale <- 0.125
datay.title <- getPlotTitle(df.symbols, datay.aux, str.sep = "\n")
ylim <- c(0, 40)
my.plot <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    "Central Bank Assets",
    "Date",
     getPlotYLabel(df.symbols, datay),
    c(as.Date("1jan2003", "%d%b%Y"), Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
my.plot <-
  my.plot + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = df.data[[datay.aux]] * datay.aux.scale,
      colour = shQuote(datay.title)
    ),
    na.rm = TRUE
  )

my.plot <-
  my.plot + scale_y_continuous(
    sec.axis = sec_axis( ~ . * (1 / datay.aux.scale), 
    name = paste(datay.aux, ", Percent", sep ="")), 
    limits = ylim
  )
my.plot

```

## Federal Debt

The government is a big driver of the economy, let's see what it is doing in the debt markets.

```{r GFDEBTN}

datay <- "GFDEBTN.Value"
ylim <- c(0, 35000000)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

```{r GFDEBTN_Log}

datay <- "GFDEBTN.Value__Log"
ylim <- c(12, 18)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```


```{r GFDEBTN_YoY}

datay <- "GFDEBTN.Value__YoY"
ylim <- c(-10, 25)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

### Federal debt as percent GDP

```{r GFDEGDQ188S}

datay <- "GFDEGDQ188S.Value"
ylim <- c(30, 150)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

### Federal deficit as percent GDP

```{r FYFSGDA188S}

datay <- "FYFSGDA188S.Value"
ylim <- c(-30, 5)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

Charlie Hatch has a nice format of deficit versus debt:

```{r corrDebtDeficit, echo=FALSE}

datax = "FYFSGDA188S.Value"
datay = "GFDEGDQ188S.Value"
titlelabel <- paste(datay, " | ", datax)
ylim <- c(30, 200)
ylabel <- paste(datay, ", ", df.symbols[grep(datay, df.symbols$string.symbol),]$yLabel, sep="")
xlim <- c(-20, 5)
xlabel <- paste(datax, ", ", df.symbols[grep(datax, df.symbols$string.symbol),]$yLabel, sep="")
bLegend <- FALSE
bFitLinear <- FALSE
dt.start = as.Date('1960-01-01')
b.reverse.y = TRUE
plotXvY(df.data, dfRecession, datax, datay, titlelabel, xlabel, ylabel, xlim, ylim, bLegend, bFitLinear, 
        dt.start, b.reverse.y)

```

## Nonfinancial Corporate Business Debt

What about Nonfinancial corporate business and debt securities? Hopefully this doesn't follow the business loan trends.

```{r nonfin, echo=FALSE}

datay <- "NCBDBIQ027S.Value"
ylim <- c(-25, 7500000)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

That is crazy steep. Time for a log format, see if that brings out the peaks and troughs. That's a litte better, it looks like there might be a change in slope prior to the recessions.


```{r nonfinlogplot, echo=FALSE}

datay <- "NCBDBIQ027S.Value__Log"
ylim <- c(10, 20)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

The derivative doesn't seem to be much help. There is not much correlation between the zero crossings and the NEBR recessions.

```{r nonfinderplot, echo=FALSE}

# datay <- "NCBDBIQ027S.Value__Log_Der"
# ylim <- c(-0.0005, 0.0005)
# plotSingleQuick(dfRecession, df.data, datay, ylim)

```

```{r nonfinderYoYplot, echo=FALSE}

datay <- "NCBDBIQ027S.Value__YoY"
ylim <- c(-5, 20)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

## Debt cycle

This analysis roughly follows the ideas in the "Big Debt Crises" book by Ray Dalio. 

### Total loans

One business cycle theory describes recessions as a market adjustment to mis-allocated assets, often fueled by an credit expansion. That makes the volume of loans an interesting feature to look at. In the presentation of data it looks like the great recession had the largest impact.

```{r realloans, echo=FALSE}

datay <- "TOTLLNSA.Value"
ylim <- c(-25, 12500)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

Plotting the year over year growth rate helps pull out those small changes in the early years in the data. Peaks can be seen prior to most recessions.

```{r totloans, echo=FALSE}

datay <- "TOTLLNSA.Value__YoY"
ylim <- c(-10, 25)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

Zoom in to the last couple of decades

```{r totloansnear, echo=FALSE}

datay <- "TOTLLNSA.Value__YoY"
ylim <- c(-10, 15)
dt.start = as.Date('2000-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

```{r totloanssnooth, echo=FALSE}

datay <- "TOTLLNSA.Value__SmoothDer"
ylim <- c(-3.0, 3.0)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

As long term interest rates rise, loans should start to tick down. To check this, the total loans and 10 to 1 year spreads are plotted. This is generally the trend observed.

```{r totloansYield, echo=FALSE}

datay <- "TOTLLNSA.Value__YoY"
datay_aux<- "DGS10TO1"
ylim <- c(-10, 25)

my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(as.Date("1jan1960","%d%b%Y"), Sys.Date()), ylim, TRUE)
my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)


```

There is a good correlation between these two variables. This next section plots that correction explicitly.


### Total loans as percent of GDP

This is the total loans. I think the picture is too broad to point to a specific sector of the economy. The debt burden assumes interest rates are tied to the 10-year treasury: (TOTLNNSA * DGS10) / 100

```{r USTotalDebt.by.GDP, echo=FALSE, fig.width = 7, fig.asp = 1.1}

datay <- "TOTLNNSA__by__GDP"
ylim <- c(0, 50)
dt.start <- as.Date("1jan1945","%d%b%Y")
b.legend <- FALSE
b.percentile <- FALSE
p1 <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, b.legend, b.percentile)

datay<- "TOTLNNSA__INTEREST__by__GDP"
ylim <- c(0, 4)
b.legend <- FALSE
b.percentile <- TRUE
p2 <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, b.legend, b.percentile)

grid.arrange(p1, p2, ncol = 1, top = "Total Debt and Debt Burdens")

```

### Commercial and industral loans

Business loans should slow before the recession (a contraction in credit as rates rise).



### Commercial and industrial loans as percent of GDP and and income

Look at business debt normalized by GDP over the entire time series. This ratio often peaks at the mid-point of a recession.

https://www.wsj.com/articles/this-isnt-your-fathers-corporate-bond-market-11590574555

"Bonds are behaving more like bank debt, which tends to remain stable or even increase at the onset of recessions, as lenders keep distressed clients afloat—and only later turn off the taps. This was confirmed by a recent report from the Bank for International Settlements. It also found a tight link between this lending cycle and the “real” economy’s booms and busts."

I assume that interest is related to the 10-year treasure: (TOTCINSA * DGS10) / 100

```{r BusinessDebt.by.GDP, echo = FALSE, fig.width = 7, fig.asp = 1.3}


datay <- "TOTCINSA__by__GDP"
datay.aux <- "CPROFIT__by__GDP"
ylim <- c(5, 20)
dt.start <- as.Date("1jan1980", "%d%b%Y")
b.legend <- FALSE
b.percentile <- FALSE
p1 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend,
    b.percentile = TRUE
  )

datay <- "TOTCINSA__INTEREST__by__GDP"
ylim <- c(0.0, 1.5)
b.legend <- FALSE
b.percentile <- TRUE
p2 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend,
    b.percentile
  )

datay <- "A053RC1Q027SBEA__by__GDP"
ylim <- c(5, 15)
b.legend <- TRUE
b.percentile <- TRUE
p3 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend,
    b.percentile
  )
p3 <-
  p3 + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux,
      colour = shQuote(datay.aux)
    ),
    na.rm = TRUE
  )

grid.arrange(p1, p2, p3, ncol = 1, top = "Business Loans and Debt Burdens")

# Tidy memory
rm(p1)
rm(p2)
rm(p3)

```

### Farm loans

See how the farming sector is fairing.

```{r FarmLoans.by.GDP, echo = FALSE, fig.width = 7, fig.asp = 1.3}


datay <- "ASFMA__by__GDP"
datay.aux <- "CPROFIT__by__GDP"
ylim <- c(0.5, 1.50)
dt.start <- as.Date("1jan1990", "%d%b%Y")
b.legend <- FALSE
b.percentile <- FALSE
p1 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend,
    b.percentile = TRUE
  )

datay <- "ASFMA__INTEREST__by__GDP"
ylim <- c(0.025, 0.125)
b.legend <- FALSE
b.percentile <- TRUE
p2 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend,
    b.percentile
  )

datay <- "FARMINCOME__by__GDP"
ylim <- c(0, 2)
b.legend <- TRUE
b.percentile <- TRUE
p3 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend,
    b.percentile
  )

grid.arrange(p1, p2, p3, ncol = 1, top = "Farm Loans and Debt Burdens")

```

### Real estate loans

Data taken from H.8 Assets and Liabilities of Commercial Banks in the United States. Take a look at SA and NSA data series as weekly and month updates. It should all be similar at this scale.

This gives a big picture, but makes it hard to connect the loans with the income needed to cover those loans. In the next section, loans will be broken up by commercial and residential.

```{r realestate, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "REALLNNSA.Value"
datay.aux <- "REALLN.Value"
datay.aux.1 <- "RELACBW027NBOG.Value"
datay.aux.2 <- "RELACBW027SBOG.Value"
ylim <- c(0, 6000)
dt.start <- as.Date("1jan1945","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  titlelabel = "All Real Estate Loans (Commercial Banks, H.8)",
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.1,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.2,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.2, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot

```

### Real Estate (Residential)

In absolute terms the mortgages have increased, but it does not appear to be out of line with the overall economy.

```{r realestate.res, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "RREACBM027NBOG.Value"
datay.aux <- "RREACBM027SBOG.Value"
datay.aux.1 <- "RREACBW027SBOG.Value"
datay.aux.2 <- "RREACBW027NBOG.Value"
datay.aux.3 <- "MSPUS__times__HSN1FNSA__plus__EXHOSLUSM495S"
ylim <- c(1000, 3000)
dt.start <- as.Date("1jun2004","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  titlelabel = "Residential Real Estate Loans (Commercial Banks, H.8)",
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.1,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.2,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.2, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.3,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.3, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot

```


Normalized by GDP it is easier to see the peak in 2008 and that loan levels appear reasonable at the commercial banks. I updated this plot to include the estimated single-family home sales volume to give a sense of percentage of home sales that are cash.

```{r realestate.by.gdp, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "RREACBM027NBOG__by__GDP"
datay.aux <- "RREACBM027SBOG__by__GDP"
datay.aux.1 <- "RREACBW027SBOG__by__GDP"
datay.aux.2 <- "RREACBW027NBOG__by__GDP"
datay.aux.3 <- "MSPUS__times__HSN1FNSA__plus__EXHOSLUSM495S__by__GDP"
ylim <- c(5, 16)
dt.start <- as.Date("1jun2004","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  titlelabel = "Residential Real Estate Loans (Commercial Banks, H.8)\nPercent of GDP",
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.1,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.2,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.2, str.sep = "\n"))
  ),
  na.rm = TRUE
)

my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.3,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.3, str.sep = "\n"))
  ),
  na.rm = TRUE
)

my.plot

```

Maybe the GSE's are making loans. Take a look at the total mortgages from Z.1 as a percentage of GDP. That does not look too far off trend (ignoring that peak in 2008).

I am assuming that personal income is paying for the mortgages.

### Real estate (residential) as percent of GDP and and income

```{r real.estate.by.GDP, echo=FALSE, fig.width = 7, fig.asp = 1.3}

datay <- "ASHMA__by__GDP"
ylim <- c(10, 80)
dt.start <- as.Date("1jan1955", "%d%b%Y")
p1 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend = FALSE,
    b.percentile = FALSE
  )

datay <- "ASHMA__INTEREST__by__GDP"
ylim <- c(0.3, 6)
p2 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend = FALSE,
    b.percentile = TRUE
  )

datay <- "A065RC1A027NBEA__by__GDP"
datay.aux <- "PI__by__GDP"
ylim <- c(75, 105)
b.legend <- TRUE
b.percentile <- TRUE
p3 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend,
    b.percentile
  )
p3 <-
  p3 + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux,
      colour = shQuote(datay.aux)
    ),
    na.rm = TRUE
  )

grid.arrange(p1, p2, p3, ncol = 1, top = "Residential Morgtage and Interest Burdens")

```

How do the number of starts compare to population?

```{r realestate.start.div.pop, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "HOUST__div__POPTHM"
ylim <- c(0, 0.01)
dt.start <- as.Date("1jun2004","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  titlelabel = "Housing starts divided by US population",
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)

my.plot

```

### Consumer loans

Focusing on the consumer sector the growth in debt and incomes can be directly compared. Personal income, as a percent of GDP, remains nearly constant. It is not uncommon for the personal income to rise prior to a recession. Likely this reflect increasing asset prices and market returns. Also interesting to see the loans pick up after interest rates dropped in 1982.

### Consumer loans as percent of GDP and and income

```{r ConsumerDebt.by.GDP, echo=FALSE, fig.width = 7, fig.asp = 1.6}

datay <- "CONSUMERNSA__by__GDP"
ylim <- c(5, 8)
dt.start <- as.Date("1jan1955","%d%b%Y")
b.legend <- FALSE
b.percentile <- FALSE
p0 <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, b.legend, b.percentile)

datay <- "CONSUMERNSA.Value__YoY"
ylim <- c(-15, 30)
dt.start <- as.Date("1jan1955","%d%b%Y")
b.legend <- FALSE
b.percentile <- FALSE
p1 <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, b.legend, b.percentile)

datay<- "CONSUMERNSA__INTEREST__YoY"
ylim <- c(-15, 30)
b.legend <- FALSE
b.percentile <- TRUE
p2 <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, b.legend, b.percentile)

datay <- "A065RC1A027NBEA.Value__YoY"
datay.aux <- "PI.Value__YoY"
ylim <- c(-5, 15)
b.legend <- TRUE
b.percentile <- TRUE
p3 <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, b.legend, b.percentile)
p3 <- p3 + geom_line(data=df.data, aes_string(x="date", y=datay.aux, colour=shQuote(datay.aux)), na.rm = TRUE)

datay <- "DRCLACBS.Value"
ylim <- c(1, 5)
b.legend <- TRUE
b.percentile <- TRUE
p4 <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, b.legend, b.percentile)

grid.arrange(p0, p1, p2, p3, p4, ncol = 1, top = "Consumer Debt and Debt Burdens")

# Tidy up memory
rm(p0)
rm(p1)
rm(p2)
rm(p3)
rm(p4)

```

Take a closer look since the 2008 recession. Looks like loans are starting to slow as the interest burden rises and incomes remain stable. There are some anomolies in the A065RC1A027NBEA data series because it only updates onces a year. the PI series updates once a month but is noisier and seasonally adjusted. It also shows incomes rising in the middle of the 2008 recession, which doesn't seem to be accurate.

```{r ConsumerDebt.by.GDP.near, echo=FALSE, fig.width = 7, fig.asp = 1.3}

datay <- "CONSUMERNSA__by__GDP"
ylim <- c(5, 8)
dt.start <- as.Date("1jan2000","%d%b%Y")
b.legend <- FALSE
b.percentile <- FALSE
p1 <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, b.legend, b.percentile)

datay<- "CONSUMERNSA__INTEREST__by__GDP"
ylim <- c(0.5, 0.9)
b.legend <- FALSE
b.percentile <- TRUE
p2 <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, b.legend, b.percentile)

datay <- "A065RC1A027NBEA__by__GDP"
datay.aux <- "PI__by__GDP"
ylim <- c(80, 90)
b.legend <- TRUE
b.percentile <- TRUE
p3 <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, b.legend, b.percentile)
p3 <- p3 + geom_line(data=df.data, aes_string(x="date", y=datay.aux, colour=shQuote(datay.aux)), na.rm = TRUE)

grid.arrange(p1, p2, p3, ncol = 1, top = "Consumer Debt and Debt Burdens")

```

## Repo market
This market went through some stress in 2008, it is happening again so setup some plots to watch it.

### Nonfincial corporate business security repo asset level


```{r nonfin.corp.securty.repo.asset.by.GDP, echo=FALSE, fig.width = 7, fig.asp = 1.0}

datay <- "SRPSABSNNCB__by__GDP"
ylim <- c(0, 1)
dt.start <- as.Date("1jan1955", "%d%b%Y")
p1 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend = FALSE,
    b.percentile = FALSE
  )
p1

```

## Bonds

### T-Bills and Yield Curve

Speaking of loans, interest rates also play into this. This analysis will focus on treasure bills. The 3-month is plotted below. The yield flattens before a recession as investors go long on bonds and short on equities.

```{r bond3month }

datay <- "TB3MS.Value"
datay.aux <- "DTB3.Value"
ylim <- c(0, 20)
p1 <- plotSingleQuickModern(datay, ylim)
p1 + geom_line(data=df.data, aes_string(x="date", y=datay.aux, colour=shQuote(datay.aux)), na.rm = TRUE)

```

```{r bond3month.recent }

datay <- "TB3MS.Value"
datay.aux <- "DTB3.Value"
ylim <- c(0, 6.0)
dt.start = as.Date('2017-01-01')
p1 <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, TRUE)
p1 + geom_line(data=df.data, aes_string(x="date", y=datay.aux, colour=shQuote(datay.aux)), na.rm = TRUE)

```
# ```{r bond3monthlibor, echo=FALSE }
# 
# datay <- "TB3MS"
# datay_aux <- "USD1MTD156N"
# ylim <- c(0, 12)
# dt.start = as.Date('1985-01-01')
# my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
#             getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, TRUE)
# my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)
# 
# my.plot
# 
# ```
Check out LIBOR and fed funds rate



The 1-year is plotted below. The yield flattens before a recession as investors go long on bonds and short on equities.

```{r bond1, echo=FALSE }

plotSingleQuickModern(datay = "DGS1.Value", ylim = c(0, 20))

```

```{r bond10 }

datay <- "DGS10.Value"
datay.aux <- "X_TNX.TNX.Close"
ylim <- c(0, 20)
p1 <- plotSingleQuickModern(datay, ylim)
p1 + geom_line(data=df.data, aes_string(x="date", y=datay.aux, colour=shQuote(datay.aux)), na.rm = TRUE)

```

Close in, the trend towards inversion be more easily seen. I am also comparing data from the CBOE as well as FRED. 

```{r bond10.recent, echo=FALSE, fig.width = 9, fig.asp = 0.4 }

datay <- "DGS10.Value"
datay.aux <- "X_TNX.TNX.Open"
datay.aux1 <- "DTB3.Value"
datay.aux2 <- "X_IRX.IRX.Open"
ylim <- c(-0.5, 6.0)
dt.start = as.Date('2018-01-01')
p1 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    b.legend = TRUE,
    b.long.legend = TRUE
  )
p1 <-
  p1 + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux,
      colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
    ),
    na.rm = TRUE
  )
p1 <-
  p1 + geom_line(
    data = df.data,
    aes_string(
      x = "date",
      y = datay.aux1,
      colour = shQuote(getPlotTitle(df.symbols, datay.aux1, str.sep = "\n"))
    ),
    na.rm = TRUE
  )
p1 + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux2,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux2, str.sep = "\n"))
  ),
  na.rm = TRUE
)

```

Bond yields are a good proxy for interest rates. As rates rise the theory goes that loans should decrease (inverse correlation).

```{r rollingcorLoansInterest, echo=FALSE, fig.width = 10, fig.asp = .62}

datay1 <- "DGS10TO1__Smooth__short"
ylim1 <- c(-5, 5)

datay2 <- "TOTLLNSA.Value__YoY"
ylim2 <- c(-25, 25)

dt.start <- as.Date("1jan1985","%d%b%Y")

w <- 200
corrName <- calcRollingCorr(dfRecession, df.data, df.symbols, datay1, ylim1, datay2, ylim2, w, dt.start)

```

And a longer window

```{r rollingcorLoansInterestLong, echo=FALSE, fig.width = 10, fig.asp = .62}

datay1 <- "DGS10.Value"
ylim1 <- c(0, 20)

datay2 <- "TOTLLNSA.Value__YoY"
ylim2 <- c(-25, 25)

dt.start <- as.Date("1jan1985","%d%b%Y")

w <- 30
corrName <- calcRollingCorr(dfRecession, df.data, df.symbols, datay1, ylim1, datay2, ylim2, w, dt.start)

```


The yield curve (30 year bond rate minus the 10 year bond rate) may not be a good recession indicator, but a collapse is not good (https://blogs.wsj.com/moneybeat/2018/04/30/theres-more-than-one-part-of-the-yield-curve-getting-flatter/).

```{r Yieldcurve_DGS30TO10, echo=FALSE}
datay <- "DGS30TO10"

plotSingleQuickModern(datay, ylim = c(-1, 2.5), b.percentile = TRUE)

```

The yield curve (10 year bond rate minus the 1 year bond rate) seems to a good indicator of an oncoming recession. It could be a buy indicator by itself.

```{r Yieldcurve_DGS10TO1,echo=FALSE}
datay <- "DGS10TO1"

ylim <- c(-5, 5)
p1 <- plotSingleQuickModern(datay, ylim)
p1

```

```{r Yieldcurve_DGS10TOTB3MS, echo=FALSE}
datay <- "DGS10TOTB3MS"

ylim <- c(-5, 5)
p1 <- plotSingleQuickModern(datay, ylim)
p1

```

More recent data

```{r YieldcurveRecent, echo=FALSE}

datay <- "DGS10TOTB3MS"
datay_aux <- "DGS10TO1"
ylim <- c(-3, 5)
datay_aux2 <- "DGS10TO2"
datay_aux3 <- "DGS30TO10"
dt.start = as.Date('1995-01-01')
my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux2, colour=shQuote(datay_aux2)), na.rm = TRUE)
my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux3, colour=shQuote(datay_aux3)), na.rm = TRUE)

```

Just the last 24 months or so.

```{r YieldcurveRecent.twoyears, echo=FALSE}

datay <- "DGS10TOTB3MS"
datay_aux <- "DGS10TO1"
ylim <- c(-2.00, 3.00)
datay_aux2 <- "DGS10TO2"
datay_aux3 <- "DGS30TO10"
dt.start = as.Date('2018-01-01')
my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux2, colour=shQuote(datay_aux2)), na.rm = TRUE)
my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux3, colour=shQuote(datay_aux3)), na.rm = TRUE)

```

Plot the 10 Year to 3 month over a few decades to see what the outling cases look like

```{r YieldcurveRecent.twoyears.stats, echo=FALSE}

datay <- "DGS10TOTB3MS"
ylim <- c(-2, 4)
dt.start = as.Date('1989-01-01')
b.legend <- FALSE
b.percentile <- TRUE
plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, b.legend, b.percentile)

```

The last two year compare favorably with the period around the 2015-2016 turndown, driven primarily by slowing of the Chinese GDP. Not a debt-driven cycle.

```{r YieldcurveRecent.twoyears.similar, echo=FALSE}
datay <- "DGS10TOTB3MS"
ylim <- c(-1.0, 2)
i.window = 60
my.data <- plotSimilarPeriods(df.data, dfRecession, df.symbols, datay, ylim, i.window)
my.data[[1]]

```



```{r Yieldcurve_DGS10TO2, echo=FALSE}
datay <- "DGS10TO2"

plotSingleQuickModern(datay, ylim = c(-2.5, 5), b.percentile = TRUE)

```

This plot format was suggested by a mises.org article (https://mises.org/wire/yield-curve-accordion-theory), but they only went back to 1988. The date seemed arbitrary so I went back further in time.

```{r YieldAccordian, echo=FALSE}

datay <- "GS5.Value"
datay_aux1<- "DGS1.Value"
datay_aux2<- "DGS10.Value"
datay_aux3 <- "TB3MS.Value"
datay_aux4 <- "DGS30.Value"
datay_aux5 <- "FEDFUNDS.Value"
datay_aux6 <- "IOER.Value"
ylim <- c(0, 20)

my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(as.Date("1jan1945","%d%b%Y"), Sys.Date()), ylim, TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux1, colour=shQuote(datay_aux1)), na.rm = TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux2, colour=shQuote(datay_aux2)), na.rm = TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux3, colour=shQuote(datay_aux3)), na.rm = TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux4, colour=shQuote(datay_aux4)), na.rm = TRUE)
my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux5, colour=shQuote(datay_aux5)), na.rm = TRUE)
my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux6, colour=shQuote(datay_aux5)), na.rm = TRUE)

```

Take a look at more recent data

```{r YieldAccordianShort, echo=FALSE}

datay <- "GS5.Value"
datay_aux1<- "DGS1.Value"
datay_aux2<- "DGS10.Value"
datay_aux3 <- "TB3MS.Value"
datay_aux4 <- "DGS30.Value"
datay_aux5 <- "FEDFUNDS.Value"
datay_aux6 <- "IOER.Value"
ylim <- c(0, 6)

my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(as.Date("1jan2008","%d%b%Y"), Sys.Date()), ylim, TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux1, colour=shQuote(datay_aux1)), na.rm = TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux2, colour=shQuote(datay_aux2)), na.rm = TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux3, colour=shQuote(datay_aux3)), na.rm = TRUE)
my.plot <- my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux4, colour=shQuote(datay_aux4)), na.rm = TRUE)
my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux5, colour=shQuote(datay_aux5)), na.rm = TRUE)
my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux5, colour=shQuote(datay_aux6)), na.rm = TRUE)

```

Try looking at a 1-year average of the above time series

```{r YieldAccordianYr, echo=FALSE}

GS5Yr <- period.apply(GS5, endpoints(GS5,"years", 1), mean)

```

### High quality bonds 

```{r AAA}

datay <- "AAA.Value"
ylim <- c(1.5, 10)
dt.start = as.Date('1997-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

### High quality bonds to 10-year treasury

High quality bonds long-term trend.

```{r AAADGS10}

datay <- "DGS10ByAAA"
ylim <- c(1, 6.0)
dt.start = as.Date('1967-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```


High quality bonds near-term trend.

```{r AAADGS10.near}

datay <- "DGS10ByAAA"
ylim <- c(1, 6.0)
dt.start = as.Date('2007-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

### High yield spread

"This data represents the Option-Adjusted Spread (OAS) of the ICE BofAML US Corporate A Index, a subset of the ICE BofAML US Corporate Master Index tracking the performance of US dollar denominated investment grade rated corporate debt publicly issued in the US domestic market. This subset includes all securities with a given investment grade rating A.
The ICE BofAML OASs are the calculated spreads between a computed OAS index of all bonds in a given rating category and a spot Treasury curve. An OAS index is constructed using each constituent bond‚Äôs OAS, weighted by market capitalization. When the last calendar day of the month takes place on the weekend, weekend observations will occur as a result of month ending accrued interest adjustments."

- ICE Benchmark Administration Limited (IBA), ICE BofAML US Corporate A Option-Adjusted Spread [BAMLC0A3CA], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/BAMLC0A3CA, July 4, 2019.


```{r ASpread}

datay <- "BAMLC0A3CA.Value"
ylim <- c(0, 7)
dt.start = as.Date('1997-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

### Municipal bond market

Suggest by a WSJ article, change in volume for high-risk muni's. Doesn't look like there is much too it yet.

https://www.wsj.com/articles/risky-municipal-bonds-are-on-a-hot-streak-11558949401?mod=hp_lead_pos3

```{r HYMB.plot.near, fig.width = 7, fig.asp = 1.3 }

datay <- "HYMB.Close"
ylim <- c(40, 62)
dt.start = as.Date('2011-01-01')
p1 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2015-08-24"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )

p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2016-01-08"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2018-02-05"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1 <-
  p1 + geom_vline(
    xintercept = as.Date("2018-10-11"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )

datay <- "HYMB.Volume"
ylim <- c(0, 1750000)
p1.vol <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

p1.vol <-
  p1.vol + geom_vline(
    xintercept = as.Date("2015-08-24"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )

p1.vol <-
  p1.vol + geom_vline(
    xintercept = as.Date("2016-01-08"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1.vol <-
  p1.vol + geom_vline(
    xintercept = as.Date("2018-02-05"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p1.vol <-
  p1.vol + geom_vline(
    xintercept = as.Date("2018-10-11"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )


datay <- "X_GSPC.GSPC.Open"
datay_aux <- "X_GSPC.GSPC.Close"
ylim <- c(1500, d.GSPC.max )
p2 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    TRUE
  )

p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2015-08-24"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2016-01-08"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2018-02-05"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )
p2 <-
  p2 + geom_vline(
    xintercept = as.Date("2018-10-11"),
    linetype = "dashed",
    color = "grey",
    size = 1.0
  )


grid.arrange(p1,
             p1.vol,
             p2,
             ncol = 1,
             top = "High Yield Muni's and S&P Price")
```

### Total Loans and yield curve correlation

This relationship was suggest by Charlie and it is an interesting one. As the yield curve flattens (10-year and 1-year rates converge), total loans grow. The generalization is not always accurate, but it does fit.

```{r corrLoansYield, echo=FALSE}

datax = "TOTLLNSA.Value__YoY"
datay = "DGS10TO1"
titlelabel <- paste(datay, " | ", datax)
ylim <- c(-5, 10)
ylabel <- paste(datay, ", ", df.symbols[grep(datay, df.symbols$string.symbol),]$yLabel, sep="")
xlim <- c(-10, 20)
xlabel <- paste(datax, ", ", df.symbols[grep(datax, df.symbols$string.symbol),]$yLabel, sep="")
bLegend <- FALSE
bFitLinear <- TRUE
dt.start = as.Date('2000-01-01')
b.reverse.y = FALSE
plotXvY(df.data, dfRecession, datax, datay, titlelabel, xlabel, ylabel, xlim, ylim, bLegend, bFitLinear, 
        dt.start, b.reverse.y)

```

I wanted to see how this looked compared to the 3 month


```{r corrLoansYield.threemonth, echo=FALSE}

datax = "TOTLLNSA.Value__YoY"
datay = "DGS10TOTB3MS"
titlelabel <- paste(datay, " | ", datax)
ylim <- c(-4, 6)
ylabel <- paste(datay, ", ", df.symbols[grep(datay, df.symbols$string.symbol),]$yLabel, sep="")
xlim <- c(-10, 15)
xlabel <- paste(datax, ", ", df.symbols[grep(datax, df.symbols$string.symbol),]$yLabel, sep="")
bLegend <- FALSE
bFitLinear <- TRUE
dt.start = as.Date('1980-01-01')
b.reverse.y = FALSE
plotXvY(df.data, dfRecession, datax, datay, titlelabel, xlabel, ylabel, xlim, ylim, bLegend, bFitLinear, 
        dt.start, b.reverse.y)

```

### Consumer loans and yield curve correlation

Compared to business loans, consumer loans seem to have to response to the 10Y to 3M yield curve. 

```{r corrConsumerYield.threemonth, echo=FALSE}

datax = "CONSUMERNSA.Value__YoY"
datay = "DGS10TOTB3MS"
titlelabel <- paste(datay, " | ", datax)
ylim <- c(-5, 7)
ylabel <- paste(datay, ", ", df.symbols[grep(datay, df.symbols$string.symbol),]$yLabel, sep="")
xlim <- c(-20, 30)
xlabel <- paste(datax, ", ", df.symbols[grep(datax, df.symbols$string.symbol),]$yLabel, sep="")
bLegend <- FALSE
bFitLinear <- TRUE
dt.start = as.Date('1970-01-01')
b.reverse.y = FALSE
plotXvY(df.data, dfRecession, datax, datay, titlelabel, xlabel, ylabel, xlim, ylim, bLegend, bFitLinear, 
        dt.start, b.reverse.y)

```

### Business loans and yield curve correlation

```{r corrBusLoansYield.threemonth, echo=FALSE}

datax = "BUSLOANS.Value__YoY"
datay = "DGS10TOTB3MS"
titlelabel <- paste(datay, " | ", datax)
ylim <- c(-4, 7)
ylabel <- paste(datay, ", ", df.symbols[grep(datay, df.symbols$string.symbol),]$yLabel, sep="")
xlim <- c(-30, 25)
xlabel <- paste(datax, ", ", df.symbols[grep(datax, df.symbols$string.symbol),]$yLabel, sep="")
bLegend <- FALSE
bFitLinear <- TRUE
dt.start = as.Date('1970-01-01')
b.reverse.y = FALSE
plotXvY(df.data, dfRecession, datax, datay, titlelabel, xlabel, ylabel, xlim, ylim, bLegend, bFitLinear, 
        dt.start, b.reverse.y)

```

That's pretty good correlation. Let's see what the rolling correlation looks like.

```{r rollingcorTOTLNNSA_YoYPSAVE, fig.width = 10, fig.asp = .62}

datay1 <- "TOTLLNSA.Value__YoY"
ylim1 <- c(-10, 20)

datay2 <- "DGS10TO1"
ylim2 <- c(-5, 10)

dt.start <- as.Date("1jan1960","%d%b%Y")

w <- 360
corrName <- calcRollingCorr(dfRecession, df.data, df.symbols, datay1, ylim1, datay2, ylim2, w, dt.start)

```

```{r rollingcorTOTLNNSA_YoYPSAVELong, fig.width = 10, fig.asp = .62}

datay1 <- "TOTLLNSA.Value__YoY"
ylim1 <- c(-10, 20)

datay2 <- "DGS10TO1"
ylim2 <- c(-5, 10)

dt.start <- as.Date("1jan1960","%d%b%Y")

w <- 720
corrName <- calcRollingCorr(dfRecession, df.data, df.symbols, datay1, ylim1, datay2, ylim2, w, dt.start)

```

One other items, let's see how loans do versus the federal funds rate


```{r corrLoansFedFunds, echo=FALSE}

datax = "TOTLLNSA.Value__YoY"
datay = "FEDFUNDS.Value"
titlelabel <- paste(datay, " | ", datax)
ylim <- c(-5, 25)
ylabel <- paste(datay, ", ", df.symbols[grep(datay, df.symbols$string.symbol),]$yLabel, sep="")
xlim <- c(-10, 20)
xlabel <- paste(datax, ", ", df.symbols[grep(datax, df.symbols$string.symbol),]$yLabel, sep="")
bLegend <- FALSE
bFitLinear <- TRUE
dt.start = as.Date('2000-01-01')
b.reverse.y = FALSE
plotXvY(df.data, dfRecession, datax, datay, titlelabel, xlabel, ylabel, xlim, ylim, bLegend, bFitLinear, dt.start, b.reverse.y)

```

<!-- ## EIA Information -->

<!-- ### Petroleum -->

<!-- #### Consumption/Sales > Refiner Motor Gasoline Sales Volumes > by Product > Motor Gasoline > by Area > U.S. -->

<!-- ```{r petro.gasoline.us, echo=FALSE, fig.width = 9, fig.asp = 0.4 } -->

<!-- datay <- "PETA103600001M" -->
<!-- datay.aux.1 <- "PETA123600001M" -->
<!-- datay.aux.2 <- "PETA143B00001M" -->
<!-- datay.aux.3 <- "PETA133B00001M" -->
<!-- ylim <- c(7.5, 100000) -->
<!-- dt.start = as.Date('1983-01-01') -->
<!-- p1 <- -->
<!--   plotSingleQuick( -->
<!--     dfRecession, -->
<!--     df.data, -->
<!--     datay, -->
<!--     ylim, -->
<!--     dt.start, -->
<!--     b.legend = TRUE, -->
<!--     b.percentile = FALSE, -->
<!--     b.long.legend = TRUE -->
<!--   ) -->
<!-- p1 <- p1 + geom_line( -->
<!--   data = df.data, -->
<!--   aes_string( -->
<!--     x = "date", -->
<!--     y = datay.aux.1, -->
<!--     colour = shQuote(getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n")) -->
<!--   ), -->
<!--   na.rm = TRUE -->
<!-- ) -->
<!-- p1 <- p1 + geom_line( -->
<!--   data = df.data, -->
<!--   aes_string( -->
<!--     x = "date", -->
<!--     y = datay.aux.2, -->
<!--     colour = shQuote(getPlotTitle(df.symbols, datay.aux.2, str.sep = "\n")) -->
<!--   ), -->
<!--   na.rm = TRUE -->
<!-- ) -->

<!-- p1 + geom_line( -->
<!--   data = df.data, -->
<!--   aes_string( -->
<!--     x = "date", -->
<!--     y = datay.aux.3, -->
<!--     colour = shQuote(getPlotTitle(df.symbols, datay.aux.3, str.sep = "\n")) -->
<!--   ), -->
<!--   na.rm = TRUE -->
<!-- ) -->

<!-- ``` -->

<!-- ### Total Energy -->

<!-- #### Crude Oil and Natural Gas Resource Development > Crude Oil and Natural Gas Drilling Activity Measurements -->

<!-- ```{r eia.total.Oilgasdrilling, echo=FALSE, fig.width = 9, fig.asp = 0.4 } -->

<!-- datay <- "TOTALPANRPUSM" -->
<!-- datay.aux.1 <- "TOTALOGNRPUSM" -->
<!-- datay.aux.2 <- "TOTALNGNRPUSM" -->
<!-- ylim <- c(7.5, 2500) -->
<!-- dt.start = as.Date('1983-01-01') -->
<!-- p1 <- -->
<!--   plotSingleQuick( -->
<!--     dfRecession, -->
<!--     df.data, -->
<!--     datay, -->
<!--     ylim, -->
<!--     dt.start, -->
<!--     b.legend = TRUE, -->
<!--     b.percentile = FALSE, -->
<!--     b.long.legend = TRUE -->
<!--   ) -->
<!-- p1 <- p1 + geom_line( -->
<!--   data = df.data, -->
<!--   aes_string( -->
<!--     x = "date", -->
<!--     y = datay.aux.1, -->
<!--     colour = shQuote(getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n")) -->
<!--   ), -->
<!--   na.rm = TRUE -->
<!-- ) -->
<!-- p1 <- p1 + geom_line( -->
<!--   data = df.data, -->
<!--   aes_string( -->
<!--     x = "date", -->
<!--     y = datay.aux.2, -->
<!--     colour = shQuote(getPlotTitle(df.symbols, datay.aux.2, str.sep = "\n")) -->
<!--   ), -->
<!--   na.rm = TRUE -->
<!-- ) -->
<!-- p1 -->


<!-- ``` -->


## Baker Hughes Rig Count

```{r bkr.total.Oilgasdrilling, echo=FALSE, fig.width = 9, fig.asp = 0.4 }

datay <- "BKR_Total"
#datay.aux.1 <- "TOTALOGNRPUSM"
datay.aux.1 <- "BKR_Total"
datay.aux.2 <- "BKR_Oil"
datay.aux.3 <- "BKR_Gas"
ylim <- c(7.5, 2500)
dt.start = as.Date('1983-01-01')
p1 <-
  plotSingleQuick(
    dfRecession,
    df.data,
    datay,
    ylim,
    dt.start,
    b.legend = TRUE,
    b.percentile = FALSE,
    b.long.legend = TRUE
  )
p1 <- p1 + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.1,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n"))
  ),
  na.rm = TRUE
)
p1 <- p1 + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.2,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.2, str.sep = "\n"))
  ),
  na.rm = TRUE
)
p1 <- p1 + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.3,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.3, str.sep = "\n"))
  ),
  na.rm = TRUE
)
p1


```


```{r bkr.total.Oilgasdrilling.near, echo=FALSE, fig.width = 9, fig.asp = 0.4 }
# 
# datay <- "BKR_Total"
# datay.aux.1 <- "TOTALOGNRPUSM"
# datay.aux.2 <- "BKR_Oil"
# datay.aux.3 <- "BKR_Gas"
# ylim <- c(7.5, 1200)
# dt.start = as.Date('2019-01-01')
# p1 <-
#   plotSingleQuick(
#     dfRecession,
#     df.data,
#     datay,
#     ylim,
#     dt.start,
#     b.legend = TRUE,
#     b.percentile = FALSE,
#     b.long.legend = TRUE
#   )
# p1 <- p1 + geom_line(
#   data = df.data,
#   aes_string(
#     x = "date",
#     y = datay.aux.1,
#     colour = shQuote(getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n"))
#   ),
#   na.rm = TRUE
# )
# p1 <- p1 + geom_line(
#   data = df.data,
#   aes_string(
#     x = "date",
#     y = datay.aux.2,
#     colour = shQuote(getPlotTitle(df.symbols, datay.aux.2, str.sep = "\n"))
#   ),
#   na.rm = TRUE
# )
# p1 <- p1 + geom_line(
#   data = df.data,
#   aes_string(
#     x = "date",
#     y = datay.aux.3,
#     colour = shQuote(getPlotTitle(df.symbols, datay.aux.3, str.sep = "\n"))
#   ),
#   na.rm = TRUE
# )
# p1


```

## BEA Supplemental Estimates, Motor Vehicles  

Definitions								
								
  Autos--all passenger cars, including station wagons.								
  Light trucks--trucks up to 14,000 pounds gross vehicle weight, including minivans and								
  sport utility vehicles.  Prior to the 2003 Benchmark Revision light trucks were up to 10,000 pounds.								
  Heavy trucks--trucks more than 14,000 pounds gross vehicle weight.								
  Prior to the 2003 Benchmark Revision heavy trucks were more than 10,000 pounds.								
  Domestic sales--United States (U.S.) sales of vehicles assembled in the U.S., Canada, and Mexico.								
  Foreign sales--U.S. sales of vehicles produced elsewhere.								
  Domestic auto production--Autos assembled in the U.S.								
  Domestic auto inventories--U.S. inventories of vehicles assembled in the U.S., Canada, and Mexico.								
								
### TAble 6 - Light Vehicle and Total Vehicle Sales

#### Auto sales

A WSJ article suggested that auto sales might be a good indicator so bring that to the mix. It does have troughs that correlate with recessions

```{r LightAutoSales, echo=FALSE}

datay <- "ALTSALES.Value"
ylim <- c(7.5, 25)
dt.start = as.Date('1977-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)


```

There might be some seasonal variance in the auto sales so lets take a look at the year over year. The data is pretty noisy, it probably will not make a very good indicator.

```{r LightAutoSales_YoY, echo=FALSE}

datay <- "ALTSALES.Value__YoY"
ylim <- c(-75, 50)
dt.start = as.Date('1977-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, 
                b.percentile = TRUE)

```

## BEA Gross Domestic Product

Data in this section come from the Bureau of Economic Analysis.

### Table 1.1.5. Gross Domestic Product

[Billions of dollars] Seasonally adjusted at annual rates

#### A191RC: Gross Domestic Product - Line 1

GDP numbers tend to lag so this series is truly an afterthought. But it does have some correlation with the recessions.

GDP does not reflect the capacity of the economy nor the efficiency. Shrinking capacity and lower prices at constant volumes would indicate improvements in effeciency/productivity which is good for the economy, but does not move the GDP upward.

```{r GDP, echo=FALSE}

datay <- "GDP.Value"
ylim <- c(1, 40000)
plotSingleQuick(dfRecession, df.data, datay, ylim)


```

Looks like the year over year change on the GDP should correlate well with unemployment.

```{r GDPYoy, echo=FALSE}

datay <- "GDP.Value__YoY"
ylim <- c(-5, 17.5)
plotSingleQuick(dfRecession, df.data, datay, ylim, b.percentile = TRUE)


```

### Table 1.1.9. Implicit Price Deflators for Gross Domestic Product

[Index numbers, 2012=100] Seasonally adjusted

#### A191RD: Gross Domestic Product - Line 1

This is GDP price deflator series. 

```{r GDPDEF, echo=FALSE}

datay <- "GDPDEF.Value"
ylim <- c(10, 140)
plotSingleQuick(dfRecession, df.data, datay, ylim)


```

### GDP normalized by CPI

Normalize GDP by CPI

```{r GDPBYCPIAUCSL, echo=FALSE}

datay <- "GDPBYCPIAUCSL"
ylim <- c(1000, 10000)
dt.start = as.Date('1959-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

### Economic yield curve (GDP to 1-year treasury)

GDP versus the yield on the 1-year. This series was prompted by an article suggesting that the "economic yield curve" should be used to indicate a recession rather than an inverted yield curve. Less of indicator and more of concurrent confirmation of recession. Not sure why they would be related either.

```{r GDPFundRateDiff, echo=FALSE}

# datay <- "GDP_YoYTODGS1"
# ylim <- c(-10.0, 10.0)
# plotSingleQuickModern(datay, ylim)


```

### Economic yield curve (GDP to 3-month treasury)

Same idea as above, but applied the 3-month treasury.This one has fewer false triggers, but is not as helpful as 10Y to 3M spread in predicting a recession.

```{r GDPFundRate3MonthDiff, echo=FALSE}

# datay <- "GDP_YoYTOTB3MS"
# ylim <- c(-10.0, 15.0)
# plotSingleQuickModern(datay, ylim)


```

#### A824RC: National defense Federal Gov't Expenditures - Line 24

U.S. Bureau of Economic Analysis, Federal Government: National Defense Consumption Expenditures and Gross Investment [FDEFX], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/FDEFX, April 6, 2021.

```{r FDEFX, echo=FALSE}

datay <- "FDEFX.Value"
ylim <- c(0.0, 1200.0)
plotSingleQuickModern(datay, ylim)

```


#### A825RC: Nondefense Federal Gov't Expenditures - Line 25

U.S. Bureau of Economic Analysis, Federal Government: Nondefense Consumption Expenditures and Gross Investment [FNDEFX], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/FNDEFX, April 6, 2021.

```{r FNDEFX, echo=FALSE}

datay <- "FNDEFX.Value"
ylim <- c(0.0, 1100.0)
plotSingleQuickModern(datay, ylim)

```

### Table 6.16D. Corporate Profits by Industry

Select series from Table 6.16D

#### A051RC: Corporate profits with inventory and capital consumption adjustment

From BEA's documentation (https://www.bea.gov/media/5671):

"BEA’s featured measure of corporate profits — profits from current production - provides a comprehensive and consistent economic measure of the income earned by all U.S. corporations. As such, it is unaffected by changes in tax laws, and it is adjusted for nonreported and misreported income. It excludes dividend income, capital gains and
losses, and other financial flows and adjustments, such as deduction for “bad debt.” Thus, the NIPA measure of profits is a particularly useful analytical measure of the health of the corporate sector. For example, in contrast to other popular measures of corporate profits, the NIPA measure did not show the large run-up in profits during the late 1990s that was primarily attributable to capital gains.


Profits after tax with IVA and CCAdj is equal to corporate profits with IVA and CCAdj less taxes on corporate income. It provides an after-tax measure of profits from current production." 

Data is Line 1 of Table 6.16D

```{r CPROFIT, echo=FALSE}

datay <- "CPROFIT.Value"
ylim <- c(0, 4000)
plotSingleQuickModern(datay, ylim)


```

#### A053RC: Corporate profits without inventory and capital consumption adjustment

Profits look a bit flat over the last several years in this series.

```{r A053RC1Q027SBEA, echo=FALSE}

datay <- "A053RC1Q027SBEA.Value"
ylim <- c(0, 4500)
plotSingleQuickModern(datay, ylim)


```

### Table 2.6. Personal Income and Its Disposition, Monthly

Billions of dollars; months are seasonally adjusted at annual rates.

#### A065RC Personal Income - Line 1

BEA Account Code: A065RC

Personal income is the income that persons receive in return for their provision of labor, land, and capital used in current production and the net current transfer payments that they receive from business and from government.25 Personal income is equal to national income minus corporate profits with inventory valuation and capital consumption adjustments, taxes on production and imports less subsidies, contributions for government social insurance, net interest and miscellaneous payments on assets, business current transfer payments (net), current surplus of government enterprises, and wage accruals less disbursements, plus personal income receipts on assets and personal current transfer receipts.
A Guide to the National Income and Product Accounts of the United States (NIPA) - (http://www.bea.gov/national/pdf/nipaguid.pdf)

Suggested Citation:
U.S. Bureau of Economic Analysis, Personal Income [PI], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/PI, July 11, 2019.

```{r PI, echo=FALSE}

datay <- "PI.Value"
ylim <- c(0, 35000)
plotSingleQuick(dfRecession, df.data, datay, ylim)


```


#### DPCERC: Personal consumption expenditures (PCE) - Table 2.1, Line 29

BEA Account Code: DPCERC
Personal consumption expenditures (PCE) is the primary measure of consumer spending on goods and services in the U.S. economy. 1 It accounts for about two-thirds of domestic final spending, and thus it is the primary engine that drives future economic growth. PCE shows how much of the income earned by households is being spent on
current consumption as opposed to how much is being saved for future consumption. -https://www.bea.gov/system/files/2019-12/Chapter-5.pdf

Suggested Citation:
U.S. Bureau of Economic Analysis, Personal Consumption Expenditures [PCE], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/PCE, June 12, 2020


```{r PCE, echo=FALSE}

datay <- "PCE.Value"
ylim <- c(0, 25000)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

```{r PCE.recent, echo=FALSE}

datay <- "PCE.Value"
ylim <- c(6000, 25000)
dt.start = as.Date('2000-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

```{r PCE.YoY, echo=FALSE}

datay <- "PCE.Value__YoY"
ylim <- c(-20, 25)
dt.start = as.Date('2000-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```


#### DPCERG: Personal consumption expenditures Price Index (PCEPI) - Table 2.1, Line 29

BEA Account Code: DPCERG
The gross domestic product price index measures changes in prices paid for goods and services produced in the United States, including those exported to other countries. Prices of imports are excluded. The gross domestic product implicit price deflator, or GDP deflator, basically measures the same things and closely mirrors the GDP price index, although the two price measures are calculated differently. The GDP deflator is used by some firms to adjust payments in contracts.

The gross domestic purchases price index is BEA's featured measure of inflation for the U.S. economy overall. It measures changes in prices paid by consumers, businesses, and governments in the United States, including the prices of the imports they buy.

BEA's closely followed personal consumption expenditures price index, or PCE price index, is a narrower measure. It looks at the changing prices of goods and services purchased by consumers in the United States. It's similar to the Bureau of Labor Statistics' consumer price index for urban consumers. The two indexes, which have their own purposes and uses, are constructed differently, resulting in different inflation rates.

The PCE price index is known for capturing inflation (or deflation) across a wide range of consumer expenses and for reflecting changes in consumer behavior. For example, if the price of beef rises, shoppers may buy less beef and more chicken. Also, BEA revises previously published PCE data to reflect updated information or new methodology, providing consistency across decades of data that’s valuable for researchers. The PCE price index is used primarily for macroeconomic analysis and forecasting.
-https://www.bea.gov/resources/learning-center/what-to-know-prices-inflation

Suggested Citation:
U.S. Bureau of Economic Analysis, Personal Consumption Expenditures: Chain-type Price Index [PCEPI], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/PCEPI, April 25, 2021.


```{r PCEPI, echo=FALSE}

datay <- "PCEPI.Value"
ylim <- c(0, 130)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

```{r PCEPI.recent, echo=FALSE}

datay <- "PCEPI.Value"
ylim <- c(60, 140)
dt.start = as.Date('2000-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

```{r PCEPI.YoY, echo=FALSE}

datay <- "PCEPI.Value__YoY"
ylim <- c(-2, 8)
dt.start = as.Date('2000-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```








#### A072RC: Personal Savings Rate - Line 35

Consumers tend to pull down their savings rates as unemployment decreases and market conditions improve. This series has tended to be unreliable due to the size of revisions during the comprehensive update carried out by the BEA. The last update on this series moved the rate from 4.2 to 6.7 percent.

(https://www.bloomberg.com/news/articles/2018-07-27/americans-have-been-saving-much-more-than-thought-new-data-show)

BEA Account Code: A072RC
Personal saving as a percentage of disposable personal income (DPI), frequently referred to as "the personal saving rate," is calculated as the ratio of personal saving to DPI.
Personal saving is equal to personal income less personal outlays and personal taxes; it may generally be viewed as the portion of personal income that is used either to provide funds to capital markets or to invest in real assets such as residences.(https://www.bea.gov/national/pdf/all-chapters.pdf)
A Guide to the National Income and Product Accounts of the United States (NIPA).

Suggested Citation:
U.S. Bureau of Economic Analysis, Personal Saving Rate [PSAVERT], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/PSAVERT, July 9, 2019.

```{r PSAVERT, echo=FALSE}

datay <- "PSAVERT.Value"
ylim <- c(0, 35)
plotSingleQuick(dfRecession, df.data, datay, ylim)


```

Take a closer look at the last decade


```{r PSAVERT.plot.close, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "PSAVERT.Value"
ylim <- c(0, 35)
dt.start <- as.Date("1jan2000","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  titlelabel = getPlotTitle(df.symbols, datay, str.sep = "\n"),
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)
my.plot

```

The relationship between personal savings and unemployment (U-3) can be better visualized with a scatter plot

```{r corrU6PSVT, echo=FALSE}

datax = "UNRATE.Value"
datay = "PSAVERT.Value"
titlelabel <- paste(datay, " | ", datax)
ylim <- c(0, 17.5)
ylabel <- paste(datay, ", ", df.symbols[grep(datay, df.symbols$string.symbol),]$yLabel, sep="")
xlim <- c(0, 15)
xlabel <- paste(datax, ", ", df.symbols[grep(datax, df.symbols$string.symbol),]$yLabel, sep="")
bLegend <- FALSE
bFitLinear <- TRUE
dt.start = as.Date('1995-01-01')
b.reverse.y = FALSE
plotXvY(df.data, dfRecession, datax, datay, titlelabel, xlabel, ylabel, xlim, ylim, bLegend, bFitLinear, dt.start, b.reverse.y)

```


The fit does not explain most of what is in the plot. Lets take a look at the rolling correlation. 

```{r rollingcor.unrate.u3.psavert, fig.width = 10, fig.asp = .62}

datay1 <- "UNRATE.Value"
ylim1 <- c(2, 12)

datay2 <- "PSAVERT.Value"
ylim2 <- c(0, 35)

dt.start <- as.Date("1jan1985","%d%b%Y")

w <- 360
corrName <- calcRollingCorr(dfRecession, df.data, df.symbols, datay1, ylim1, datay2, ylim2, w, dt.start)

```

### Personal savings to household net worth

A relationship between personal savings and household networth can be seen in a scatter plot. This was suggested by a WSJ article (https://blogs.wsj.com/dailyshot/2018/02/23/the-daily-shot-reasons-for-declining-u-s-household-savings-rate/).

```{r corrHNONWPDPIPSVT, echo=FALSE}

datax = "HNONWPDPI.Value"
datay = "PSAVERT.Value"
titlelabel <- paste(datay, " | ", datax)
ylim <- c(0, 17.5)
ylabel <- paste(datay, ", ", df.symbols[grep(datay, df.symbols$string.symbol),]$yLabel, sep="")
xlim <- c(440, 750)
xlabel <- paste(datax, ", ", df.symbols[grep(datax, df.symbols$string.symbol),]$yLabel, sep="")
bLegend <- FALSE
bFitLinear <- TRUE
dt.start = as.Date('1980-01-01')
b.reverse.y = FALSE
plotXvY(df.data, dfRecession, datax, datay, titlelabel, xlabel, ylabel, xlim, ylim, bLegend, bFitLinear, 
        dt.start, b.reverse.y)

```

## U.S. Census Bureau

### U.S. International Trade in Goods and Services (FT900)

U.S. Bureau of Economic Analysis and U.S. Census Bureau, U.S. Imports of Goods by Customs Basis from China [IMPCH], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/IMPCH, October 5, 2019.

```{r IMPCH.plot, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "IMPCH.Value"
datay.aux <- "EXPCH.Value"
ylim <- c(0, 60)
dt.start <- as.Date("1jan1985","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  titlelabel ="China: Exports and Imports",
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
  ),
  na.rm = TRUE
)

my.plot

```


```{r IMPCH.IMPMX.plot, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "EXPCH__minus__IMPCH"
datay.aux <- "EXPMX__minus__IMPMX"
ylim <- c(-50, 0)
dt.start <- as.Date("1jan1985","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  titlelabel ="Exports minus Imports for China and Mexico",
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
  ),
  na.rm = TRUE
)

my.plot

```


```{r IMPCH.plot.yoy, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "IMPCH.Value__YoY"
datay.aux <- "EXPCH.Value__YoY"
ylim <- c(-50, 100)
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  titlelabel = getPlotTitle(df.symbols, datay),
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
  ),
  na.rm = TRUE
)

my.plot

```

### New Houses Sold and For Sale by Stage of Construction and Median Number of Months on Sales Market

Read an article suggesting that housing sales and sales growth could be useful. FRED only has new home data so start there.

```{r newhousing, fig.width = 7, fig.asp = 1.3 }

datay <- "HSN1FNSA.Value"
ylim <- c(0, 200)
dt.start = as.Date('1964-01-01')
p1 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

datay <- "HNFSUSNSA.Value"
ylim <- c(0, 600)
p2 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

datay <- "HNFSUSNSA__minus__HSN1FNSA"
ylim <- c(0, 600)
p3 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    TRUE
  )

grid.arrange(p1,
             p2,
             p3,
             ncol = 1,
             top = "New Housing Sales")
```

New housing yoy

```{r newhousing.yoy, fig.width = 7, fig.asp = 1.3, echo=FALSE}

datay <- "HSN1FNSA.Value__YoY"
ylim <- c(-50, 100)
dt.start = as.Date('1964-01-01')
p1 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

datay <- "HNFSUSNSA.Value__YoY"
p2 <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

datay <- "HNFSUSNSA__minus__HSN1FNSA__YoY"
p3 <-
  plotSingle(
    dfRecession,
    df.data,
    "date",
    datay,
    getPlotTitle(df.symbols, datay),
    "Date",
    getPlotYLabel(df.symbols, datay),
    c(dt.start, Sys.Date()),
    ylim,
    TRUE
  )

grid.arrange(p1,
             p2,
             p3,
             ncol = 1,
             top = "New Housing Sales Year-Over-Year")
```

### New Privately-Owned Housing Units Authorized in Permit-Issuing Places

As provided by the Census, start occurs when excavation begins for the footings or foundation of a building. All housing units in a multifamily building are defined as being started when this excavation begins. Beginning with data for September 1992, estimates of housing starts include units in structures being totally rebuilt on an existing foundation.

Suggested Citation:
U.S. Census Bureau and U.S. Department of Housing and Urban Development, Housing Starts: Total: New Privately Owned Housing Units Started [HOUST], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/HOUST, June 13, 2020.

```{r HOUST.plot, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "HOUST.Value"
ylim <- c(0, 3000)
dt.start <- as.Date("1jan1959","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  getPlotTitle(df.symbols, datay),
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)

my.plot

```


Take a look at privately owned starts

```{r HOUST1F.plot, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "HOUST1F.Value"
ylim <- c(0, 3000)
dt.start <- as.Date("1jan1959","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  getPlotTitle(df.symbols, datay),
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)

my.plot

```


### New Privately-Owned Houses Sold and For Sale

Suggested Citation:
U.S. Census Bureau and U.S. Department of Housing and Urban Development, Median Sales Price of Houses Sold for the United States [MSPUS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/MSPUS, June 13, 2020.


```{r MSPUS.plot, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "MSPUS.Value"
ylim <- c(0, 500000)
dt.start <- as.Date("1jan1963","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  getPlotTitle(df.symbols, datay),
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)

my.plot

```

Finally, take a look at starts times the median price

```{r MSPUS.times.HOUST.plot, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "MSPUS__times__HOUST"
ylim <- c(0, 750)
dt.start <- as.Date("1jan1963","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  getPlotTitle(df.symbols, datay),
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)

my.plot

```


### Durable Goods

Suggested Citation:
U.S. Census Bureau, Manufacturers' New Orders: Durable Goods [UMDMNO], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/UMDMNO, April 26, 2021.


```{r UMDMNO.plot, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "UMDMNO.Value"
ylim <- c(120, 300)
dt.start <- as.Date("1jan1992","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  getPlotTitle(df.symbols, datay),
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)

my.plot

```

Durable goods, not seasonally adjusted, divided by GDP

```{r UMDMNO.by.GDP.plot, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "UMDMNO__by__GDP"
ylim <- c(0, 3)
dt.start <- as.Date("1jan1992","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  getPlotTitle(df.symbols, datay),
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)

my.plot

```


```{r DGORDER.plot, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "DGORDER.Value"
ylim <- c(120, 300)
dt.start <- as.Date("1jan1992","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  getPlotTitle(df.symbols, datay),
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)

my.plot

```

Durable goods, seasonally adjusted, divided by GDP

```{r DGORDER.by.GDP.plot, echo=FALSE, fig.width = 9, fig.asp = 0.4}

# datay <- "DGORDER__by__GDP"
# ylim <- c(0, 3)
# dt.start <- as.Date("1jan1992","%d%b%Y")
# my.plot <- plotSingle(
#   dfRecession,
#   df.data,
#   "date",
#   datay,
#   getPlotTitle(df.symbols, datay),
#   xlabel = "Date",
#   ylabel = getPlotYLabel(df.symbols, datay),
#   c(dt.start, Sys.Date()),
#   ylim,
#   b.legend = TRUE,
#   b.percentile = FALSE,
#   b.long.legend = TRUE
# )
# 
# my.plot

```

## Federal reserve board H.8: Assets and Liabilities of Commercial Banks in the United States

### Page 4: Not Seasonally adjusted, billions of dollars

#### Commercial and industrial loans, all commercial banks - Line 10

Data taken from H.8 Assets and Liabilities of Commercial Banks in the United States. Take a look at SA and NSA data series as weekly and month updates. It should all be similar at this scale.

Suggested Citation:
Board of Governors of the Federal Reserve System (US), Commercial and Industrial Loans, All Commercial Banks [BUSLOANS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/BUSLOANS, July 11, 2019.

```{r cureal, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "BUSLOANS.Value"
datay.aux <- "BUSLOANSNSA.Value"
datay.aux.1 <- "TOTCI.Value"
datay.aux.2 <- "TOTCINSA.Value"
ylim <- c(0, 3500)
dt.start <- as.Date("1jan1945","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  titlelabel = getPlotTitle(df.symbols, datay),
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.1,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.2,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.2, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot

```


```{r businessloans.by.gdp, echo=FALSE, fig.width = 9, fig.asp = 0.4}

datay <- "BUSLOANS__by__GDP"
datay.aux <- "BUSLOANSNSA__by__GDP"
datay.aux.1 <- "TOTCI__by__GDP"
datay.aux.2 <- "TOTCINSA__by__GDP"
ylim <- c(7, 15)
dt.start <- as.Date("1jan1975","%d%b%Y")
my.plot <- plotSingle(
  dfRecession,
  df.data,
  "date",
  datay,
  titlelabel = getPlotTitle(df.symbols, datay),
  xlabel = "Date",
  ylabel = getPlotYLabel(df.symbols, datay),
  c(dt.start, Sys.Date()),
  ylim,
  b.legend = TRUE,
  b.percentile = FALSE,
  b.long.legend = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.1,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.1, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot <- my.plot + geom_line(
  data = df.data,
  aes_string(
    x = "date",
    y = datay.aux.2,
    colour = shQuote(getPlotTitle(df.symbols, datay.aux.2, str.sep = "\n"))
  ),
  na.rm = TRUE
)
my.plot

```

Taking a look at the difference in SA and NSA series. Seasonal adjustments do vary, but do not seem to be related to recessions.

```{r busloans.monthly.sa.nsa, echo=FALSE}
# datay <- "BUSLOANS__minus__BUSLOANSNSA__by__GDP"
# ylim <- c(-0.25, 0.25)
# plotSingleQuick(dfRecession, df.data, datay, ylim)

```

The raw series is just too steep for any kind of machine learnine. This needs to be converted to log scale.

```{r busloanslogplot, echo=FALSE}
datay <- "BUSLOANS.Value__Log"
ylim <- c(0, 10)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

That's a little better, let's see what the smoothed derivative looks like.

```{r busloansderplot, echo=FALSE}
# datay <- "BUSLOANS.Value__Log__Der"
# ylim <- c(-0.01, 0.01)
# plotSingleQuick(dfRecession, df.data, datay, ylim)

```

That is odd...looks like this doesn't cross zero unless we are getting close to, or into, a recession. The year over year tells about the same story. Might be a good indication of the end of a recession.

```{r BusLoansYoYplot, echo=FALSE}

datay <- "BUSLOANS.Value__YoY"
ylim <- c(-30, 30)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```


#### Consumer loans, all commercial banks - Line 20

Suggested Citation:
Board of Governors of the Federal Reserve System (US), Consumer Loans, All Commercial Banks [CONSUMERNSA], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/CONSUMERNSA, July 11, 2019.

That spike in consumer loans is due to 

"April 9, 2010 (Last revised September 23, 2011): As of the week ending March 31, 2010, domestically chartered banks and foreign-related institutions had consolidated onto their balance sheets the following assets and liabilities of off-balance-sheet vehicles, owing to the adoption of FASB's Financial Accounting Statements No. 166 (FAS 166), "Accounting for Transfers of Financial Assets," and No. 167 (FAS 167), "Amendments to FASB Interpretation No. 46(R)."

This included a consumer loans, credit cards and other revolving plans change of $321.9B. That was a lot of off-balance-sheet bank assets.


```{r consumer.loans, echo=FALSE}

datay <- "CONSUMERNSA.Value"
ylim <- c(0, 2000)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

#### Deposits, All Commercial Banks, all commercial banks - Line 34

Data taken from H.8 Assets and Liabilities of Commercial Banks in the United States. Take a look at SA and NSA data series as weekly and month updates. It should all be similar at this scale.

Suggested Citation:
Board of Governors of the Federal Reserve System (US), Deposits, All Commercial Banks [DPSACBW027SBOG], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/DPSACBW027SBOG, May 14, 2020.

```{r DPSACBW027SBOG.plots, echo=FALSE}

datay <- "DPSACBW027SBOG.Value"
ylim <- c(1000, 25000)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

## Federal reserve board Z.1: Financial Accounts of the United States

From the FRED website (https://fred.stlouisfed.org/release?rid=52):

"The Financial Accounts (formerly known as the Flow of Funds accounts) are a set of financial accounts used to track the sources and uses of funds by sector. They are a component of a system of macroeconomic accounts including the National Income and Product accounts (NIPA) and balance of payments accounts, all of which serve as a comprehensive set of information on the economy’s performance.(1) Some important inferences that can be drawn from the Financial accounts are the financial strength of a given sector, new economic trends, changes in the composition of wealth, and development of new financial instruments over time.(1) 

Sectors are compiled into three categories: households, nonfinancial businesses, and banks. The sources of funds for a sector are its internal funds (savings from income after consumption) and external funds (loans from banks and other financial intermediaries). (1) Funds for a given sector are used for its investments in physical and financial assets. Dividing sources and uses of funds into two categories helps the staff of the Federal Reserve System pay particular attention to external sources of funds and financial uses of funds.(2) One example is whether households are borrowing more from banks—or in other words, whether household debt is rising. Another example might be whether banks are using more of their funds to provide loans to consumers. Transactions within a sector are not shown in the accounts; however, transactions between sectors are.(2) Monitoring the external flows of funds provides insights into a sector’s health and the performance of the economy as a whole.

Data for the Financial accounts are compiled from a large number of reports and publications, including regulatory reports such as those submitted by banks, tax filings, and surveys conducted by the Federal Reserve System.(2) The Financial accounts are published quarterly as a set of tables in the Federal Reserve’s Z.1 statistical release.

(1)	Teplin, Albert M. “The U.S. Flow of Funds Accounts and Their Uses.” Federal Reserve Bulletin, July 2001; http://www.federalreserve.gov/pubs/bulletin/2001/0701lead.pdf. 
(2)	Board of Governors of the Federal Reserve System. “Guide to the Flow of Funds Accounts.” 2000, http://www.federalreserve.gov/apps/fof/."

### L.102 Nonfinancial Business

#### FL102051003.Q: Nonfinancial corporate business; security repurchase agreements; asset

Asset level of nonfinancial business security repo agreements. federalreserve.gov/apps/fof/SeriesAnalyzer.aspx?s=FL102051003&t=

```{r SRPSABSNNCB.z.1, echo=FALSE}

datay <- "SRPSABSNNCB.Value"
ylim <- c(-20, 120)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

```{r SRPSABSNNCB.by.GDP.z.1, echo=FALSE}


datay <- "SRPSABSNNCB__by__GDP"
ylim <- c(0, 1)
plotSingleQuick(dfRecession,
                df.data,
                datay,
                ylim,
                dt.start = as.Date("1jan1965", "%d%b%Y"))

```

```{r SRPSABSNNCB.YoY.z.1, echo=FALSE}

plotSingleQuick(dfRecession,
                df.data,
                datay = "SRPSABSNNCB.Value__YoY",
                ylim =  c(-250, 250),
                dt.start = as.Date("1jan1965", "%d%b%Y"))

```

### L.214 Loans

#### FL894123005.Q: All sectors; total loans; liability

Sum of domestic financial sectors, all sectors, total mortgages, and households/non-profits. federalreserve.gov/apps/fof/SeriesAnalyzer.aspx?s=FL894123005&t=L.107&bc=L.107:FL793068005&suf=Q


```{r ASTLL.z.1, echo=FALSE}

datay <- "ASTLL.Value"
ylim <- c(0, 45000)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

#### FL793068005.Q: Domestic financial sectors; depository institution loans n.e.c.; asset

Sum of Monetary authority; depository institution loans n.e.c.; asset and Private depository institutions; depository institution loans n.e.c.; asset. federalreserve.gov/apps/fof/SeriesAnalyzer.aspx?s=FL793068005&t=L.214&suf=Q


```{r FBDILNECA.z.1, echo=FALSE}

datay <- "FBDILNECA.Value"
ylim <- c(0, 7000)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

#### FL893169005.Q: All sectors; other loans and advances; liability

Sum of finance, government, and chartered institutions asset levels. https://www.federalreserve.gov/apps/fof/SeriesAnalyzer.aspx?s=FL893169005&t=L.214&suf=Q


```{r ASOLAL.z.1, echo=FALSE}

datay <- "ASOLAL.Value"
ylim <- c(0, 9000)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

#### FL893065005.Q: All sectors; total mortgages; asset

https://www.federalreserve.gov/apps/fof/SeriesAnalyzer.aspx?s=FL893065005&t=L.214&suf=Q

```{r ASTMA.z.1, echo=FALSE}

datay <- "ASTMA.Value"
ylim <- c(0, 25000)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

#### FL893065105.Q: All sectors; home mortgages; asset

https://www.federalreserve.gov/apps/fof/DisplayTable.aspx?t=L.214

```{r ASHMA.z.1, echo=FALSE}

datay <- "ASHMA.Value"
ylim <- c(0, 15000)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

#### FL893065405.Q: All sectors; multifamily residential mortgages; asset

https://www.federalreserve.gov/apps/fof/SeriesAnalyzer.aspx?s=FL893065405&t=L.214&suf=Q

```{r ASMRMA.z.1, echo=FALSE}

datay <- "ASMRMA.Value"
ylim <- c(0, 3000)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

#### FL893065505.Q: All sectors; commercial mortgages; asset

https://www.federalreserve.gov/apps/fof/SeriesAnalyzer.aspx?s=FL893065505&t=L.214&suf=Q

```{r ASCMA.z.1, echo=FALSE}

datay <- "ASCMA.Value"
ylim <- c(0, d.GSPC.max)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

#### FL893065603.Q: All sectors; farm mortgages; asset

https://www.federalreserve.gov/apps/fof/SeriesAnalyzer.aspx?s=FL893065603&t=L.214&suf=Q

```{r ASFMA.z.1, echo=FALSE}
# 
# datay <- "ASFMA.VAlue"
# ylim <- c(0, 400)
# plotSingleQuick(dfRecession, df.data, datay, ylim)

```


#### FL153166000.Q: Households and nonprofit organizations; consumer credit; liability

federalreserve.gov/apps/fof/SeriesAnalyzer.aspx?s=FL153166000&t=L.214&suf=Q

```{r CCLBSHNO.z.1, echo=FALSE}

datay <- "CCLBSHNO.Value"
ylim <- c(0, 7000)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```

### B.101 Balance Sheet of Households and Nonprofit Organizations

#### FL152000005.Q: Households and nonprofit organizations; total assets, Level

string.source ID: FL152000005.Q. 

```{r TABSHNO, echo=FALSE}

datay <- "TABSHNO.Value"
ylim <- c(0, 230000)
plotSingleQuick(dfRecession, df.data, datay, ylim)


```

#### FL152090006.Q: Household Net Worth as Percentage of Disposable Personal Income

string.source ID: FL152090006.Q. Household networth tends to fall as a recession start.

```{r HNONWPDPI, echo=FALSE}

datay <- "HNONWPDPI.Value"
ylim <- c(450, 850)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```


## Productivity Yield Curve

GDP versus productivity

```{r ProdFundRate, echo=FALSE}

datay <- "OPHNFB.Value__YoY"
datay_aux<- "DGS1.Value"
ylim <- c(-5, 20)

my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
            getPlotYLabel(df.symbols, datay), c(as.Date("1jan1960","%d%b%Y"), Sys.Date()), ylim, TRUE)
my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)

```
```{r ProdFundRateDiff, echo=FALSE}

# datay <- "OPHNFB_YoYTODGS1"
# ylim <- c(-20.0, 10.0)
# plotSingleQuickModern(datay, ylim)


```

## Manufacturing output and employees

Not sure if these relates to a recession, but fascinating to see how output and employees change with time.

```{r manoutput}

datay <- "OUTMS.Value"
ylim <- c(60, 120)
dt.start = as.Date('1987-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

```{r manworkers}

datay <- "MANEMP.Value"
ylim <- c(10000, 20000)
dt.start = as.Date('1948-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

```{r manout2workers}

datay <- "PRS30006163.Value"
ylim <- c(40, 120)
dt.start = as.Date('1986-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

Shipping volumes might be helpful in determining state of the economy.

```{r CASSINDEX}

datay <- "FRGSHPUSM649NCIS.Value"
ylim <- c(0.8, 1.4)
dt.start = as.Date('1999-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

```{r CASSINDEX.yoy}

datay <- "FRGSHPUSM649NCIS.Value__YoY"
ylim <- c(-30, 30)
dt.start = as.Date('1999-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```


Freight, loosely, moves inversely to the trade deficit.

```{r BOPGTB.yoy}

datay <- "BOPGTB.Value__YoY"
ylim <- c(-30, 30)
dt.start = as.Date('1999-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```


World bank air transportation. Only updated annually so less usefull, but interesting reference to above.

```{r WWDIWLDISAIRGOODMTK1}

# datay <- "WWDIWLDISAIRGOODMTK1"
# ylim <- c(0, 250000)
# dt.start = as.Date('1999-01-01')
# plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

## Gross private domestic investment
Spending most certainly tips down prior to a recession. The gross private domestic investment data series, plotted in log format below, show how private investment pulls back prior to recessions.

```{r GPDI.by.GDP, echo=FALSE}

lst.syms <- c("GPDI__by__GDP")
if ( require_columns(df.data, lst.syms ) ){
  
plotSingleQuick(dfRecession, 
                df.data, 
                datay = lst.syms[[1]], 
                ylim =  c(0.0, 0.3))

}
rm(lst.syms)

```

```{r GPDI_Log, echo=FALSE}

datay <- "GPDI.Value__Log"
ylim <- c(3, 8.5)
plotSingleQuick(dfRecession, df.data, datay, ylim)


```

The change in direction is a little easier to see if the derivative is plotted, first YoY then the smoothed derivative

```{r GPDI_YoY, echo=FALSE}

plotSingleQuick(
  dfRecession,
  df.data,
  datay =  "GPDI.Value__YoY",
  ylim = c(-50, 50),
  b.percentile = TRUE
)

```

```{r GPDI_Log_Der, echo=FALSE}

# plotSingleQuick(
#   dfRecession,
#   df.data,
#   datay = "GPDI.Value__Log_Der",
#   ylim = c(-0.002, 0.002),
#   b.percentile = TRUE
# )

```

## Velocity

```{r MZMV, echo=FALSE}

datay <- "MZMV.Value"
ylim <- c(0, 4)
plotSingleQuick(dfRecession, df.data, datay, ylim)


```

## Productivity

Frequency:  Quarterly
The Productivity and Costs release on August 7, 2003, will reflect the June 2003
benchmark revision to payroll employment. Since employment is now reported on a
North American Industry Classification System (NAICS) basis, all of the
historical data will be revised. Changes as a consequence of the move to NAICS
should not be significant since this release carries data at high levels of
aggregation.

Suggested Citation: U.S. Bureau of Labor Statistics, Nonfarm Business Sector:
Labor Productivity (Output per Hour) for All Employed Persons [OPHNFB],
retrieved from FRED, Federal Reserve Bank of St. Louis;
https://fred.stlouisfed.org/series/OPHNFB, December 24, 2022.

```{r OPHNFB, echo=FALSE}

datay <- "OPHNFB.Value"
ylim <- c(20, 120)
plotSingleQuick(dfRecession, df.data, datay, ylim)

```


```{r OPHNFB_YoY, echo=FALSE}

plotSingleQuick(
  dfRecession,
  df.data,
  datay = "OPHNFB.Value__YoY",
  ylim = c(-3, 8),
  b.percentile = TRUE
)

```

Date range to match census data

```{r OPHNFB_YoY_Date, echo=FALSE}

plotSingleQuick(
  dfRecession,
  df.data,
  datay = "OPHNFB.Value__YoY",
  ylim = c(-3, 6),
  dt.start = as.Date('1977-01-01'),
  b.percentile = TRUE
)

```

## PMI

```{r PMIComp, echo=FALSE}

# plotSingleQuick(
#   dfRecession,
#   df.data,
#   datay = "ISMMANPMI",
#   ylim = c(30, 80),
#   b.percentile = TRUE
# )

```

## Industrial Production

This is a look at manufacturing industrial production. The yoY change should be a leading indicator of unemployment.

```{r IPMan, echo=FALSE}

datay <- "IPMAN.Value"
ylim <- c(30, 120)
dt.start = as.Date('1972-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```


```{r IPMan_YoY, echo=FALSE}

datay <- "IPMAN.Value__YoY"
ylim <- c(-25, 15)
dt.start = as.Date('1972-01-01')
b.percentile <- TRUE
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile)

```

## Housing 

Take a look at housing starts. These can drop as rates rise.

Frequency:  Monthly

As provided by the Census, start occurs when excavation begins for the footings
or foundation of a building. All housing units in a multifamily building are
defined as being started when this excavation begins. Beginning with data for
September 1992, estimates of housing starts include units in structures being
totally rebuilt on an existing foundation.

Suggested Citation:
U.S. Census Bureau and U.S. Department of Housing and Urban Development, New
Privately-Owned Housing Units Started: Total Units [HOUST], retrieved from FRED,
Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/HOUST,
December 24, 2022.

```{r Houst, echo=FALSE}

datay <- "HOUST.Value"
ylim <- c(400, 2700)
dt.start = as.Date('1960-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```
Housing starts, NSA

HOUST reports at annual rate, but HOUSTNSA just reports the monthly numbers. I
scale up the NSA to the annual rate.

Units:  Thousands of Units, Not Seasonally Adjusted

Frequency:  Monthly

Suggested Citation:
U.S. Census Bureau and U.S. Department of Housing and Urban Development, New
Privately-Owned Housing Units Started: Total Units [HOUSTNSA], retrieved from
FRED, Federal Reserve Bank of St. Louis;
https://fred.stlouisfed.org/series/HOUSTNSA, December 24, 2022.

```{r Houst.NSA, echo=FALSE}

lst.syms <- c("HOUSTNSA.Value")
if ( require_columns(df.data, lst.syms ) ){

  plotSingleQuick(dfRecession, df.data, 
                  datay = lst.syms[[1]], 
                  ylim = c(0, 2700), 
                  dt.start = as.Date('1960-01-01'),
                  b.percentile = TRUE)
  
}
rm(lst.syms)

```

```{r Houst_YoY, echo=FALSE}

datay <- "HOUST.Value__YoY"
datay_aux <- "HOUSTNSA.Value__YoY"
ylim <- c(-50, 100)
dt.start = as.Date('1960-01-01')
b.percentile <- TRUE
my.plot <- plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile)

my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)

```

Case-schiller price index

```{r CSUSHPINSA, echo=FALSE}

datay <- "CSUSHPINSA.Value"
ylim <- c(60, 350)
dt.start = as.Date('1987-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

```{r CSUSHPINSA_YoY, echo=FALSE}

datay <- "CSUSHPINSA.Value__YoY"
ylim <- c(-25, 25)
dt.start = as.Date('1987-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```


## Population data

Many of the economic series can be better understood if normalized by population. Basic population and worker data from FRED.


```{r population, echo=FALSE}

datay <- "POPTHM.Value"
ylim <- c(160000, 350000)
dt.start = as.Date('1959-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```


```{r population.yoy, echo=FALSE}

datay <- "POPTHM.Value__YoY"
ylim <- c(0, 2.5)
dt.start = as.Date('1960-01-01')
plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

### Population to GDP

```{r GDPBYPOPTHM, echo=FALSE}

# datay <- "GDPBYPOPTHM"
# ylim <- c(0, 75000)
# dt.start = as.Date('1960-01-01')
# plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

```{r GDPBYPOPTHM.yoy, echo=FALSE}

# datay <- "GDPBYPOPTHM.Value__YoY"
# ylim <- c(-5, 15)
# datay_aux <- "CPIAUCSL.Value__YoY"
# dt.start = as.Date('1960-01-01')
# bLegend <- TRUE
# my.plot <- plotSingle(dfRecession, df.data, "date", datay, getPlotTitle(df.symbols, datay), "Date", 
#             getPlotYLabel(df.symbols, datay), c(dt.start, Sys.Date()), ylim, bLegend)
# my.plot + geom_line(data=df.data, aes_string(x="date", y=datay_aux, colour=shQuote(datay_aux)), na.rm = TRUE)

```

Look at GDP divided by CPI per person. It flattens and even dips a little prior to a recession. Might be worth looking at the derivative of this series.

```{r GDPBYCPIAUCSLBYPOPTHM, echo=FALSE}

# datay <- "GDPBYCPIAUCSLBYPOPTHM"
# ylim <- c(10000, 30000)
# dt.start = as.Date('1960-01-01')
# plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start)

```

```{r GDPBYCPIAUCSLBYPOPTHM_SmoothDer, echo=FALSE}

# datay <- "GDPBYCPIAUCSLBYPOPTHM_SmoothDer"
# ylim <- c(-5, 5)
# dt.start = as.Date('1960-01-01')
# b.percentile <- TRUE
# plotSingleQuick(dfRecession, df.data, datay, ylim, dt.start, b.percentile)

```

That is worth a closer look

```{r GDPBYCPIAUCSLBYPOPTHM_SmoothDer_RecInit_Smooth, fig.width = 10, fig.asp = .62}

# datay1 <- "GDPBYCPIAUCSLBYPOPTHM_SmoothDer"
# ylim1 <- c(-5, 5)
# 
# datay2 <- "RecInit_Smooth"
# ylim2 <- c(0, 1)
# 
# dt.start <- as.Date("1jan1960","%d%b%Y")
# 
# w <- 30
# corrName <- calcRollingCorr(dfRecession, df.data, df.symbols, datay1, ylim1, datay2, ylim2, w, dt.start)

```

# Correlation Study

Detailed correlations are explored above. Before concluding, let's take a look at some overall correlation values to see if anything pops out.

## Commodities

As mentioned above, copper, year over year, has some correlation with the recession initiation. It could be useful.

```{r corplot.commodities, echo=FALSE, fig.width=10,fig.height=10}
# # Correlation for the entire data set
#   #training.cor <- df.data[,c("RecInit", "RecInit_Smooth", "CHRISCMEHG1", "CHRISCMEHG1_YoY","LBMAGOLD.USD_PM_YoY")]
#   training.cor <- df.data[,c("RecInit", "RecInit_Smooth")]
#   rcorr.data <- rcorr(as.matrix(training.cor), type = "pearson")
#   #print(rcorr.data)
# 
#   corrplot::corrplot(cor(training.cor), type="upper", order="original", 
#            tl.col="black", tl.srt=45, title ="Commodities data")
```

## GDP Series

GDP, normalized first by CPI and then by population, looks like it migh correlate inversely with the recession indicators


```{r corplot.gdp, echo=FALSE, fig.width=10,fig.height=10}
# 
#   # Correlation for the entire data set
#   training.cor <- df.data[,c("RecInit", "RecInit_Smooth", "GDP", "GDPC1", "GDP_YoY", "GDPBYCPIAUCSLBYPOPTHM_SmoothDer")]
#   rcorr.data <- rcorr(as.matrix(training.cor), type = "pearson")
#   #print(rcorr.data)
# 
#   corrplot::corrplot(cor(training.cor), type="upper", order="original", 
#            tl.col="black", tl.srt=45, title ="Commodities data")
```

## Financials

Let's see where we are so far. The correlation plot confirms some of the speculation above. The S&P 500 (X_GSPC.GSPC.Open) is well correlated with industrial production (INDPRO), business loans (BUSLOANS), total loans (TOTLNNSA) , and nonfinancial corporate business debt (NCBDBIQ027S). 

In this case, I want and indicator that rises prior to a recession. It looks like the unemployment rate (UNRATE), real personal income (W875RX1), and the yield curve (DGS10TO1) are all inversely correlated with the recession initiation indicator.


```{r corplot1, echo=FALSE, fig.width=12,fig.height=12}
# # Correlation for the entire data set
#   training.cor <- df.data[,c("RecInit","GSPC.Open_YoY","GSPC.Open_Log_SmoothDer",
#                             "UNRATE.Value","UNRATE_SmoothDer","UNRATE_SmoothDer2", 
#                             "INDPRO_YoY","INDPRO_SmoothDer","INDPRO_YoY",
#                             "RSALESAGG_YoY","RSALESAGG_SmoothDer",  
#                             "W875RX1_SmoothDer", "W875RX1.Value__YoY",
#                             "BUSLOANS","BUSLOANS_Log","BUSLOANS_Log_Der","BUSLOANS_YoY",
#                             "NCBDBIQ027S", "NCBDBIQ027S_Log","NCBDBIQ027S_Log_Der",
#                             "TOTLNNSA","TOTLNNSA_YoY","DGS10TO1", "DGS1", "DGS10",
#                             "ALTSALES","ALTSALES_YoY",
#                             "ICSA","ICSA.Value__YoY", "ICSA_SmoothDer","GPDI","DCOILWTICO", 
#                             "GDPSP500","IPMAN","HOUST_YoY", "GFDEBTN_YoY",
#                             "FINRAMarginDebt_YoY","GSPC.Open_mva200_Norm")]
#   rcorr.data <- rcorr(as.matrix(training.cor), type = "pearson")
#   #print(rcorr.data)
# 
#   corrplot::corrplot(cor(training.cor), type="upper", order="original", 
#            tl.col="black", tl.srt=45, title ="Financial data")
```

I thought the modified recession initiation would be a harder match, but there are quite a few correlated variables. Lets take a look at some of those in more detail

# Complete list of symbols

Since it is tedious to do this one at a time, all the symbols were entered into a data frame, loaded, and aggregated together in a single `xts` object. 

This is the complete list of symbol names and sources used in the project.

```{r listsyms, echo=FALSE}
# string.colnames <- colnames(df.symbols);
# string.colnames[1] <- "string.symbol"
# string.colnames[2] <- "string.source"
# string.colnames[3] <- "Description"
# string.colnames[4] <- "Label"
# string.colnames[5] <- "Series Start"
# kable(df.symbols, col.names = string.colnames) %>%
#  kable_styling(bootstrap_options = c("striped", "hover")) %>%
#  column_spec(column = 1, width = "1.5in; display: inline-block;") %>%
#  column_spec(2, width = "10em")

```